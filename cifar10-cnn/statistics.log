INFO: Output path already present.
INFO: Protocol buffers have been saved to the disk.
INFO: Executing on the training dataset
Iteration : 0
The accuracy of training : 0.0989999994636
The loss of the training : 2.42593169212
Iteration : 1
The accuracy of training : 0.0920000001788
The loss of the training : 2.34905314445
Iteration : 2
The accuracy of training : 0.123000003397
The loss of the training : 2.29873299599
Iteration : 3
The accuracy of training : 0.130999997258
The loss of the training : 2.29599761963
Iteration : 4
The accuracy of training : 0.135000005364
The loss of the training : 2.29066181183
Iteration : 5
The accuracy of training : 0.125
The loss of the training : 2.28689932823
Iteration : 6
The accuracy of training : 0.150999993086
The loss of the training : 2.28829979897
Iteration : 7
The accuracy of training : 0.155000001192
The loss of the training : 2.28503012657
Iteration : 8
The accuracy of training : 0.196999996901
The loss of the training : 2.27707386017
Iteration : 9
The accuracy of training : 0.141000002623
The loss of the training : 2.27533388138
Iteration : 10
The accuracy of training : 0.202999994159
The loss of the training : 2.27209854126
Iteration : 11
The accuracy of training : 0.115999996662
The loss of the training : 2.27945327759
Iteration : 12
The accuracy of training : 0.157000005245
The loss of the training : 2.27252793312
Iteration : 13
The accuracy of training : 0.12800000608
The loss of the training : 2.27470421791
Iteration : 14
The accuracy of training : 0.152999997139
The loss of the training : 2.26875901222
Iteration : 15
The accuracy of training : 0.135000005364
The loss of the training : 2.26811432838
Iteration : 16
The accuracy of training : 0.123999997973
The loss of the training : 2.27191472054
Iteration : 17
The accuracy of training : 0.136000007391
The loss of the training : 2.27974104881
Iteration : 18
The accuracy of training : 0.127000004053
The loss of the training : 2.26706361771
Iteration : 19
The accuracy of training : 0.166999995708
The loss of the training : 2.24249625206
Iteration : 20
The accuracy of training : 0.20000000298
The loss of the training : 2.23483800888
Iteration : 21
The accuracy of training : 0.16400000453
The loss of the training : 2.23274278641
Iteration : 22
The accuracy of training : 0.17499999702
The loss of the training : 2.23996591568
Iteration : 23
The accuracy of training : 0.172000005841
The loss of the training : 2.23570394516
Iteration : 24
The accuracy of training : 0.108999997377
The loss of the training : 2.30356025696
Iteration : 25
The accuracy of training : 0.145999997854
The loss of the training : 2.31903862953
Iteration : 26
The accuracy of training : 0.159999996424
The loss of the training : 2.25752019882
Iteration : 27
The accuracy of training : 0.229000002146
The loss of the training : 2.22904014587
Iteration : 28
The accuracy of training : 0.245000004768
The loss of the training : 2.20987939835
Iteration : 29
The accuracy of training : 0.240999996662
The loss of the training : 2.18989944458
Iteration : 30
The accuracy of training : 0.165999993682
The loss of the training : 2.19391131401
Iteration : 31
The accuracy of training : 0.144999995828
The loss of the training : 2.31153964996
Iteration : 32
The accuracy of training : 0.123000003397
The loss of the training : 2.29303622246
Iteration : 33
The accuracy of training : 0.216000005603
The loss of the training : 2.22827649117
Iteration : 34
The accuracy of training : 0.203999996185
The loss of the training : 2.21659326553
Iteration : 35
The accuracy of training : 0.254000008106
The loss of the training : 2.18372368813
Iteration : 36
The accuracy of training : 0.143000006676
The loss of the training : 2.18531179428
Iteration : 37
The accuracy of training : 0.112999998033
The loss of the training : 2.29905629158
Iteration : 38
The accuracy of training : 0.199000000954
The loss of the training : 2.23359394073
Iteration : 39
The accuracy of training : 0.230000004172
The loss of the training : 2.1931271553
Iteration : 40
The accuracy of training : 0.197999998927
The loss of the training : 2.14242005348
Iteration : 41
The accuracy of training : 0.24699999392
The loss of the training : 2.14609003067
Iteration : 42
The accuracy of training : 0.156000003219
The loss of the training : 2.26842403412
Iteration : 43
The accuracy of training : 0.101999998093
The loss of the training : 2.53022575378
Iteration : 44
The accuracy of training : 0.0909999981523
The loss of the training : 2.32246446609
Iteration : 45
The accuracy of training : 0.166999995708
The loss of the training : 2.26850104332
Iteration : 46
The accuracy of training : 0.162000000477
The loss of the training : 2.25670266151
Iteration : 47
The accuracy of training : 0.151999995112
The loss of the training : 2.24991393089
Iteration : 48
The accuracy of training : 0.175999999046
The loss of the training : 2.21653151512
Iteration : 49
The accuracy of training : 0.206000000238
The loss of the training : 2.19474244118
Iteration : 50
The accuracy of training : 0.226999998093
The loss of the training : 2.18219447136
Iteration : 51
The accuracy of training : 0.252000004053
The loss of the training : 2.1628484726
Iteration : 52
The accuracy of training : 0.261000007391
The loss of the training : 2.12739706039
Iteration : 53
The accuracy of training : 0.216999992728
The loss of the training : 2.12326478958
Iteration : 54
The accuracy of training : 0.245000004768
The loss of the training : 2.15792679787
Iteration : 55
The accuracy of training : 0.206000000238
The loss of the training : 2.23116803169
Iteration : 56
The accuracy of training : 0.105999998748
The loss of the training : 2.36992692947
Iteration : 57
The accuracy of training : 0.172000005841
The loss of the training : 2.26888394356
Iteration : 58
The accuracy of training : 0.25
The loss of the training : 2.20283651352
Iteration : 59
The accuracy of training : 0.294999986887
The loss of the training : 2.13588786125
Iteration : 60
The accuracy of training : 0.280999988317
The loss of the training : 2.0995028019
Iteration : 61
The accuracy of training : 0.291000008583
The loss of the training : 2.062302351
Iteration : 62
The accuracy of training : 0.25
The loss of the training : 2.07571864128
Iteration : 63
The accuracy of training : 0.241999998689
The loss of the training : 2.13668560982
Iteration : 64
The accuracy of training : 0.167999997735
The loss of the training : 2.288449049
Iteration : 65
The accuracy of training : 0.141000002623
The loss of the training : 2.41347169876
Iteration : 66
The accuracy of training : 0.126000002027
The loss of the training : 2.33975577354
Iteration : 67
The accuracy of training : 0.146999999881
The loss of the training : 2.25565481186
Iteration : 68
The accuracy of training : 0.228000000119
The loss of the training : 2.24478507042
Iteration : 69
The accuracy of training : 0.250999987125
The loss of the training : 2.23644161224
Iteration : 70
The accuracy of training : 0.270000010729
The loss of the training : 2.22275996208
Iteration : 71
The accuracy of training : 0.244000002742
The loss of the training : 2.21710753441
Iteration : 72
The accuracy of training : 0.233999997377
The loss of the training : 2.21600937843
Iteration : 73
The accuracy of training : 0.237000003457
The loss of the training : 2.205265522
Iteration : 74
The accuracy of training : 0.221000000834
The loss of the training : 2.17136836052
Iteration : 75
The accuracy of training : 0.238000005484
The loss of the training : 2.1808950901
Iteration : 76
The accuracy of training : 0.196999996901
The loss of the training : 2.14746165276
Iteration : 77
The accuracy of training : 0.194000005722
The loss of the training : 2.21992087364
Iteration : 78
The accuracy of training : 0.324999988079
The loss of the training : 2.09252595901
Iteration : 79
The accuracy of training : 0.277000010014
The loss of the training : 2.07516407967
Iteration : 80
The accuracy of training : 0.275999993086
The loss of the training : 2.02881598473
Iteration : 81
The accuracy of training : 0.238999992609
The loss of the training : 2.05414962769
Iteration : 82
The accuracy of training : 0.261000007391
The loss of the training : 2.12147760391
Iteration : 83
The accuracy of training : 0.180999994278
The loss of the training : 2.12386345863
Iteration : 84
The accuracy of training : 0.150999993086
The loss of the training : 2.27207350731
Iteration : 85
The accuracy of training : 0.140000000596
The loss of the training : 2.37696099281
Iteration : 86
The accuracy of training : 0.233999997377
The loss of the training : 2.21505236626
Iteration : 87
The accuracy of training : 0.261999994516
The loss of the training : 2.17326593399
Iteration : 88
The accuracy of training : 0.270000010729
The loss of the training : 2.12928533554
Iteration : 89
The accuracy of training : 0.27500000596
The loss of the training : 2.08802056313
Iteration : 90
The accuracy of training : 0.289999991655
The loss of the training : 2.07483363152
Iteration : 91
The accuracy of training : 0.244000002742
The loss of the training : 2.12152957916
Iteration : 92
The accuracy of training : 0.146999999881
The loss of the training : 2.31030273438
Iteration : 93
The accuracy of training : 0.261000007391
The loss of the training : 2.08623409271
Iteration : 94
The accuracy of training : 0.293000012636
The loss of the training : 2.06161808968
Iteration : 95
The accuracy of training : 0.296000003815
The loss of the training : 2.04404258728
Iteration : 96
The accuracy of training : 0.243000000715
The loss of the training : 2.05279350281
Iteration : 97
The accuracy of training : 0.218999996781
The loss of the training : 2.14558029175
Iteration : 98
The accuracy of training : 0.244000002742
The loss of the training : 2.12785124779
Iteration : 99
The accuracy of training : 0.197999998927
The loss of the training : 2.18332242966
Iteration : 100
The accuracy of training : 0.301999986172
The loss of the training : 2.03058242798
Iteration : 101
The accuracy of training : 0.314999997616
The loss of the training : 1.97311353683
Iteration : 102
The accuracy of training : 0.338999986649
The loss of the training : 1.94705533981
Iteration : 103
The accuracy of training : 0.340999990702
The loss of the training : 1.90215754509
Iteration : 104
The accuracy of training : 0.301999986172
The loss of the training : 1.98591125011
Iteration : 105
The accuracy of training : 0.131999999285
The loss of the training : 2.40109443665
Iteration : 106
The accuracy of training : 0.224000006914
The loss of the training : 2.12022948265
Iteration : 107
The accuracy of training : 0.250999987125
The loss of the training : 2.06300115585
Iteration : 108
The accuracy of training : 0.319999992847
The loss of the training : 1.99607777596
Iteration : 109
The accuracy of training : 0.342000007629
The loss of the training : 1.95425069332
Iteration : 110
The accuracy of training : 0.294999986887
The loss of the training : 1.95969176292
Iteration : 111
The accuracy of training : 0.298999994993
The loss of the training : 2.06566762924
Iteration : 112
The accuracy of training : 0.268999993801
The loss of the training : 2.01779198647
Iteration : 113
The accuracy of training : 0.268999993801
The loss of the training : 2.04823637009
Iteration : 114
The accuracy of training : 0.289999991655
The loss of the training : 1.98012900352
Iteration : 115
The accuracy of training : 0.31400001049
The loss of the training : 2.02431440353
Iteration : 116
The accuracy of training : 0.286000013351
The loss of the training : 2.02955532074
Iteration : 117
The accuracy of training : 0.231999993324
The loss of the training : 2.12244153023
Iteration : 118
The accuracy of training : 0.312999993563
The loss of the training : 1.96327650547
Iteration : 119
The accuracy of training : 0.300999999046
The loss of the training : 1.95114612579
Iteration : 120
The accuracy of training : 0.303000003099
The loss of the training : 1.99855065346
Iteration : 121
The accuracy of training : 0.231000006199
The loss of the training : 1.99152815342
Iteration : 122
The accuracy of training : 0.298000007868
The loss of the training : 1.96506309509
Iteration : 123
The accuracy of training : 0.310000002384
The loss of the training : 1.91917145252
Iteration : 124
The accuracy of training : 0.284999996424
The loss of the training : 2.01681494713
Iteration : 125
The accuracy of training : 0.268000006676
The loss of the training : 2.12331390381
Iteration : 126
The accuracy of training : 0.261999994516
The loss of the training : 2.05307722092
Iteration : 127
The accuracy of training : 0.351000010967
The loss of the training : 1.94274866581
Iteration : 128
The accuracy of training : 0.370000004768
The loss of the training : 1.86353647709
Iteration : 129
The accuracy of training : 0.356999993324
The loss of the training : 1.84150326252
Iteration : 130
The accuracy of training : 0.312000006437
The loss of the training : 1.92797636986
Iteration : 131
The accuracy of training : 0.252000004053
The loss of the training : 2.11326003075
Iteration : 132
The accuracy of training : 0.289999991655
The loss of the training : 1.94341635704
Iteration : 133
The accuracy of training : 0.319999992847
The loss of the training : 1.90160560608
Iteration : 134
The accuracy of training : 0.277000010014
The loss of the training : 1.98959577084
Iteration : 135
The accuracy of training : 0.261000007391
The loss of the training : 2.10628914833
Iteration : 136
The accuracy of training : 0.317999988794
The loss of the training : 1.95872735977
Iteration : 137
The accuracy of training : 0.379999995232
The loss of the training : 1.84049844742
Iteration : 138
The accuracy of training : 0.375
The loss of the training : 1.79656767845
Iteration : 139
The accuracy of training : 0.372000008821
The loss of the training : 1.77620840073
Iteration : 140
The accuracy of training : 0.345999985933
The loss of the training : 1.84856545925
Iteration : 141
The accuracy of training : 0.248999997973
The loss of the training : 2.1053712368
Iteration : 142
The accuracy of training : 0.241999998689
The loss of the training : 2.17947530746
Iteration : 143
The accuracy of training : 0.209000006318
The loss of the training : 2.24939799309
Iteration : 144
The accuracy of training : 0.172999992967
The loss of the training : 2.20800948143
Iteration : 145
The accuracy of training : 0.298000007868
The loss of the training : 2.00518488884
Iteration : 146
The accuracy of training : 0.344999998808
The loss of the training : 1.92833018303
Iteration : 147
The accuracy of training : 0.337000012398
The loss of the training : 1.91111063957
Iteration : 148
The accuracy of training : 0.351999998093
The loss of the training : 1.84543454647
Iteration : 149
The accuracy of training : 0.372000008821
The loss of the training : 1.81263685226
Iteration : 150
The accuracy of training : 0.389999985695
The loss of the training : 1.78797113895
Iteration : 151
The accuracy of training : 0.352999985218
The loss of the training : 1.82915353775
Iteration : 152
The accuracy of training : 0.264999985695
The loss of the training : 2.06562685966
Iteration : 153
The accuracy of training : 0.233999997377
The loss of the training : 2.35758209229
Iteration : 154
The accuracy of training : 0.211999997497
The loss of the training : 2.12933635712
Iteration : 155
The accuracy of training : 0.377999991179
The loss of the training : 1.93749964237
Iteration : 156
The accuracy of training : 0.377000004053
The loss of the training : 1.84024453163
Iteration : 157
The accuracy of training : 0.363999992609
The loss of the training : 1.82454252243
Iteration : 158
The accuracy of training : 0.398999989033
The loss of the training : 1.77135646343
Iteration : 159
The accuracy of training : 0.379000008106
The loss of the training : 1.76859509945
Iteration : 160
The accuracy of training : 0.384000003338
The loss of the training : 1.7297052145
Iteration : 161
The accuracy of training : 0.340000003576
The loss of the training : 1.76332116127
Iteration : 162
The accuracy of training : 0.34999999404
The loss of the training : 1.81406748295
Iteration : 163
The accuracy of training : 0.324999988079
The loss of the training : 1.86043560505
Iteration : 164
The accuracy of training : 0.330000013113
The loss of the training : 1.87819612026
Iteration : 165
The accuracy of training : 0.319999992847
The loss of the training : 1.91328585148
Iteration : 166
The accuracy of training : 0.240999996662
The loss of the training : 2.08417248726
Iteration : 167
The accuracy of training : 0.263999998569
The loss of the training : 2.1027636528
Iteration : 168
The accuracy of training : 0.344999998808
The loss of the training : 1.90518975258
Iteration : 169
The accuracy of training : 0.354000002146
The loss of the training : 1.79872477055
Iteration : 170
The accuracy of training : 0.40000000596
The loss of the training : 1.79054570198
Iteration : 171
The accuracy of training : 0.388999998569
The loss of the training : 1.73560202122
Iteration : 172
The accuracy of training : 0.412000000477
The loss of the training : 1.72852778435
Iteration : 173
The accuracy of training : 0.375999987125
The loss of the training : 1.72980940342
Iteration : 174
The accuracy of training : 0.335000008345
The loss of the training : 1.90445077419
Iteration : 175
The accuracy of training : 0.275999993086
The loss of the training : 2.17025208473
Iteration : 176
The accuracy of training : 0.29699999094
The loss of the training : 1.97239637375
Iteration : 177
The accuracy of training : 0.381999999285
The loss of the training : 1.81408059597
Iteration : 178
The accuracy of training : 0.404000014067
The loss of the training : 1.72997677326
Iteration : 179
The accuracy of training : 0.393000006676
The loss of the training : 1.68927013874
Iteration : 180
The accuracy of training : 0.393000006676
The loss of the training : 1.71215939522
Iteration : 181
The accuracy of training : 0.351999998093
The loss of the training : 1.76711308956
Iteration : 182
The accuracy of training : 0.312000006437
The loss of the training : 1.94130659103
Iteration : 183
The accuracy of training : 0.324999988079
The loss of the training : 1.95802545547
Iteration : 184
The accuracy of training : 0.389999985695
The loss of the training : 1.76349961758
Iteration : 185
The accuracy of training : 0.411000013351
The loss of the training : 1.71568071842
Iteration : 186
The accuracy of training : 0.425000011921
The loss of the training : 1.68359434605
Iteration : 187
The accuracy of training : 0.377000004053
The loss of the training : 1.73755669594
Iteration : 188
The accuracy of training : 0.352999985218
The loss of the training : 1.76326715946
Iteration : 189
The accuracy of training : 0.296000003815
The loss of the training : 1.88687264919
Iteration : 190
The accuracy of training : 0.363999992609
The loss of the training : 1.86552870274
Iteration : 191
The accuracy of training : 0.381000012159
The loss of the training : 1.73421537876
Iteration : 192
The accuracy of training : 0.361999988556
The loss of the training : 1.7288621664
Iteration : 193
The accuracy of training : 0.393000006676
The loss of the training : 1.70673179626
Iteration : 194
The accuracy of training : 0.416999995708
The loss of the training : 1.67072975636
Iteration : 195
The accuracy of training : 0.405000001192
The loss of the training : 1.72296571732
Iteration : 196
The accuracy of training : 0.331999987364
The loss of the training : 1.8836171627
Iteration : 197
The accuracy of training : 0.301999986172
The loss of the training : 2.0151181221
Iteration : 198
The accuracy of training : 0.360000014305
The loss of the training : 1.86028397083
Iteration : 199
The accuracy of training : 0.40000000596
The loss of the training : 1.71999168396
Iteration : 200
The accuracy of training : 0.428000003099
The loss of the training : 1.65032553673
Iteration : 201
The accuracy of training : 0.38299998641
The loss of the training : 1.67265534401
Iteration : 202
The accuracy of training : 0.368000000715
The loss of the training : 1.7227281332
Iteration : 203
The accuracy of training : 0.361999988556
The loss of the training : 1.79733777046
Iteration : 204
The accuracy of training : 0.368000000715
The loss of the training : 1.73494064808
Iteration : 205
The accuracy of training : 0.395999997854
The loss of the training : 1.73572647572
Iteration : 206
The accuracy of training : 0.370999991894
The loss of the training : 1.72248852253
Iteration : 207
The accuracy of training : 0.40000000596
The loss of the training : 1.6749060154
Iteration : 208
The accuracy of training : 0.416999995708
The loss of the training : 1.6356985569
Iteration : 209
The accuracy of training : 0.407000005245
The loss of the training : 1.63221979141
Iteration : 210
The accuracy of training : 0.402999997139
The loss of the training : 1.72407138348
Iteration : 211
The accuracy of training : 0.365999996662
The loss of the training : 1.74844348431
Iteration : 212
The accuracy of training : 0.358000010252
The loss of the training : 1.85932850838
Iteration : 213
The accuracy of training : 0.365999996662
The loss of the training : 1.79067957401
Iteration : 214
The accuracy of training : 0.397000014782
The loss of the training : 1.72962510586
Iteration : 215
The accuracy of training : 0.398999989033
The loss of the training : 1.72905945778
Iteration : 216
The accuracy of training : 0.389999985695
The loss of the training : 1.68087518215
Iteration : 217
The accuracy of training : 0.412000000477
The loss of the training : 1.66775500774
Iteration : 218
The accuracy of training : 0.358000010252
The loss of the training : 1.75126564503
Iteration : 219
The accuracy of training : 0.365000009537
The loss of the training : 1.77796661854
Iteration : 220
The accuracy of training : 0.407999992371
The loss of the training : 1.70115017891
Iteration : 221
The accuracy of training : 0.439999997616
The loss of the training : 1.61160290241
Iteration : 222
The accuracy of training : 0.458999991417
The loss of the training : 1.57995188236
Iteration : 223
The accuracy of training : 0.444000005722
The loss of the training : 1.55586266518
Iteration : 224
The accuracy of training : 0.393999993801
The loss of the training : 1.6674849987
Iteration : 225
The accuracy of training : 0.335000008345
The loss of the training : 1.84289431572
Iteration : 226
The accuracy of training : 0.317000001669
The loss of the training : 1.86670327187
Iteration : 227
The accuracy of training : 0.372999995947
The loss of the training : 1.72548556328
Iteration : 228
The accuracy of training : 0.423000007868
The loss of the training : 1.59930944443
Iteration : 229
The accuracy of training : 0.449000000954
The loss of the training : 1.57119977474
Iteration : 230
The accuracy of training : 0.433999985456
The loss of the training : 1.61029839516
Iteration : 231
The accuracy of training : 0.388999998569
The loss of the training : 1.72180604935
Iteration : 232
The accuracy of training : 0.287999987602
The loss of the training : 2.03116750717
Iteration : 233
The accuracy of training : 0.340999990702
The loss of the training : 1.88481235504
Iteration : 234
The accuracy of training : 0.40000000596
The loss of the training : 1.73186290264
Iteration : 235
The accuracy of training : 0.41400000453
The loss of the training : 1.62433767319
Iteration : 236
The accuracy of training : 0.442000001669
The loss of the training : 1.57304906845
Iteration : 237
The accuracy of training : 0.430999994278
The loss of the training : 1.6048643589
Iteration : 238
The accuracy of training : 0.418999999762
The loss of the training : 1.58948636055
Iteration : 239
The accuracy of training : 0.407000005245
The loss of the training : 1.64873099327
Iteration : 240
The accuracy of training : 0.358999997377
The loss of the training : 1.76803219318
Iteration : 241
The accuracy of training : 0.397000014782
The loss of the training : 1.69374549389
Iteration : 242
The accuracy of training : 0.423999994993
The loss of the training : 1.6310454607
Iteration : 243
The accuracy of training : 0.418000012636
The loss of the training : 1.65702474117
Iteration : 244
The accuracy of training : 0.423999994993
The loss of the training : 1.6879273653
Iteration : 245
The accuracy of training : 0.379000008106
The loss of the training : 1.75234925747
Iteration : 246
The accuracy of training : 0.395999997854
The loss of the training : 1.64917230606
Iteration : 247
The accuracy of training : 0.437000006437
The loss of the training : 1.58617985249
Iteration : 248
The accuracy of training : 0.437999993563
The loss of the training : 1.57675468922
Iteration : 249
The accuracy of training : 0.402999997139
The loss of the training : 1.60676074028
Iteration : 250
The accuracy of training : 0.426999986172
The loss of the training : 1.65114438534
Iteration : 251
The accuracy of training : 0.412000000477
The loss of the training : 1.63300895691
Iteration : 252
The accuracy of training : 0.404000014067
The loss of the training : 1.6565567255
Iteration : 253
The accuracy of training : 0.423999994993
The loss of the training : 1.63159036636
Iteration : 254
The accuracy of training : 0.418999999762
The loss of the training : 1.65414130688
Iteration : 255
The accuracy of training : 0.437000006437
The loss of the training : 1.64387118816
Iteration : 256
The accuracy of training : 0.444999992847
The loss of the training : 1.54827225208
Iteration : 257
The accuracy of training : 0.476000010967
The loss of the training : 1.51165354252
Iteration : 258
The accuracy of training : 0.451000005007
The loss of the training : 1.53042316437
Iteration : 259
The accuracy of training : 0.416999995708
The loss of the training : 1.63309252262
Iteration : 260
The accuracy of training : 0.340000003576
The loss of the training : 2.00352215767
Iteration : 261
The accuracy of training : 0.352999985218
The loss of the training : 1.83685994148
Iteration : 262
The accuracy of training : 0.41400000453
The loss of the training : 1.66615593433
Iteration : 263
The accuracy of training : 0.432000011206
The loss of the training : 1.59470415115
Iteration : 264
The accuracy of training : 0.439999997616
The loss of the training : 1.57745289803
Iteration : 265
The accuracy of training : 0.43599998951
The loss of the training : 1.58758354187
Iteration : 266
The accuracy of training : 0.432000011206
The loss of the training : 1.59290075302
Iteration : 267
The accuracy of training : 0.419999986887
The loss of the training : 1.64478766918
Iteration : 268
The accuracy of training : 0.437999993563
The loss of the training : 1.57483923435
Iteration : 269
The accuracy of training : 0.423000007868
The loss of the training : 1.5640232563
Iteration : 270
The accuracy of training : 0.391999989748
The loss of the training : 1.69258677959
Iteration : 271
The accuracy of training : 0.418999999762
The loss of the training : 1.63219916821
Iteration : 272
The accuracy of training : 0.402000010014
The loss of the training : 1.63868713379
Iteration : 273
The accuracy of training : 0.433999985456
The loss of the training : 1.63082098961
Iteration : 274
The accuracy of training : 0.449000000954
The loss of the training : 1.56043076515
Iteration : 275
The accuracy of training : 0.444999992847
The loss of the training : 1.57666432858
Iteration : 276
The accuracy of training : 0.456000000238
The loss of the training : 1.53739321232
Iteration : 277
The accuracy of training : 0.412000000477
The loss of the training : 1.59808409214
Iteration : 278
The accuracy of training : 0.449999988079
The loss of the training : 1.56294476986
Iteration : 279
The accuracy of training : 0.437000006437
The loss of the training : 1.5445625782
Iteration : 280
The accuracy of training : 0.446000009775
The loss of the training : 1.52780902386
Iteration : 281
The accuracy of training : 0.444999992847
The loss of the training : 1.51590514183
Iteration : 282
The accuracy of training : 0.465000003576
The loss of the training : 1.49913299084
Iteration : 283
The accuracy of training : 0.448000013828
The loss of the training : 1.5300630331
Iteration : 284
The accuracy of training : 0.46099999547
The loss of the training : 1.51692485809
Iteration : 285
The accuracy of training : 0.442000001669
The loss of the training : 1.56473553181
Iteration : 286
The accuracy of training : 0.432999998331
The loss of the training : 1.54069650173
Iteration : 287
The accuracy of training : 0.430000007153
The loss of the training : 1.60676085949
Iteration : 288
The accuracy of training : 0.389999985695
The loss of the training : 1.64700400829
Iteration : 289
The accuracy of training : 0.418999999762
The loss of the training : 1.62580525875
Iteration : 290
The accuracy of training : 0.437000006437
The loss of the training : 1.62857294083
Iteration : 291
The accuracy of training : 0.451999992132
The loss of the training : 1.54874932766
Iteration : 292
The accuracy of training : 0.451999992132
The loss of the training : 1.55099880695
Iteration : 293
The accuracy of training : 0.449999988079
The loss of the training : 1.54388093948
Iteration : 294
The accuracy of training : 0.41400000453
The loss of the training : 1.65797221661
Iteration : 295
The accuracy of training : 0.433999985456
The loss of the training : 1.66751790047
Iteration : 296
The accuracy of training : 0.418000012636
The loss of the training : 1.63191437721
Iteration : 297
The accuracy of training : 0.477999985218
The loss of the training : 1.54323351383
Iteration : 298
The accuracy of training : 0.458000004292
The loss of the training : 1.56848526001
Iteration : 299
The accuracy of training : 0.47499999404
The loss of the training : 1.50855517387
Iteration : 300
The accuracy of training : 0.469000011683
The loss of the training : 1.52327251434
Iteration : 301
The accuracy of training : 0.495999991894
The loss of the training : 1.46817433834
Iteration : 302
The accuracy of training : 0.497999995947
The loss of the training : 1.46552169323
Iteration : 303
The accuracy of training : 0.497999995947
The loss of the training : 1.42932963371
Iteration : 304
The accuracy of training : 0.481000006199
The loss of the training : 1.47675812244
Iteration : 305
The accuracy of training : 0.462000012398
The loss of the training : 1.51099634171
Iteration : 306
The accuracy of training : 0.460000008345
The loss of the training : 1.52129030228
Iteration : 307
The accuracy of training : 0.437000006437
The loss of the training : 1.60421812534
Iteration : 308
The accuracy of training : 0.446000009775
The loss of the training : 1.55066466331
Iteration : 309
The accuracy of training : 0.43599998951
The loss of the training : 1.58415484428
Iteration : 310
The accuracy of training : 0.36700001359
The loss of the training : 1.794080019
Iteration : 311
The accuracy of training : 0.398000001907
The loss of the training : 1.65353810787
Iteration : 312
The accuracy of training : 0.435000002384
The loss of the training : 1.57494807243
Iteration : 313
The accuracy of training : 0.458999991417
The loss of the training : 1.55561554432
Iteration : 314
The accuracy of training : 0.488999992609
The loss of the training : 1.47053682804
Iteration : 315
The accuracy of training : 0.488000005484
The loss of the training : 1.44688332081
Iteration : 316
The accuracy of training : 0.486000001431
The loss of the training : 1.43778634071
Iteration : 317
The accuracy of training : 0.439999997616
The loss of the training : 1.51660895348
Iteration : 318
The accuracy of training : 0.43599998951
The loss of the training : 1.58148252964
Iteration : 319
The accuracy of training : 0.425999999046
The loss of the training : 1.63364553452
Iteration : 320
The accuracy of training : 0.451000005007
The loss of the training : 1.52552866936
Iteration : 321
The accuracy of training : 0.467999994755
The loss of the training : 1.45769143105
Iteration : 322
The accuracy of training : 0.486999988556
The loss of the training : 1.44352579117
Iteration : 323
The accuracy of training : 0.481999993324
The loss of the training : 1.46175658703
Iteration : 324
The accuracy of training : 0.486000001431
The loss of the training : 1.44756770134
Iteration : 325
The accuracy of training : 0.463999986649
The loss of the training : 1.48886299133
Iteration : 326
The accuracy of training : 0.472000002861
The loss of the training : 1.45646643639
Iteration : 327
The accuracy of training : 0.469999998808
The loss of the training : 1.46289503574
Iteration : 328
The accuracy of training : 0.493000000715
The loss of the training : 1.45798325539
Iteration : 329
The accuracy of training : 0.462999999523
The loss of the training : 1.47689926624
Iteration : 330
The accuracy of training : 0.426999986172
The loss of the training : 1.64578151703
Iteration : 331
The accuracy of training : 0.456999987364
The loss of the training : 1.56604230404
Iteration : 332
The accuracy of training : 0.442000001669
The loss of the training : 1.53894507885
Iteration : 333
The accuracy of training : 0.449000000954
The loss of the training : 1.55684816837
Iteration : 334
The accuracy of training : 0.442000001669
The loss of the training : 1.57958900928
Iteration : 335
The accuracy of training : 0.467000007629
The loss of the training : 1.65470862389
Iteration : 336
The accuracy of training : 0.451000005007
The loss of the training : 1.57773566246
Iteration : 337
The accuracy of training : 0.474000006914
The loss of the training : 1.55639815331
Iteration : 338
The accuracy of training : 0.472999989986
The loss of the training : 1.47743606567
Iteration : 339
The accuracy of training : 0.481999993324
The loss of the training : 1.45594632626
Iteration : 340
The accuracy of training : 0.470999985933
The loss of the training : 1.4830057621
Iteration : 341
The accuracy of training : 0.488999992609
The loss of the training : 1.45232021809
Iteration : 342
The accuracy of training : 0.500999987125
The loss of the training : 1.41834652424
Iteration : 343
The accuracy of training : 0.509000003338
The loss of the training : 1.38717114925
Iteration : 344
The accuracy of training : 0.485000014305
The loss of the training : 1.4380825758
Iteration : 345
The accuracy of training : 0.479999989271
The loss of the training : 1.47732186317
Iteration : 346
The accuracy of training : 0.45300000906
The loss of the training : 1.53234875202
Iteration : 347
The accuracy of training : 0.423000007868
The loss of the training : 1.63949716091
Iteration : 348
The accuracy of training : 0.488000005484
The loss of the training : 1.45068776608
Iteration : 349
The accuracy of training : 0.497000008821
The loss of the training : 1.40572464466
Iteration : 350
The accuracy of training : 0.501999974251
The loss of the training : 1.41903233528
Iteration : 351
The accuracy of training : 0.488999992609
The loss of the training : 1.43768560886
Iteration : 352
The accuracy of training : 0.493000000715
The loss of the training : 1.48239672184
Iteration : 353
The accuracy of training : 0.446000009775
The loss of the training : 1.52722406387
Iteration : 354
The accuracy of training : 0.476999998093
The loss of the training : 1.4925378561
Iteration : 355
The accuracy of training : 0.451999992132
The loss of the training : 1.54310417175
Iteration : 356
The accuracy of training : 0.501999974251
The loss of the training : 1.42186796665
Iteration : 357
The accuracy of training : 0.449999988079
The loss of the training : 1.4838694334
Iteration : 358
The accuracy of training : 0.465000003576
The loss of the training : 1.5012588501
Iteration : 359
The accuracy of training : 0.467000007629
The loss of the training : 1.46613669395
Iteration : 360
The accuracy of training : 0.488000005484
The loss of the training : 1.45681166649
Iteration : 361
The accuracy of training : 0.488999992609
The loss of the training : 1.42861926556
Iteration : 362
The accuracy of training : 0.451999992132
The loss of the training : 1.47937595844
Iteration : 363
The accuracy of training : 0.467000007629
The loss of the training : 1.50715172291
Iteration : 364
The accuracy of training : 0.513000011444
The loss of the training : 1.44436442852
Iteration : 365
The accuracy of training : 0.481000006199
The loss of the training : 1.42063331604
Iteration : 366
The accuracy of training : 0.495999991894
The loss of the training : 1.38687169552
Iteration : 367
The accuracy of training : 0.490999996662
The loss of the training : 1.43160116673
Iteration : 368
The accuracy of training : 0.465999990702
The loss of the training : 1.50148069859
Iteration : 369
The accuracy of training : 0.407999992371
The loss of the training : 1.65304744244
Iteration : 370
The accuracy of training : 0.441000014544
The loss of the training : 1.68743824959
Iteration : 371
The accuracy of training : 0.493999987841
The loss of the training : 1.46497249603
Iteration : 372
The accuracy of training : 0.472999989986
The loss of the training : 1.47714722157
Iteration : 373
The accuracy of training : 0.462999999523
The loss of the training : 1.48804938793
Iteration : 374
The accuracy of training : 0.483999997377
The loss of the training : 1.47802448273
Iteration : 375
The accuracy of training : 0.493000000715
The loss of the training : 1.51517760754
Iteration : 376
The accuracy of training : 0.488000005484
The loss of the training : 1.42335295677
Iteration : 377
The accuracy of training : 0.500999987125
The loss of the training : 1.41517531872
Iteration : 378
The accuracy of training : 0.47499999404
The loss of the training : 1.47280204296
Iteration : 379
The accuracy of training : 0.444999992847
The loss of the training : 1.55752718449
Iteration : 380
The accuracy of training : 0.474000006914
The loss of the training : 1.53385531902
Iteration : 381
The accuracy of training : 0.509000003338
The loss of the training : 1.39558577538
Iteration : 382
The accuracy of training : 0.532000005245
The loss of the training : 1.37911629677
Iteration : 383
The accuracy of training : 0.52999997139
The loss of the training : 1.33554196358
Iteration : 384
The accuracy of training : 0.521000027657
The loss of the training : 1.38098216057
Iteration : 385
The accuracy of training : 0.497000008821
The loss of the training : 1.41013991833
Iteration : 386
The accuracy of training : 0.486999988556
The loss of the training : 1.42487752438
Iteration : 387
The accuracy of training : 0.483000010252
The loss of the training : 1.46198344231
Iteration : 388
The accuracy of training : 0.504000008106
The loss of the training : 1.38861870766
Iteration : 389
The accuracy of training : 0.497000008821
The loss of the training : 1.37546420097
Iteration : 390
The accuracy of training : 0.500999987125
The loss of the training : 1.39988732338
Iteration : 391
The accuracy of training : 0.49200001359
The loss of the training : 1.44056940079
Iteration : 392
The accuracy of training : 0.462999999523
The loss of the training : 1.50200009346
Iteration : 393
The accuracy of training : 0.435000002384
The loss of the training : 1.57182836533
Iteration : 394
The accuracy of training : 0.465000003576
The loss of the training : 1.51334965229
Iteration : 395
The accuracy of training : 0.509000003338
The loss of the training : 1.43124997616
Iteration : 396
The accuracy of training : 0.513999998569
The loss of the training : 1.3989739418
Iteration : 397
The accuracy of training : 0.486999988556
The loss of the training : 1.42875421047
Iteration : 398
The accuracy of training : 0.479000002146
The loss of the training : 1.42831671238
Iteration : 399
The accuracy of training : 0.497999995947
The loss of the training : 1.42310905457
Iteration : 400
The accuracy of training : 0.483000010252
The loss of the training : 1.43774247169
Iteration : 401
The accuracy of training : 0.508000016212
The loss of the training : 1.37568688393
Iteration : 402
The accuracy of training : 0.493000000715
The loss of the training : 1.39819955826
Iteration : 403
The accuracy of training : 0.507000029087
The loss of the training : 1.41500735283
Iteration : 404
The accuracy of training : 0.501999974251
The loss of the training : 1.39722120762
Iteration : 405
The accuracy of training : 0.46099999547
The loss of the training : 1.45799303055
Iteration : 406
The accuracy of training : 0.481000006199
The loss of the training : 1.40675270557
Iteration : 407
The accuracy of training : 0.467000007629
The loss of the training : 1.45981097221
Iteration : 408
The accuracy of training : 0.481999993324
The loss of the training : 1.49250197411
Iteration : 409
The accuracy of training : 0.43599998951
The loss of the training : 1.57700932026
Iteration : 410
The accuracy of training : 0.456999987364
The loss of the training : 1.51890540123
Iteration : 411
The accuracy of training : 0.476000010967
The loss of the training : 1.46143984795
Iteration : 412
The accuracy of training : 0.479000002146
The loss of the training : 1.43518435955
Iteration : 413
The accuracy of training : 0.495000004768
The loss of the training : 1.43262457848
Iteration : 414
The accuracy of training : 0.505999982357
The loss of the training : 1.44536948204
Iteration : 415
The accuracy of training : 0.488000005484
The loss of the training : 1.50107312202
Iteration : 416
The accuracy of training : 0.501999974251
The loss of the training : 1.44423615932
Iteration : 417
The accuracy of training : 0.500999987125
The loss of the training : 1.42278885841
Iteration : 418
The accuracy of training : 0.509000003338
The loss of the training : 1.3798763752
Iteration : 419
The accuracy of training : 0.509999990463
The loss of the training : 1.36568927765
Iteration : 420
The accuracy of training : 0.504999995232
The loss of the training : 1.39195656776
Iteration : 421
The accuracy of training : 0.509999990463
The loss of the training : 1.36959183216
Iteration : 422
The accuracy of training : 0.509999990463
The loss of the training : 1.36064970493
Iteration : 423
The accuracy of training : 0.536000013351
The loss of the training : 1.31732082367
Iteration : 424
The accuracy of training : 0.522000014782
The loss of the training : 1.33402466774
Iteration : 425
The accuracy of training : 0.527999997139
The loss of the training : 1.33942294121
Iteration : 426
The accuracy of training : 0.532000005245
The loss of the training : 1.35345387459
Iteration : 427
The accuracy of training : 0.490000009537
The loss of the training : 1.42932522297
Iteration : 428
The accuracy of training : 0.504000008106
The loss of the training : 1.38797664642
Iteration : 429
The accuracy of training : 0.46099999547
The loss of the training : 1.47396659851
Iteration : 430
The accuracy of training : 0.488999992609
The loss of the training : 1.45078623295
Iteration : 431
The accuracy of training : 0.485000014305
The loss of the training : 1.43289971352
Iteration : 432
The accuracy of training : 0.474000006914
The loss of the training : 1.45514941216
Iteration : 433
The accuracy of training : 0.467000007629
The loss of the training : 1.46929085255
Iteration : 434
The accuracy of training : 0.51700001955
The loss of the training : 1.38814258575
Iteration : 435
The accuracy of training : 0.510999977589
The loss of the training : 1.42112314701
Iteration : 436
The accuracy of training : 0.500999987125
The loss of the training : 1.39843857288
Iteration : 437
The accuracy of training : 0.474000006914
The loss of the training : 1.43210995197
Iteration : 438
The accuracy of training : 0.483000010252
The loss of the training : 1.41320562363
Iteration : 439
The accuracy of training : 0.49200001359
The loss of the training : 1.41777956486
Iteration : 440
The accuracy of training : 0.486999988556
The loss of the training : 1.44566202164
Iteration : 441
The accuracy of training : 0.490000009537
The loss of the training : 1.41864287853
Iteration : 442
The accuracy of training : 0.526000022888
The loss of the training : 1.35764312744
Iteration : 443
The accuracy of training : 0.51599997282
The loss of the training : 1.3614783287
Iteration : 444
The accuracy of training : 0.54699999094
The loss of the training : 1.32764184475
Iteration : 445
The accuracy of training : 0.507000029087
The loss of the training : 1.36603534222
Iteration : 446
The accuracy of training : 0.497000008821
The loss of the training : 1.36129796505
Iteration : 447
The accuracy of training : 0.479999989271
The loss of the training : 1.43367171288
Iteration : 448
The accuracy of training : 0.493000000715
The loss of the training : 1.45440924168
Iteration : 449
The accuracy of training : 0.446000009775
The loss of the training : 1.50481545925
Iteration : 450
The accuracy of training : 0.469000011683
The loss of the training : 1.49433720112
Iteration : 451
The accuracy of training : 0.467000007629
The loss of the training : 1.47017538548
Iteration : 452
The accuracy of training : 0.467000007629
The loss of the training : 1.45303881168
Iteration : 453
The accuracy of training : 0.483000010252
The loss of the training : 1.45336341858
Iteration : 454
The accuracy of training : 0.518000006676
The loss of the training : 1.42449045181
Iteration : 455
The accuracy of training : 0.509999990463
The loss of the training : 1.43804883957
Iteration : 456
The accuracy of training : 0.544000029564
The loss of the training : 1.33956575394
Iteration : 457
The accuracy of training : 0.537999987602
The loss of the training : 1.31239771843
Iteration : 458
The accuracy of training : 0.532000005245
The loss of the training : 1.32010924816
Iteration : 459
The accuracy of training : 0.523999989033
The loss of the training : 1.32954788208
Iteration : 460
The accuracy of training : 0.536000013351
The loss of the training : 1.35141122341
Iteration : 461
The accuracy of training : 0.536000013351
The loss of the training : 1.33574175835
Iteration : 462
The accuracy of training : 0.538999974728
The loss of the training : 1.31475448608
Iteration : 463
The accuracy of training : 0.538999974728
The loss of the training : 1.28769493103
Iteration : 464
The accuracy of training : 0.528999984264
The loss of the training : 1.32549107075
Iteration : 465
The accuracy of training : 0.518999993801
The loss of the training : 1.37352931499
Iteration : 466
The accuracy of training : 0.499000012875
The loss of the training : 1.41105544567
Iteration : 467
The accuracy of training : 0.488000005484
The loss of the training : 1.41469824314
Iteration : 468
The accuracy of training : 0.527000010014
The loss of the training : 1.31632137299
Iteration : 469
The accuracy of training : 0.523999989033
The loss of the training : 1.32775127888
Iteration : 470
The accuracy of training : 0.501999974251
The loss of the training : 1.37228834629
Iteration : 471
The accuracy of training : 0.512000024319
The loss of the training : 1.39982748032
Iteration : 472
The accuracy of training : 0.479999989271
The loss of the training : 1.44505500793
Iteration : 473
The accuracy of training : 0.474000006914
The loss of the training : 1.47723150253
Iteration : 474
The accuracy of training : 0.5
The loss of the training : 1.38638114929
Iteration : 475
The accuracy of training : 0.532000005245
The loss of the training : 1.36774837971
Iteration : 476
The accuracy of training : 0.527000010014
The loss of the training : 1.34964084625
Iteration : 477
The accuracy of training : 0.503000020981
The loss of the training : 1.36721491814
Iteration : 478
The accuracy of training : 0.512000024319
The loss of the training : 1.35208380222
Iteration : 479
The accuracy of training : 0.532999992371
The loss of the training : 1.32784545422
Iteration : 480
The accuracy of training : 0.522000014782
The loss of the training : 1.33544123173
Iteration : 481
The accuracy of training : 0.573000013828
The loss of the training : 1.26880586147
Iteration : 482
The accuracy of training : 0.52999997139
The loss of the training : 1.29614269733
Iteration : 483
The accuracy of training : 0.509999990463
The loss of the training : 1.37209796906
Iteration : 484
The accuracy of training : 0.497999995947
The loss of the training : 1.41395127773
Iteration : 485
The accuracy of training : 0.45300000906
The loss of the training : 1.47253584862
Iteration : 486
The accuracy of training : 0.495000004768
The loss of the training : 1.38260388374
Iteration : 487
The accuracy of training : 0.521000027657
The loss of the training : 1.32722449303
Iteration : 488
The accuracy of training : 0.541000008583
The loss of the training : 1.32843732834
Iteration : 489
The accuracy of training : 0.509999990463
The loss of the training : 1.34396767616
Iteration : 490
The accuracy of training : 0.524999976158
The loss of the training : 1.40865266323
Iteration : 491
The accuracy of training : 0.479999989271
The loss of the training : 1.4353672266
Iteration : 492
The accuracy of training : 0.449999988079
The loss of the training : 1.49099838734
Iteration : 493
The accuracy of training : 0.497999995947
The loss of the training : 1.44471251965
Iteration : 494
The accuracy of training : 0.535000026226
The loss of the training : 1.36784899235
Iteration : 495
The accuracy of training : 0.523000001907
The loss of the training : 1.38292276859
Iteration : 496
The accuracy of training : 0.552999973297
The loss of the training : 1.29727518559
Iteration : 497
The accuracy of training : 0.565999984741
The loss of the training : 1.27172911167
Iteration : 498
The accuracy of training : 0.550000011921
The loss of the training : 1.29093134403
Iteration : 499
The accuracy of training : 0.532999992371
The loss of the training : 1.32221245766
Iteration : 500
The accuracy of training : 0.493000000715
The loss of the training : 1.41977488995
Iteration : 501
The accuracy of training : 0.477999985218
The loss of the training : 1.49909210205
Iteration : 502
The accuracy of training : 0.504999995232
The loss of the training : 1.37809717655
Iteration : 503
The accuracy of training : 0.541000008583
The loss of the training : 1.27026426792
Iteration : 504
The accuracy of training : 0.547999978065
The loss of the training : 1.29212403297
Iteration : 505
The accuracy of training : 0.536000013351
The loss of the training : 1.31122291088
Iteration : 506
The accuracy of training : 0.544000029564
The loss of the training : 1.29695463181
Iteration : 507
The accuracy of training : 0.526000022888
The loss of the training : 1.32853031158
Iteration : 508
The accuracy of training : 0.545000016689
The loss of the training : 1.24561333656
Iteration : 509
The accuracy of training : 0.532999992371
The loss of the training : 1.27986383438
Iteration : 510
The accuracy of training : 0.523999989033
The loss of the training : 1.34669554234
Iteration : 511
The accuracy of training : 0.507000029087
The loss of the training : 1.4132014513
Iteration : 512
The accuracy of training : 0.449999988079
The loss of the training : 1.55529689789
Iteration : 513
The accuracy of training : 0.47499999404
The loss of the training : 1.4824539423
Iteration : 514
The accuracy of training : 0.546000003815
The loss of the training : 1.33463454247
Iteration : 515
The accuracy of training : 0.551999986172
The loss of the training : 1.30573272705
Iteration : 516
The accuracy of training : 0.551999986172
The loss of the training : 1.2875649929
Iteration : 517
The accuracy of training : 0.53100001812
The loss of the training : 1.31259191036
Iteration : 518
The accuracy of training : 0.535000026226
The loss of the training : 1.30399441719
Iteration : 519
The accuracy of training : 0.527000010014
The loss of the training : 1.31293392181
Iteration : 520
The accuracy of training : 0.521000027657
The loss of the training : 1.37885713577
Iteration : 521
The accuracy of training : 0.504000008106
The loss of the training : 1.39524519444
Iteration : 522
The accuracy of training : 0.507000029087
The loss of the training : 1.39193475246
Iteration : 523
The accuracy of training : 0.514999985695
The loss of the training : 1.42493736744
Iteration : 524
The accuracy of training : 0.538999974728
The loss of the training : 1.38021349907
Iteration : 525
The accuracy of training : 0.495999991894
The loss of the training : 1.38904392719
Iteration : 526
The accuracy of training : 0.555000007153
The loss of the training : 1.28490996361
Iteration : 527
The accuracy of training : 0.52999997139
The loss of the training : 1.28462553024
Iteration : 528
The accuracy of training : 0.533999979496
The loss of the training : 1.28769087791
Iteration : 529
The accuracy of training : 0.503000020981
The loss of the training : 1.33853209019
Iteration : 530
The accuracy of training : 0.493000000715
The loss of the training : 1.42453372478
Iteration : 531
The accuracy of training : 0.518999993801
The loss of the training : 1.37512671947
Iteration : 532
The accuracy of training : 0.51599997282
The loss of the training : 1.34976124763
Iteration : 533
The accuracy of training : 0.541999995708
The loss of the training : 1.31309521198
Iteration : 534
The accuracy of training : 0.550999999046
The loss of the training : 1.31540060043
Iteration : 535
The accuracy of training : 0.51599997282
The loss of the training : 1.38288092613
Iteration : 536
The accuracy of training : 0.535000026226
The loss of the training : 1.33052229881
Iteration : 537
The accuracy of training : 0.528999984264
The loss of the training : 1.3285702467
Iteration : 538
The accuracy of training : 0.472000002861
The loss of the training : 1.44002306461
Iteration : 539
The accuracy of training : 0.499000012875
The loss of the training : 1.40503835678
Iteration : 540
The accuracy of training : 0.532000005245
The loss of the training : 1.36424303055
Iteration : 541
The accuracy of training : 0.545000016689
The loss of the training : 1.30263316631
Iteration : 542
The accuracy of training : 0.556999981403
The loss of the training : 1.28406655788
Iteration : 543
The accuracy of training : 0.564999997616
The loss of the training : 1.21805274487
Iteration : 544
The accuracy of training : 0.549000024796
The loss of the training : 1.2585092783
Iteration : 545
The accuracy of training : 0.552999973297
The loss of the training : 1.26438188553
Iteration : 546
The accuracy of training : 0.569000005722
The loss of the training : 1.25561451912
Iteration : 547
The accuracy of training : 0.537999987602
The loss of the training : 1.30255162716
Iteration : 548
The accuracy of training : 0.563000023365
The loss of the training : 1.22478640079
Iteration : 549
The accuracy of training : 0.549000024796
The loss of the training : 1.25767755508
Iteration : 550
The accuracy of training : 0.533999979496
The loss of the training : 1.29792690277
Iteration : 551
The accuracy of training : 0.544000029564
The loss of the training : 1.31299889088
Iteration : 552
The accuracy of training : 0.53100001812
The loss of the training : 1.33869659901
Iteration : 553
The accuracy of training : 0.514999985695
The loss of the training : 1.36314630508
Iteration : 554
The accuracy of training : 0.565999984741
The loss of the training : 1.28174853325
Iteration : 555
The accuracy of training : 0.558000028133
The loss of the training : 1.30707502365
Iteration : 556
The accuracy of training : 0.535000026226
The loss of the training : 1.30660796165
Iteration : 557
The accuracy of training : 0.532999992371
The loss of the training : 1.33738803864
Iteration : 558
The accuracy of training : 0.552999973297
The loss of the training : 1.29917383194
Iteration : 559
The accuracy of training : 0.533999979496
The loss of the training : 1.30080533028
Iteration : 560
The accuracy of training : 0.549000024796
The loss of the training : 1.32413744926
Iteration : 561
The accuracy of training : 0.527999997139
The loss of the training : 1.34935796261
Iteration : 562
The accuracy of training : 0.523999989033
The loss of the training : 1.35179102421
Iteration : 563
The accuracy of training : 0.53100001812
The loss of the training : 1.33305895329
Iteration : 564
The accuracy of training : 0.579999983311
The loss of the training : 1.28002989292
Iteration : 565
The accuracy of training : 0.527999997139
The loss of the training : 1.27717804909
Iteration : 566
The accuracy of training : 0.555000007153
The loss of the training : 1.26212239265
Iteration : 567
The accuracy of training : 0.533999979496
The loss of the training : 1.29246389866
Iteration : 568
The accuracy of training : 0.535000026226
The loss of the training : 1.2801015377
Iteration : 569
The accuracy of training : 0.528999984264
The loss of the training : 1.29862892628
Iteration : 570
The accuracy of training : 0.541000008583
The loss of the training : 1.34505808353
Iteration : 571
The accuracy of training : 0.550999999046
The loss of the training : 1.2757833004
Iteration : 572
The accuracy of training : 0.507000029087
The loss of the training : 1.33770275116
Iteration : 573
The accuracy of training : 0.518000006676
The loss of the training : 1.37514019012
Iteration : 574
The accuracy of training : 0.546000003815
The loss of the training : 1.32508814335
Iteration : 575
The accuracy of training : 0.514999985695
The loss of the training : 1.36419653893
Iteration : 576
The accuracy of training : 0.559000015259
The loss of the training : 1.27443897724
Iteration : 577
The accuracy of training : 0.569000005722
The loss of the training : 1.25282609463
Iteration : 578
The accuracy of training : 0.538999974728
The loss of the training : 1.29262089729
Iteration : 579
The accuracy of training : 0.523999989033
The loss of the training : 1.35651445389
Iteration : 580
The accuracy of training : 0.527000010014
The loss of the training : 1.36697566509
Iteration : 581
The accuracy of training : 0.545000016689
The loss of the training : 1.30199444294
Iteration : 582
The accuracy of training : 0.532999992371
The loss of the training : 1.30628597736
Iteration : 583
The accuracy of training : 0.568000018597
The loss of the training : 1.23062551022
Iteration : 584
The accuracy of training : 0.560000002384
The loss of the training : 1.28462588787
Iteration : 585
The accuracy of training : 0.535000026226
The loss of the training : 1.28937065601
Iteration : 586
The accuracy of training : 0.550999999046
The loss of the training : 1.29462993145
Iteration : 587
The accuracy of training : 0.533999979496
The loss of the training : 1.31606090069
Iteration : 588
The accuracy of training : 0.554000020027
The loss of the training : 1.25210821629
Iteration : 589
The accuracy of training : 0.547999978065
The loss of the training : 1.26974153519
Iteration : 590
The accuracy of training : 0.533999979496
The loss of the training : 1.28235387802
Iteration : 591
The accuracy of training : 0.556999981403
The loss of the training : 1.2815117836
Iteration : 592
The accuracy of training : 0.551999986172
The loss of the training : 1.30222785473
Iteration : 593
The accuracy of training : 0.526000022888
The loss of the training : 1.33925759792
Iteration : 594
The accuracy of training : 0.565999984741
The loss of the training : 1.28283500671
Iteration : 595
The accuracy of training : 0.527000010014
The loss of the training : 1.34839463234
Iteration : 596
The accuracy of training : 0.550000011921
The loss of the training : 1.32732117176
Iteration : 597
The accuracy of training : 0.541999995708
The loss of the training : 1.33685147762
Iteration : 598
The accuracy of training : 0.542999982834
The loss of the training : 1.30137598515
Iteration : 599
The accuracy of training : 0.538999974728
The loss of the training : 1.28922247887
Iteration : 600
The accuracy of training : 0.552999973297
The loss of the training : 1.3021402359
Iteration : 601
The accuracy of training : 0.561999976635
The loss of the training : 1.25173246861
Iteration : 602
The accuracy of training : 0.551999986172
The loss of the training : 1.24099338055
Iteration : 603
The accuracy of training : 0.570999979973
The loss of the training : 1.27468049526
Iteration : 604
The accuracy of training : 0.579999983311
The loss of the training : 1.25476884842
Iteration : 605
The accuracy of training : 0.533999979496
The loss of the training : 1.2848418951
Iteration : 606
The accuracy of training : 0.540000021458
The loss of the training : 1.27662456036
Iteration : 607
The accuracy of training : 0.518999993801
The loss of the training : 1.335313797
Iteration : 608
The accuracy of training : 0.538999974728
The loss of the training : 1.27957427502
Iteration : 609
The accuracy of training : 0.524999976158
The loss of the training : 1.28985762596
Iteration : 610
The accuracy of training : 0.53100001812
The loss of the training : 1.33906209469
Iteration : 611
The accuracy of training : 0.518999993801
The loss of the training : 1.33033502102
Iteration : 612
The accuracy of training : 0.514999985695
The loss of the training : 1.34334886074
Iteration : 613
The accuracy of training : 0.541999995708
The loss of the training : 1.3172981739
Iteration : 614
The accuracy of training : 0.574000000954
The loss of the training : 1.26458323002
Iteration : 615
The accuracy of training : 0.541999995708
The loss of the training : 1.3179987669
Iteration : 616
The accuracy of training : 0.574999988079
The loss of the training : 1.24652314186
Iteration : 617
The accuracy of training : 0.584999978542
The loss of the training : 1.22140431404
Iteration : 618
The accuracy of training : 0.555000007153
The loss of the training : 1.25154614449
Iteration : 619
The accuracy of training : 0.546000003815
The loss of the training : 1.30058991909
Iteration : 620
The accuracy of training : 0.54699999094
The loss of the training : 1.29080760479
Iteration : 621
The accuracy of training : 0.560000002384
The loss of the training : 1.2492017746
Iteration : 622
The accuracy of training : 0.569999992847
The loss of the training : 1.23862457275
Iteration : 623
The accuracy of training : 0.575999975204
The loss of the training : 1.1980599165
Iteration : 624
The accuracy of training : 0.555999994278
The loss of the training : 1.25278794765
Iteration : 625
The accuracy of training : 0.560000002384
The loss of the training : 1.24692499638
Iteration : 626
The accuracy of training : 0.570999979973
The loss of the training : 1.22367596626
Iteration : 627
The accuracy of training : 0.569999992847
The loss of the training : 1.24770486355
Iteration : 628
The accuracy of training : 0.579999983311
The loss of the training : 1.16568100452
Iteration : 629
The accuracy of training : 0.561999976635
The loss of the training : 1.21939742565
Iteration : 630
The accuracy of training : 0.528999984264
The loss of the training : 1.30730354786
Iteration : 631
The accuracy of training : 0.521000027657
The loss of the training : 1.38966035843
Iteration : 632
The accuracy of training : 0.509999990463
The loss of the training : 1.43487334251
Iteration : 633
The accuracy of training : 0.485000014305
The loss of the training : 1.45048034191
Iteration : 634
The accuracy of training : 0.537999987602
The loss of the training : 1.32989060879
Iteration : 635
The accuracy of training : 0.536000013351
The loss of the training : 1.30523574352
Iteration : 636
The accuracy of training : 0.563000023365
The loss of the training : 1.25920152664
Iteration : 637
The accuracy of training : 0.552999973297
The loss of the training : 1.2748042345
Iteration : 638
The accuracy of training : 0.561999976635
The loss of the training : 1.23386228085
Iteration : 639
The accuracy of training : 0.556999981403
The loss of the training : 1.22465777397
Iteration : 640
The accuracy of training : 0.555000007153
The loss of the training : 1.245875597
Iteration : 641
The accuracy of training : 0.586000025272
The loss of the training : 1.19804370403
Iteration : 642
The accuracy of training : 0.568000018597
The loss of the training : 1.21359813213
Iteration : 643
The accuracy of training : 0.565999984741
The loss of the training : 1.27101671696
Iteration : 644
The accuracy of training : 0.575999975204
The loss of the training : 1.22369301319
Iteration : 645
The accuracy of training : 0.550999999046
The loss of the training : 1.25305771828
Iteration : 646
The accuracy of training : 0.563000023365
The loss of the training : 1.24316167831
Iteration : 647
The accuracy of training : 0.542999982834
The loss of the training : 1.29913985729
Iteration : 648
The accuracy of training : 0.524999976158
The loss of the training : 1.31550240517
Iteration : 649
The accuracy of training : 0.495999991894
The loss of the training : 1.35412061214
Iteration : 650
The accuracy of training : 0.504999995232
The loss of the training : 1.37294638157
Iteration : 651
The accuracy of training : 0.52999997139
The loss of the training : 1.31341338158
Iteration : 652
The accuracy of training : 0.533999979496
The loss of the training : 1.29239583015
Iteration : 653
The accuracy of training : 0.56400001049
The loss of the training : 1.26831281185
Iteration : 654
The accuracy of training : 0.577000021935
The loss of the training : 1.25225567818
Iteration : 655
The accuracy of training : 0.547999978065
The loss of the training : 1.28546237946
Iteration : 656
The accuracy of training : 0.583999991417
The loss of the training : 1.21438479424
Iteration : 657
The accuracy of training : 0.582000017166
The loss of the training : 1.17469274998
Iteration : 658
The accuracy of training : 0.569999992847
The loss of the training : 1.21318411827
Iteration : 659
The accuracy of training : 0.563000023365
The loss of the training : 1.25078392029
Iteration : 660
The accuracy of training : 0.575999975204
The loss of the training : 1.2385083437
Iteration : 661
The accuracy of training : 0.57800000906
The loss of the training : 1.21862661839
Iteration : 662
The accuracy of training : 0.568000018597
The loss of the training : 1.2062754631
Iteration : 663
The accuracy of training : 0.586000025272
The loss of the training : 1.15694713593
Iteration : 664
The accuracy of training : 0.56400001049
The loss of the training : 1.21010363102
Iteration : 665
The accuracy of training : 0.556999981403
The loss of the training : 1.24310255051
Iteration : 666
The accuracy of training : 0.570999979973
The loss of the training : 1.22764873505
Iteration : 667
The accuracy of training : 0.549000024796
The loss of the training : 1.2739443779
Iteration : 668
The accuracy of training : 0.586000025272
The loss of the training : 1.17563521862
Iteration : 669
The accuracy of training : 0.573000013828
The loss of the training : 1.22125005722
Iteration : 670
The accuracy of training : 0.550000011921
The loss of the training : 1.24375104904
Iteration : 671
The accuracy of training : 0.551999986172
The loss of the training : 1.26820683479
Iteration : 672
The accuracy of training : 0.547999978065
The loss of the training : 1.29521536827
Iteration : 673
The accuracy of training : 0.544000029564
The loss of the training : 1.31390750408
Iteration : 674
The accuracy of training : 0.56099998951
The loss of the training : 1.22858858109
Iteration : 675
The accuracy of training : 0.57800000906
The loss of the training : 1.22020924091
Iteration : 676
The accuracy of training : 0.574000000954
The loss of the training : 1.20985591412
Iteration : 677
The accuracy of training : 0.532999992371
The loss of the training : 1.29515838623
Iteration : 678
The accuracy of training : 0.537000000477
The loss of the training : 1.31822836399
Iteration : 679
The accuracy of training : 0.513000011444
The loss of the training : 1.39669048786
Iteration : 680
The accuracy of training : 0.513000011444
The loss of the training : 1.34530377388
Iteration : 681
The accuracy of training : 0.591000020504
The loss of the training : 1.22060060501
Iteration : 682
The accuracy of training : 0.580999970436
The loss of the training : 1.19611823559
Iteration : 683
The accuracy of training : 0.578999996185
The loss of the training : 1.25186753273
Iteration : 684
The accuracy of training : 0.579999983311
The loss of the training : 1.23461985588
Iteration : 685
The accuracy of training : 0.555999994278
The loss of the training : 1.24293851852
Iteration : 686
The accuracy of training : 0.565999984741
The loss of the training : 1.22161185741
Iteration : 687
The accuracy of training : 0.547999978065
The loss of the training : 1.24712455273
Iteration : 688
The accuracy of training : 0.587999999523
The loss of the training : 1.22263288498
Iteration : 689
The accuracy of training : 0.537000000477
The loss of the training : 1.26789367199
Iteration : 690
The accuracy of training : 0.532999992371
The loss of the training : 1.31468141079
Iteration : 691
The accuracy of training : 0.542999982834
The loss of the training : 1.29929983616
Iteration : 692
The accuracy of training : 0.533999979496
The loss of the training : 1.31292235851
Iteration : 693
The accuracy of training : 0.56400001049
The loss of the training : 1.23298490047
Iteration : 694
The accuracy of training : 0.579999983311
The loss of the training : 1.22804200649
Iteration : 695
The accuracy of training : 0.52999997139
The loss of the training : 1.28424453735
Iteration : 696
The accuracy of training : 0.569000005722
The loss of the training : 1.23183393478
Iteration : 697
The accuracy of training : 0.592999994755
The loss of the training : 1.17131018639
Iteration : 698
The accuracy of training : 0.583999991417
The loss of the training : 1.21081233025
Iteration : 699
The accuracy of training : 0.558000028133
The loss of the training : 1.25388348103
Iteration : 700
The accuracy of training : 0.532000005245
The loss of the training : 1.29594492912
Iteration : 701
The accuracy of training : 0.569000005722
The loss of the training : 1.23425447941
Iteration : 702
The accuracy of training : 0.570999979973
The loss of the training : 1.22513318062
Iteration : 703
The accuracy of training : 0.584999978542
The loss of the training : 1.15059447289
Iteration : 704
The accuracy of training : 0.592000007629
The loss of the training : 1.18657839298
Iteration : 705
The accuracy of training : 0.578999996185
The loss of the training : 1.20921838284
Iteration : 706
The accuracy of training : 0.578999996185
The loss of the training : 1.21397662163
Iteration : 707
The accuracy of training : 0.550999999046
The loss of the training : 1.247169137
Iteration : 708
The accuracy of training : 0.560000002384
The loss of the training : 1.18562602997
Iteration : 709
The accuracy of training : 0.574000000954
The loss of the training : 1.23068857193
Iteration : 710
The accuracy of training : 0.551999986172
The loss of the training : 1.24409258366
Iteration : 711
The accuracy of training : 0.56099998951
The loss of the training : 1.2470690012
Iteration : 712
The accuracy of training : 0.538999974728
The loss of the training : 1.27667605877
Iteration : 713
The accuracy of training : 0.527000010014
The loss of the training : 1.32640755177
Iteration : 714
The accuracy of training : 0.570999979973
The loss of the training : 1.24930870533
Iteration : 715
The accuracy of training : 0.56099998951
The loss of the training : 1.27884674072
Iteration : 716
The accuracy of training : 0.577000021935
The loss of the training : 1.20848858356
Iteration : 717
The accuracy of training : 0.565999984741
The loss of the training : 1.22234368324
Iteration : 718
The accuracy of training : 0.573000013828
The loss of the training : 1.19543457031
Iteration : 719
The accuracy of training : 0.575999975204
The loss of the training : 1.18464922905
Iteration : 720
The accuracy of training : 0.57800000906
The loss of the training : 1.19712913036
Iteration : 721
The accuracy of training : 0.592999994755
The loss of the training : 1.14641189575
Iteration : 722
The accuracy of training : 0.603999972343
The loss of the training : 1.15930962563
Iteration : 723
The accuracy of training : 0.559000015259
The loss of the training : 1.21170532703
Iteration : 724
The accuracy of training : 0.586000025272
The loss of the training : 1.20771849155
Iteration : 725
The accuracy of training : 0.561999976635
The loss of the training : 1.20024609566
Iteration : 726
The accuracy of training : 0.589999973774
The loss of the training : 1.1789522171
Iteration : 727
The accuracy of training : 0.564999997616
The loss of the training : 1.18717598915
Iteration : 728
The accuracy of training : 0.583000004292
The loss of the training : 1.16342043877
Iteration : 729
The accuracy of training : 0.554000020027
The loss of the training : 1.20803713799
Iteration : 730
The accuracy of training : 0.522000014782
The loss of the training : 1.38689565659
Iteration : 731
The accuracy of training : 0.523000001907
The loss of the training : 1.41459929943
Iteration : 732
The accuracy of training : 0.512000024319
The loss of the training : 1.42267537117
Iteration : 733
The accuracy of training : 0.565999984741
The loss of the training : 1.23028004169
Iteration : 734
The accuracy of training : 0.598999977112
The loss of the training : 1.24188184738
Iteration : 735
The accuracy of training : 0.552999973297
The loss of the training : 1.28488850594
Iteration : 736
The accuracy of training : 0.582000017166
The loss of the training : 1.21802246571
Iteration : 737
The accuracy of training : 0.619000017643
The loss of the training : 1.13554060459
Iteration : 738
The accuracy of training : 0.605000019073
The loss of the training : 1.18508565426
Iteration : 739
The accuracy of training : 0.584999978542
The loss of the training : 1.21270442009
Iteration : 740
The accuracy of training : 0.573000013828
The loss of the training : 1.21192872524
Iteration : 741
The accuracy of training : 0.592999994755
The loss of the training : 1.19694316387
Iteration : 742
The accuracy of training : 0.572000026703
The loss of the training : 1.19911301136
Iteration : 743
The accuracy of training : 0.606999993324
The loss of the training : 1.11808621883
Iteration : 744
The accuracy of training : 0.601999998093
The loss of the training : 1.15771389008
Iteration : 745
The accuracy of training : 0.587000012398
The loss of the training : 1.16219639778
Iteration : 746
The accuracy of training : 0.587999999523
The loss of the training : 1.16498291492
Iteration : 747
The accuracy of training : 0.573000013828
The loss of the training : 1.20915937424
Iteration : 748
The accuracy of training : 0.579999983311
The loss of the training : 1.14506089687
Iteration : 749
The accuracy of training : 0.574999988079
The loss of the training : 1.18263626099
Iteration : 750
The accuracy of training : 0.577000021935
The loss of the training : 1.20438766479
Iteration : 751
The accuracy of training : 0.583999991417
The loss of the training : 1.20518565178
Iteration : 752
The accuracy of training : 0.572000026703
The loss of the training : 1.2233736515
Iteration : 753
The accuracy of training : 0.550000011921
The loss of the training : 1.25477516651
Iteration : 754
The accuracy of training : 0.587999999523
The loss of the training : 1.18808746338
Iteration : 755
The accuracy of training : 0.572000026703
The loss of the training : 1.22421443462
Iteration : 756
The accuracy of training : 0.57800000906
The loss of the training : 1.22988724709
Iteration : 757
The accuracy of training : 0.550999999046
The loss of the training : 1.28271174431
Iteration : 758
The accuracy of training : 0.569000005722
The loss of the training : 1.23982596397
Iteration : 759
The accuracy of training : 0.574999988079
The loss of the training : 1.19594860077
Iteration : 760
The accuracy of training : 0.587999999523
The loss of the training : 1.20725572109
Iteration : 761
The accuracy of training : 0.589999973774
The loss of the training : 1.15675520897
Iteration : 762
The accuracy of training : 0.59399998188
The loss of the training : 1.13858520985
Iteration : 763
The accuracy of training : 0.588999986649
The loss of the training : 1.19511067867
Iteration : 764
The accuracy of training : 0.577000021935
The loss of the training : 1.19909727573
Iteration : 765
The accuracy of training : 0.537999987602
The loss of the training : 1.26767098904
Iteration : 766
The accuracy of training : 0.532000005245
The loss of the training : 1.29043328762
Iteration : 767
The accuracy of training : 0.545000016689
The loss of the training : 1.26858150959
Iteration : 768
The accuracy of training : 0.588999986649
The loss of the training : 1.17779946327
Iteration : 769
The accuracy of training : 0.569999992847
The loss of the training : 1.19209575653
Iteration : 770
The accuracy of training : 0.561999976635
The loss of the training : 1.24510288239
Iteration : 771
The accuracy of training : 0.573000013828
The loss of the training : 1.19831717014
Iteration : 772
The accuracy of training : 0.550999999046
The loss of the training : 1.22787809372
Iteration : 773
The accuracy of training : 0.583999991417
The loss of the training : 1.20172536373
Iteration : 774
The accuracy of training : 0.589999973774
The loss of the training : 1.19784271717
Iteration : 775
The accuracy of training : 0.556999981403
The loss of the training : 1.23848712444
Iteration : 776
The accuracy of training : 0.59500002861
The loss of the training : 1.17384088039
Iteration : 777
The accuracy of training : 0.601999998093
The loss of the training : 1.1290293932
Iteration : 778
The accuracy of training : 0.587000012398
The loss of the training : 1.1752165556
Iteration : 779
The accuracy of training : 0.575999975204
The loss of the training : 1.19991314411
Iteration : 780
The accuracy of training : 0.583000004292
The loss of the training : 1.19494438171
Iteration : 781
The accuracy of training : 0.598999977112
The loss of the training : 1.15537118912
Iteration : 782
The accuracy of training : 0.603999972343
The loss of the training : 1.15264356136
Iteration : 783
The accuracy of training : 0.601999998093
The loss of the training : 1.11304426193
Iteration : 784
The accuracy of training : 0.587000012398
The loss of the training : 1.1663428545
Iteration : 785
The accuracy of training : 0.584999978542
The loss of the training : 1.18566799164
Iteration : 786
The accuracy of training : 0.59399998188
The loss of the training : 1.16653263569
Iteration : 787
The accuracy of training : 0.588999986649
The loss of the training : 1.17952466011
Iteration : 788
The accuracy of training : 0.606999993324
The loss of the training : 1.09242963791
Iteration : 789
The accuracy of training : 0.606999993324
The loss of the training : 1.14239990711
Iteration : 790
The accuracy of training : 0.584999978542
The loss of the training : 1.17986178398
Iteration : 791
The accuracy of training : 0.577000021935
The loss of the training : 1.23076856136
Iteration : 792
The accuracy of training : 0.550000011921
The loss of the training : 1.26822304726
Iteration : 793
The accuracy of training : 0.52999997139
The loss of the training : 1.30899643898
Iteration : 794
The accuracy of training : 0.580999970436
The loss of the training : 1.17611086369
Iteration : 795
The accuracy of training : 0.606999993324
The loss of the training : 1.16795563698
Iteration : 796
The accuracy of training : 0.601999998093
The loss of the training : 1.14898979664
Iteration : 797
The accuracy of training : 0.587999999523
The loss of the training : 1.17693281174
Iteration : 798
The accuracy of training : 0.592999994755
The loss of the training : 1.1566157341
Iteration : 799
The accuracy of training : 0.59500002861
The loss of the training : 1.15702474117
Iteration : 800
The accuracy of training : 0.605000019073
The loss of the training : 1.16561281681
Iteration : 801
The accuracy of training : 0.611999988556
The loss of the training : 1.12062418461
Iteration : 802
The accuracy of training : 0.597999989986
The loss of the training : 1.15553712845
Iteration : 803
The accuracy of training : 0.559000015259
The loss of the training : 1.23536014557
Iteration : 804
The accuracy of training : 0.568000018597
The loss of the training : 1.24219274521
Iteration : 805
The accuracy of training : 0.559000015259
The loss of the training : 1.21880722046
Iteration : 806
The accuracy of training : 0.600000023842
The loss of the training : 1.1721765995
Iteration : 807
The accuracy of training : 0.570999979973
The loss of the training : 1.16018712521
Iteration : 808
The accuracy of training : 0.602999985218
The loss of the training : 1.12193048
Iteration : 809
The accuracy of training : 0.573000013828
The loss of the training : 1.14400136471
Iteration : 810
The accuracy of training : 0.554000020027
The loss of the training : 1.25454592705
Iteration : 811
The accuracy of training : 0.573000013828
The loss of the training : 1.21132481098
Iteration : 812
The accuracy of training : 0.561999976635
The loss of the training : 1.25364089012
Iteration : 813
The accuracy of training : 0.575999975204
The loss of the training : 1.19384205341
Iteration : 814
The accuracy of training : 0.596000015736
The loss of the training : 1.20899021626
Iteration : 815
The accuracy of training : 0.536000013351
The loss of the training : 1.27581501007
Iteration : 816
The accuracy of training : 0.580999970436
The loss of the training : 1.2152518034
Iteration : 817
The accuracy of training : 0.596000015736
The loss of the training : 1.13251876831
Iteration : 818
The accuracy of training : 0.60799998045
The loss of the training : 1.14235019684
Iteration : 819
The accuracy of training : 0.597999989986
The loss of the training : 1.15899562836
Iteration : 820
The accuracy of training : 0.597000002861
The loss of the training : 1.1584187746
Iteration : 821
The accuracy of training : 0.614000022411
The loss of the training : 1.13821077347
Iteration : 822
The accuracy of training : 0.598999977112
The loss of the training : 1.14062428474
Iteration : 823
The accuracy of training : 0.60900002718
The loss of the training : 1.08125054836
Iteration : 824
The accuracy of training : 0.611000001431
The loss of the training : 1.12541925907
Iteration : 825
The accuracy of training : 0.592999994755
The loss of the training : 1.14762866497
Iteration : 826
The accuracy of training : 0.592000007629
The loss of the training : 1.14716410637
Iteration : 827
The accuracy of training : 0.587000012398
The loss of the training : 1.17855834961
Iteration : 828
The accuracy of training : 0.605000019073
The loss of the training : 1.10840678215
Iteration : 829
The accuracy of training : 0.579999983311
The loss of the training : 1.14530813694
Iteration : 830
The accuracy of training : 0.592000007629
The loss of the training : 1.1661438942
Iteration : 831
The accuracy of training : 0.596000015736
The loss of the training : 1.18414163589
Iteration : 832
The accuracy of training : 0.575999975204
The loss of the training : 1.22415816784
Iteration : 833
The accuracy of training : 0.546000003815
The loss of the training : 1.28404521942
Iteration : 834
The accuracy of training : 0.574000000954
The loss of the training : 1.20416164398
Iteration : 835
The accuracy of training : 0.578999996185
The loss of the training : 1.1808065176
Iteration : 836
The accuracy of training : 0.612999975681
The loss of the training : 1.13863134384
Iteration : 837
The accuracy of training : 0.574999988079
The loss of the training : 1.19295954704
Iteration : 838
The accuracy of training : 0.59399998188
The loss of the training : 1.15768587589
Iteration : 839
The accuracy of training : 0.586000025272
The loss of the training : 1.15234673023
Iteration : 840
The accuracy of training : 0.582000017166
The loss of the training : 1.16472244263
Iteration : 841
The accuracy of training : 0.617999970913
The loss of the training : 1.09685230255
Iteration : 842
The accuracy of training : 0.602999985218
The loss of the training : 1.10036063194
Iteration : 843
The accuracy of training : 0.596000015736
The loss of the training : 1.16713213921
Iteration : 844
The accuracy of training : 0.586000025272
The loss of the training : 1.14454269409
Iteration : 845
The accuracy of training : 0.574999988079
The loss of the training : 1.16592299938
Iteration : 846
The accuracy of training : 0.564999997616
The loss of the training : 1.15952670574
Iteration : 847
The accuracy of training : 0.577000021935
The loss of the training : 1.18211233616
Iteration : 848
The accuracy of training : 0.580999970436
The loss of the training : 1.17213726044
Iteration : 849
The accuracy of training : 0.560000002384
The loss of the training : 1.23461723328
Iteration : 850
The accuracy of training : 0.568000018597
The loss of the training : 1.23887228966
Iteration : 851
The accuracy of training : 0.583000004292
The loss of the training : 1.20131313801
Iteration : 852
The accuracy of training : 0.573000013828
The loss of the training : 1.20694220066
Iteration : 853
The accuracy of training : 0.605000019073
The loss of the training : 1.15223026276
Iteration : 854
The accuracy of training : 0.602999985218
The loss of the training : 1.16328060627
Iteration : 855
The accuracy of training : 0.564999997616
The loss of the training : 1.21433258057
Iteration : 856
The accuracy of training : 0.597999989986
The loss of the training : 1.15201556683
Iteration : 857
The accuracy of training : 0.617999970913
The loss of the training : 1.08708488941
Iteration : 858
The accuracy of training : 0.606000006199
The loss of the training : 1.13125181198
Iteration : 859
The accuracy of training : 0.591000020504
The loss of the training : 1.15385985374
Iteration : 860
The accuracy of training : 0.596000015736
The loss of the training : 1.15035402775
Iteration : 861
The accuracy of training : 0.611000001431
The loss of the training : 1.12406420708
Iteration : 862
The accuracy of training : 0.620000004768
The loss of the training : 1.12243008614
Iteration : 863
The accuracy of training : 0.612999975681
The loss of the training : 1.07239937782
Iteration : 864
The accuracy of training : 0.598999977112
The loss of the training : 1.12854552269
Iteration : 865
The accuracy of training : 0.605000019073
The loss of the training : 1.16903102398
Iteration : 866
The accuracy of training : 0.59399998188
The loss of the training : 1.16426885128
Iteration : 867
The accuracy of training : 0.587000012398
The loss of the training : 1.18666231632
Iteration : 868
The accuracy of training : 0.606000006199
The loss of the training : 1.09659254551
Iteration : 869
The accuracy of training : 0.606999993324
The loss of the training : 1.1419043541
Iteration : 870
The accuracy of training : 0.587000012398
The loss of the training : 1.15027594566
Iteration : 871
The accuracy of training : 0.603999972343
The loss of the training : 1.15696418285
Iteration : 872
The accuracy of training : 0.583999991417
The loss of the training : 1.18231081963
Iteration : 873
The accuracy of training : 0.56099998951
The loss of the training : 1.21736991405
Iteration : 874
The accuracy of training : 0.592999994755
The loss of the training : 1.13343989849
Iteration : 875
The accuracy of training : 0.602999985218
The loss of the training : 1.14889514446
Iteration : 876
The accuracy of training : 0.633000016212
The loss of the training : 1.12269937992
Iteration : 877
The accuracy of training : 0.597000002861
The loss of the training : 1.18645012379
Iteration : 878
The accuracy of training : 0.59500002861
The loss of the training : 1.21121442318
Iteration : 879
The accuracy of training : 0.574999988079
The loss of the training : 1.2526563406
Iteration : 880
The accuracy of training : 0.550000011921
The loss of the training : 1.29130876064
Iteration : 881
The accuracy of training : 0.586000025272
The loss of the training : 1.21582341194
Iteration : 882
The accuracy of training : 0.588999986649
The loss of the training : 1.15257847309
Iteration : 883
The accuracy of training : 0.59500002861
The loss of the training : 1.17010402679
Iteration : 884
The accuracy of training : 0.619000017643
The loss of the training : 1.11141335964
Iteration : 885
The accuracy of training : 0.615999996662
The loss of the training : 1.11828696728
Iteration : 886
The accuracy of training : 0.588999986649
The loss of the training : 1.11013066769
Iteration : 887
The accuracy of training : 0.588999986649
The loss of the training : 1.13629949093
Iteration : 888
The accuracy of training : 0.60900002718
The loss of the training : 1.11306262016
Iteration : 889
The accuracy of training : 0.579999983311
The loss of the training : 1.1744903326
Iteration : 890
The accuracy of training : 0.56099998951
The loss of the training : 1.21200692654
Iteration : 891
The accuracy of training : 0.598999977112
The loss of the training : 1.17228770256
Iteration : 892
The accuracy of training : 0.579999983311
The loss of the training : 1.19064414501
Iteration : 893
The accuracy of training : 0.60799998045
The loss of the training : 1.13121128082
Iteration : 894
The accuracy of training : 0.611999988556
The loss of the training : 1.14061641693
Iteration : 895
The accuracy of training : 0.568000018597
The loss of the training : 1.19727563858
Iteration : 896
The accuracy of training : 0.597999989986
The loss of the training : 1.15292704105
Iteration : 897
The accuracy of training : 0.64099997282
The loss of the training : 1.06148266792
Iteration : 898
The accuracy of training : 0.616999983788
The loss of the training : 1.10868692398
Iteration : 899
The accuracy of training : 0.603999972343
The loss of the training : 1.13178741932
Iteration : 900
The accuracy of training : 0.602999985218
The loss of the training : 1.13089239597
Iteration : 901
The accuracy of training : 0.603999972343
The loss of the training : 1.10030889511
Iteration : 902
The accuracy of training : 0.615000009537
The loss of the training : 1.11205160618
Iteration : 903
The accuracy of training : 0.616999983788
The loss of the training : 1.06251394749
Iteration : 904
The accuracy of training : 0.614000022411
The loss of the training : 1.11757540703
Iteration : 905
The accuracy of training : 0.614000022411
The loss of the training : 1.14056682587
Iteration : 906
The accuracy of training : 0.601000010967
The loss of the training : 1.14505267143
Iteration : 907
The accuracy of training : 0.592999994755
The loss of the training : 1.1513620615
Iteration : 908
The accuracy of training : 0.621999979019
The loss of the training : 1.08415901661
Iteration : 909
The accuracy of training : 0.605000019073
The loss of the training : 1.14722681046
Iteration : 910
The accuracy of training : 0.592999994755
The loss of the training : 1.16629242897
Iteration : 911
The accuracy of training : 0.584999978542
The loss of the training : 1.18648171425
Iteration : 912
The accuracy of training : 0.56400001049
The loss of the training : 1.21214449406
Iteration : 913
The accuracy of training : 0.561999976635
The loss of the training : 1.21896111965
Iteration : 914
The accuracy of training : 0.606999993324
The loss of the training : 1.11922609806
Iteration : 915
The accuracy of training : 0.589999973774
The loss of the training : 1.14607036114
Iteration : 916
The accuracy of training : 0.621999979019
The loss of the training : 1.10963320732
Iteration : 917
The accuracy of training : 0.586000025272
The loss of the training : 1.17606663704
Iteration : 918
The accuracy of training : 0.602999985218
The loss of the training : 1.15240192413
Iteration : 919
The accuracy of training : 0.598999977112
The loss of the training : 1.13880741596
Iteration : 920
The accuracy of training : 0.611999988556
The loss of the training : 1.13611841202
Iteration : 921
The accuracy of training : 0.615000009537
The loss of the training : 1.09895479679
Iteration : 922
The accuracy of training : 0.616999983788
The loss of the training : 1.09089899063
Iteration : 923
The accuracy of training : 0.59399998188
The loss of the training : 1.11589097977
Iteration : 924
The accuracy of training : 0.624000012875
The loss of the training : 1.10003018379
Iteration : 925
The accuracy of training : 0.611000001431
The loss of the training : 1.09298014641
Iteration : 926
The accuracy of training : 0.611999988556
The loss of the training : 1.07197582722
Iteration : 927
The accuracy of training : 0.619000017643
The loss of the training : 1.08677816391
Iteration : 928
The accuracy of training : 0.646000027657
The loss of the training : 1.05883765221
Iteration : 929
The accuracy of training : 0.619000017643
The loss of the training : 1.08703184128
Iteration : 930
The accuracy of training : 0.589999973774
The loss of the training : 1.17633724213
Iteration : 931
The accuracy of training : 0.586000025272
The loss of the training : 1.15767872334
Iteration : 932
The accuracy of training : 0.584999978542
The loss of the training : 1.19399952888
Iteration : 933
The accuracy of training : 0.598999977112
The loss of the training : 1.14749705791
Iteration : 934
The accuracy of training : 0.60799998045
The loss of the training : 1.1450483799
Iteration : 935
The accuracy of training : 0.558000028133
The loss of the training : 1.20792555809
Iteration : 936
The accuracy of training : 0.597000002861
The loss of the training : 1.15609717369
Iteration : 937
The accuracy of training : 0.615999996662
The loss of the training : 1.06816589832
Iteration : 938
The accuracy of training : 0.615999996662
The loss of the training : 1.13301515579
Iteration : 939
The accuracy of training : 0.596000015736
The loss of the training : 1.14582192898
Iteration : 940
The accuracy of training : 0.60900002718
The loss of the training : 1.13995289803
Iteration : 941
The accuracy of training : 0.60900002718
The loss of the training : 1.12280249596
Iteration : 942
The accuracy of training : 0.603999972343
The loss of the training : 1.13867640495
Iteration : 943
The accuracy of training : 0.630999982357
The loss of the training : 1.06626009941
Iteration : 944
The accuracy of training : 0.614000022411
The loss of the training : 1.1140332222
Iteration : 945
The accuracy of training : 0.606000006199
The loss of the training : 1.11863410473
Iteration : 946
The accuracy of training : 0.610000014305
The loss of the training : 1.09063231945
Iteration : 947
The accuracy of training : 0.616999983788
The loss of the training : 1.12943530083
Iteration : 948
The accuracy of training : 0.630999982357
The loss of the training : 1.05281853676
Iteration : 949
The accuracy of training : 0.616999983788
The loss of the training : 1.08900463581
Iteration : 950
The accuracy of training : 0.603999972343
The loss of the training : 1.11867141724
Iteration : 951
The accuracy of training : 0.611000001431
The loss of the training : 1.13269460201
Iteration : 952
The accuracy of training : 0.592000007629
The loss of the training : 1.19659972191
Iteration : 953
The accuracy of training : 0.556999981403
The loss of the training : 1.2629160881
Iteration : 954
The accuracy of training : 0.60900002718
The loss of the training : 1.10162591934
Iteration : 955
The accuracy of training : 0.625
The loss of the training : 1.09506082535
Iteration : 956
The accuracy of training : 0.657000005245
The loss of the training : 1.05463337898
Iteration : 957
The accuracy of training : 0.606000006199
The loss of the training : 1.10393571854
Iteration : 958
The accuracy of training : 0.629999995232
The loss of the training : 1.07663309574
Iteration : 959
The accuracy of training : 0.625
The loss of the training : 1.08766460419
Iteration : 960
The accuracy of training : 0.623000025749
The loss of the training : 1.09299349785
Iteration : 961
The accuracy of training : 0.657000005245
The loss of the training : 1.0272012949
Iteration : 962
The accuracy of training : 0.64200001955
The loss of the training : 1.02000486851
Iteration : 963
The accuracy of training : 0.632000029087
The loss of the training : 1.07937288284
Iteration : 964
The accuracy of training : 0.615999996662
The loss of the training : 1.06941235065
Iteration : 965
The accuracy of training : 0.615000009537
The loss of the training : 1.09548056126
Iteration : 966
The accuracy of training : 0.575999975204
The loss of the training : 1.12726080418
Iteration : 967
The accuracy of training : 0.574000000954
The loss of the training : 1.16124033928
Iteration : 968
The accuracy of training : 0.589999973774
The loss of the training : 1.16309916973
Iteration : 969
The accuracy of training : 0.568000018597
The loss of the training : 1.16200935841
Iteration : 970
The accuracy of training : 0.584999978542
The loss of the training : 1.18626487255
Iteration : 971
The accuracy of training : 0.615999996662
The loss of the training : 1.11168730259
Iteration : 972
The accuracy of training : 0.59399998188
The loss of the training : 1.16247940063
Iteration : 973
The accuracy of training : 0.615999996662
The loss of the training : 1.11604940891
Iteration : 974
The accuracy of training : 0.60900002718
The loss of the training : 1.13158905506
Iteration : 975
The accuracy of training : 0.573000013828
The loss of the training : 1.18704140186
Iteration : 976
The accuracy of training : 0.606000006199
The loss of the training : 1.13803207874
Iteration : 977
The accuracy of training : 0.620999991894
The loss of the training : 1.05402815342
Iteration : 978
The accuracy of training : 0.611999988556
The loss of the training : 1.10762429237
Iteration : 979
The accuracy of training : 0.60799998045
The loss of the training : 1.12872755527
Iteration : 980
The accuracy of training : 0.603999972343
The loss of the training : 1.12948524952
Iteration : 981
The accuracy of training : 0.611999988556
The loss of the training : 1.11202085018
Iteration : 982
The accuracy of training : 0.619000017643
The loss of the training : 1.11305737495
Iteration : 983
The accuracy of training : 0.629999995232
The loss of the training : 1.05099105835
Iteration : 984
The accuracy of training : 0.606999993324
The loss of the training : 1.11777245998
Iteration : 985
The accuracy of training : 0.620999991894
The loss of the training : 1.12961781025
Iteration : 986
The accuracy of training : 0.611000001431
The loss of the training : 1.10412251949
Iteration : 987
The accuracy of training : 0.602999985218
The loss of the training : 1.12304902077
Iteration : 988
The accuracy of training : 0.635999977589
The loss of the training : 1.03578555584
Iteration : 989
The accuracy of training : 0.630999982357
The loss of the training : 1.07362556458
Iteration : 990
The accuracy of training : 0.612999975681
The loss of the training : 1.09424161911
Iteration : 991
The accuracy of training : 0.629999995232
The loss of the training : 1.10225105286
Iteration : 992
The accuracy of training : 0.611999988556
The loss of the training : 1.13930177689
Iteration : 993
The accuracy of training : 0.574000000954
The loss of the training : 1.18585109711
Iteration : 994
The accuracy of training : 0.620000004768
The loss of the training : 1.09999513626
Iteration : 995
The accuracy of training : 0.60900002718
The loss of the training : 1.10549438
Iteration : 996
The accuracy of training : 0.648000001907
The loss of the training : 1.060095191
Iteration : 997
The accuracy of training : 0.611000001431
The loss of the training : 1.11916017532
Iteration : 998
The accuracy of training : 0.620999991894
The loss of the training : 1.08686125278
Iteration : 999
The accuracy of training : 0.611000001431
The loss of the training : 1.09788739681
Iteration : 1000
The accuracy of training : 0.601999998093
The loss of the training : 1.1104272604
Iteration : 1001
The accuracy of training : 0.639999985695
The loss of the training : 1.06418001652
Iteration : 1002
The accuracy of training : 0.615000009537
The loss of the training : 1.06102287769
Iteration : 1003
The accuracy of training : 0.606000006199
The loss of the training : 1.12148237228
Iteration : 1004
The accuracy of training : 0.620999991894
The loss of the training : 1.08419823647
Iteration : 1005
The accuracy of training : 0.619000017643
The loss of the training : 1.08485817909
Iteration : 1006
The accuracy of training : 0.60900002718
The loss of the training : 1.06045103073
Iteration : 1007
The accuracy of training : 0.616999983788
The loss of the training : 1.08256745338
Iteration : 1008
The accuracy of training : 0.643000006676
The loss of the training : 1.05785381794
Iteration : 1009
The accuracy of training : 0.616999983788
The loss of the training : 1.09848976135
Iteration : 1010
The accuracy of training : 0.587000012398
The loss of the training : 1.16110086441
Iteration : 1011
The accuracy of training : 0.603999972343
The loss of the training : 1.1337338686
Iteration : 1012
The accuracy of training : 0.591000020504
The loss of the training : 1.1553760767
Iteration : 1013
The accuracy of training : 0.611999988556
The loss of the training : 1.10487127304
Iteration : 1014
The accuracy of training : 0.60900002718
The loss of the training : 1.12298977375
Iteration : 1015
The accuracy of training : 0.575999975204
The loss of the training : 1.18496370316
Iteration : 1016
The accuracy of training : 0.610000014305
The loss of the training : 1.13490247726
Iteration : 1017
The accuracy of training : 0.620000004768
The loss of the training : 1.04054546356
Iteration : 1018
The accuracy of training : 0.616999983788
The loss of the training : 1.08796739578
Iteration : 1019
The accuracy of training : 0.615999996662
The loss of the training : 1.09828567505
Iteration : 1020
The accuracy of training : 0.625999987125
The loss of the training : 1.08781063557
Iteration : 1021
The accuracy of training : 0.635999977589
The loss of the training : 1.062317729
Iteration : 1022
The accuracy of training : 0.634000003338
The loss of the training : 1.0652102232
Iteration : 1023
The accuracy of training : 0.649999976158
The loss of the training : 1.00427484512
Iteration : 1024
The accuracy of training : 0.638000011444
The loss of the training : 1.05614745617
Iteration : 1025
The accuracy of training : 0.620000004768
The loss of the training : 1.08030831814
Iteration : 1026
The accuracy of training : 0.621999979019
The loss of the training : 1.06727325916
Iteration : 1027
The accuracy of training : 0.619000017643
The loss of the training : 1.08803403378
Iteration : 1028
The accuracy of training : 0.634000003338
The loss of the training : 1.01424062252
Iteration : 1029
The accuracy of training : 0.620999991894
The loss of the training : 1.06303751469
Iteration : 1030
The accuracy of training : 0.615999996662
The loss of the training : 1.07703566551
Iteration : 1031
The accuracy of training : 0.625999987125
The loss of the training : 1.09598457813
Iteration : 1032
The accuracy of training : 0.606999993324
The loss of the training : 1.13519394398
Iteration : 1033
The accuracy of training : 0.591000020504
The loss of the training : 1.16808152199
Iteration : 1034
The accuracy of training : 0.628000020981
The loss of the training : 1.09445881844
Iteration : 1035
The accuracy of training : 0.601000010967
The loss of the training : 1.10811567307
Iteration : 1036
The accuracy of training : 0.646000027657
The loss of the training : 1.05740296841
Iteration : 1037
The accuracy of training : 0.620999991894
The loss of the training : 1.108548522
Iteration : 1038
The accuracy of training : 0.635999977589
The loss of the training : 1.07849657536
Iteration : 1039
The accuracy of training : 0.625999987125
The loss of the training : 1.08530461788
Iteration : 1040
The accuracy of training : 0.60799998045
The loss of the training : 1.11077690125
Iteration : 1041
The accuracy of training : 0.620999991894
The loss of the training : 1.098133564
Iteration : 1042
The accuracy of training : 0.603999972343
The loss of the training : 1.1042277813
Iteration : 1043
The accuracy of training : 0.60799998045
The loss of the training : 1.12449228764
Iteration : 1044
The accuracy of training : 0.611999988556
The loss of the training : 1.10987555981
Iteration : 1045
The accuracy of training : 0.588999986649
The loss of the training : 1.1190032959
Iteration : 1046
The accuracy of training : 0.59399998188
The loss of the training : 1.10783541203
Iteration : 1047
The accuracy of training : 0.601000010967
The loss of the training : 1.10998511314
Iteration : 1048
The accuracy of training : 0.615999996662
The loss of the training : 1.07351636887
Iteration : 1049
The accuracy of training : 0.602999985218
The loss of the training : 1.09658396244
Iteration : 1050
The accuracy of training : 0.597000002861
The loss of the training : 1.14585208893
Iteration : 1051
The accuracy of training : 0.624000012875
The loss of the training : 1.0949729681
Iteration : 1052
The accuracy of training : 0.606000006199
The loss of the training : 1.11806643009
Iteration : 1053
The accuracy of training : 0.629999995232
The loss of the training : 1.06059741974
Iteration : 1054
The accuracy of training : 0.633000016212
The loss of the training : 1.07411932945
Iteration : 1055
The accuracy of training : 0.59399998188
The loss of the training : 1.13046956062
Iteration : 1056
The accuracy of training : 0.621999979019
The loss of the training : 1.08028960228
Iteration : 1057
The accuracy of training : 0.658999979496
The loss of the training : 0.995007872581
Iteration : 1058
The accuracy of training : 0.634999990463
The loss of the training : 1.0571744442
Iteration : 1059
The accuracy of training : 0.621999979019
The loss of the training : 1.07407951355
Iteration : 1060
The accuracy of training : 0.620000004768
The loss of the training : 1.06705224514
Iteration : 1061
The accuracy of training : 0.634000003338
The loss of the training : 1.04973757267
Iteration : 1062
The accuracy of training : 0.635999977589
The loss of the training : 1.05864667892
Iteration : 1063
The accuracy of training : 0.651000022888
The loss of the training : 1.00229609013
Iteration : 1064
The accuracy of training : 0.638999998569
The loss of the training : 1.04562842846
Iteration : 1065
The accuracy of training : 0.628000020981
The loss of the training : 1.06413543224
Iteration : 1066
The accuracy of training : 0.630999982357
The loss of the training : 1.041416049
Iteration : 1067
The accuracy of training : 0.630999982357
The loss of the training : 1.05902516842
Iteration : 1068
The accuracy of training : 0.643999993801
The loss of the training : 0.981770217419
Iteration : 1069
The accuracy of training : 0.635999977589
The loss of the training : 1.03132987022
Iteration : 1070
The accuracy of training : 0.623000025749
The loss of the training : 1.06386566162
Iteration : 1071
The accuracy of training : 0.632000029087
The loss of the training : 1.09869158268
Iteration : 1072
The accuracy of training : 0.596000015736
The loss of the training : 1.17202103138
Iteration : 1073
The accuracy of training : 0.575999975204
The loss of the training : 1.20787405968
Iteration : 1074
The accuracy of training : 0.619000017643
The loss of the training : 1.0930980444
Iteration : 1075
The accuracy of training : 0.616999983788
The loss of the training : 1.07241392136
Iteration : 1076
The accuracy of training : 0.651000022888
The loss of the training : 1.0276902914
Iteration : 1077
The accuracy of training : 0.611000001431
The loss of the training : 1.10235571861
Iteration : 1078
The accuracy of training : 0.634000003338
The loss of the training : 1.07205677032
Iteration : 1079
The accuracy of training : 0.621999979019
The loss of the training : 1.08725762367
Iteration : 1080
The accuracy of training : 0.598999977112
The loss of the training : 1.09443771839
Iteration : 1081
The accuracy of training : 0.626999974251
The loss of the training : 1.04861056805
Iteration : 1082
The accuracy of training : 0.625999987125
The loss of the training : 1.04517579079
Iteration : 1083
The accuracy of training : 0.620999991894
The loss of the training : 1.08217358589
Iteration : 1084
The accuracy of training : 0.623000025749
The loss of the training : 1.06923007965
Iteration : 1085
The accuracy of training : 0.619000017643
The loss of the training : 1.07019531727
Iteration : 1086
The accuracy of training : 0.620000004768
The loss of the training : 1.04653871059
Iteration : 1087
The accuracy of training : 0.633000016212
The loss of the training : 1.061632514
Iteration : 1088
The accuracy of training : 0.626999974251
The loss of the training : 1.04651367664
Iteration : 1089
The accuracy of training : 0.606000006199
The loss of the training : 1.09682691097
Iteration : 1090
The accuracy of training : 0.592999994755
The loss of the training : 1.15854716301
Iteration : 1091
The accuracy of training : 0.614000022411
The loss of the training : 1.12558114529
Iteration : 1092
The accuracy of training : 0.605000019073
The loss of the training : 1.11053085327
Iteration : 1093
The accuracy of training : 0.638999998569
The loss of the training : 1.04626333714
Iteration : 1094
The accuracy of training : 0.643000006676
The loss of the training : 1.06123220921
Iteration : 1095
The accuracy of training : 0.605000019073
The loss of the training : 1.11740899086
Iteration : 1096
The accuracy of training : 0.633000016212
The loss of the training : 1.06344711781
Iteration : 1097
The accuracy of training : 0.663999974728
The loss of the training : 0.988696336746
Iteration : 1098
The accuracy of training : 0.638000011444
The loss of the training : 1.06108403206
Iteration : 1099
The accuracy of training : 0.615999996662
The loss of the training : 1.08228027821
Iteration : 1100
The accuracy of training : 0.619000017643
The loss of the training : 1.07721936703
Iteration : 1101
The accuracy of training : 0.620999991894
The loss of the training : 1.07705128193
Iteration : 1102
The accuracy of training : 0.620999991894
The loss of the training : 1.09606862068
Iteration : 1103
The accuracy of training : 0.647000014782
The loss of the training : 0.997033119202
Iteration : 1104
The accuracy of training : 0.647000014782
The loss of the training : 1.03457927704
Iteration : 1105
The accuracy of training : 0.632000029087
The loss of the training : 1.04462480545
Iteration : 1106
The accuracy of training : 0.628000020981
The loss of the training : 1.01950860023
Iteration : 1107
The accuracy of training : 0.634000003338
The loss of the training : 1.0516037941
Iteration : 1108
The accuracy of training : 0.652999997139
The loss of the training : 0.98001909256
Iteration : 1109
The accuracy of training : 0.630999982357
The loss of the training : 1.02886378765
Iteration : 1110
The accuracy of training : 0.633000016212
The loss of the training : 1.04900324345
Iteration : 1111
The accuracy of training : 0.64200001955
The loss of the training : 1.06704854965
Iteration : 1112
The accuracy of training : 0.617999970913
The loss of the training : 1.11975693703
Iteration : 1113
The accuracy of training : 0.591000020504
The loss of the training : 1.16073179245
Iteration : 1114
The accuracy of training : 0.620999991894
The loss of the training : 1.07970106602
Iteration : 1115
The accuracy of training : 0.619000017643
The loss of the training : 1.07459867001
Iteration : 1116
The accuracy of training : 0.649999976158
The loss of the training : 1.02736210823
Iteration : 1117
The accuracy of training : 0.617999970913
The loss of the training : 1.09916138649
Iteration : 1118
The accuracy of training : 0.638000011444
The loss of the training : 1.05366039276
Iteration : 1119
The accuracy of training : 0.626999974251
The loss of the training : 1.05932474136
Iteration : 1120
The accuracy of training : 0.616999983788
The loss of the training : 1.05626571178
Iteration : 1121
The accuracy of training : 0.657000005245
The loss of the training : 0.990903615952
Iteration : 1122
The accuracy of training : 0.648000001907
The loss of the training : 0.987347364426
Iteration : 1123
The accuracy of training : 0.634999990463
The loss of the training : 1.04960036278
Iteration : 1124
The accuracy of training : 0.635999977589
The loss of the training : 1.04670834541
Iteration : 1125
The accuracy of training : 0.621999979019
The loss of the training : 1.05712401867
Iteration : 1126
The accuracy of training : 0.628000020981
The loss of the training : 1.0354334116
Iteration : 1127
The accuracy of training : 0.625999987125
The loss of the training : 1.04759967327
Iteration : 1128
The accuracy of training : 0.660000026226
The loss of the training : 1.0116904974
Iteration : 1129
The accuracy of training : 0.638999998569
The loss of the training : 1.02945590019
Iteration : 1130
The accuracy of training : 0.64099997282
The loss of the training : 1.08689200878
Iteration : 1131
The accuracy of training : 0.634999990463
The loss of the training : 1.04831898212
Iteration : 1132
The accuracy of training : 0.624000012875
The loss of the training : 1.09241437912
Iteration : 1133
The accuracy of training : 0.634999990463
The loss of the training : 1.04172158241
Iteration : 1134
The accuracy of training : 0.633000016212
The loss of the training : 1.07104313374
Iteration : 1135
The accuracy of training : 0.586000025272
The loss of the training : 1.13660681248
Iteration : 1136
The accuracy of training : 0.612999975681
The loss of the training : 1.10977423191
Iteration : 1137
The accuracy of training : 0.648000001907
The loss of the training : 0.997831702232
Iteration : 1138
The accuracy of training : 0.633000016212
The loss of the training : 1.06148838997
Iteration : 1139
The accuracy of training : 0.620999991894
The loss of the training : 1.08595907688
Iteration : 1140
The accuracy of training : 0.59399998188
The loss of the training : 1.12035429478
Iteration : 1141
The accuracy of training : 0.615999996662
The loss of the training : 1.09091150761
Iteration : 1142
The accuracy of training : 0.617999970913
The loss of the training : 1.08696293831
Iteration : 1143
The accuracy of training : 0.644999980927
The loss of the training : 0.994836449623
Iteration : 1144
The accuracy of training : 0.646000027657
The loss of the training : 1.02066159248
Iteration : 1145
The accuracy of training : 0.643999993801
The loss of the training : 1.04282033443
Iteration : 1146
The accuracy of training : 0.638999998569
The loss of the training : 1.02994525433
Iteration : 1147
The accuracy of training : 0.625
The loss of the training : 1.06266951561
Iteration : 1148
The accuracy of training : 0.652999997139
The loss of the training : 0.98685002327
Iteration : 1149
The accuracy of training : 0.626999974251
The loss of the training : 1.03331661224
Iteration : 1150
The accuracy of training : 0.638000011444
The loss of the training : 1.05219852924
Iteration : 1151
The accuracy of training : 0.64099997282
The loss of the training : 1.06249272823
Iteration : 1152
The accuracy of training : 0.635999977589
The loss of the training : 1.10302913189
Iteration : 1153
The accuracy of training : 0.605000019073
The loss of the training : 1.14688336849
Iteration : 1154
The accuracy of training : 0.625
The loss of the training : 1.08265972137
Iteration : 1155
The accuracy of training : 0.620999991894
The loss of the training : 1.07347023487
Iteration : 1156
The accuracy of training : 0.660000026226
The loss of the training : 1.02316498756
Iteration : 1157
The accuracy of training : 0.624000012875
The loss of the training : 1.08196675777
Iteration : 1158
The accuracy of training : 0.646000027657
The loss of the training : 1.02857160568
Iteration : 1159
The accuracy of training : 0.633000016212
The loss of the training : 1.02634775639
Iteration : 1160
The accuracy of training : 0.638000011444
The loss of the training : 1.02167654037
Iteration : 1161
The accuracy of training : 0.663999974728
The loss of the training : 0.976112186909
Iteration : 1162
The accuracy of training : 0.657000005245
The loss of the training : 0.971610546112
Iteration : 1163
The accuracy of training : 0.634999990463
The loss of the training : 1.02413749695
Iteration : 1164
The accuracy of training : 0.639999985695
The loss of the training : 1.02262604237
Iteration : 1165
The accuracy of training : 0.639999985695
The loss of the training : 1.03089654446
Iteration : 1166
The accuracy of training : 0.638999998569
The loss of the training : 1.00945651531
Iteration : 1167
The accuracy of training : 0.639999985695
The loss of the training : 1.02497565746
Iteration : 1168
The accuracy of training : 0.666999995708
The loss of the training : 0.986272454262
Iteration : 1169
The accuracy of training : 0.652999997139
The loss of the training : 1.00867784023
Iteration : 1170
The accuracy of training : 0.626999974251
The loss of the training : 1.08751571178
Iteration : 1171
The accuracy of training : 0.630999982357
The loss of the training : 1.04123973846
Iteration : 1172
The accuracy of training : 0.619000017643
The loss of the training : 1.0869603157
Iteration : 1173
The accuracy of training : 0.625999987125
The loss of the training : 1.06207084656
Iteration : 1174
The accuracy of training : 0.617999970913
The loss of the training : 1.080991745
Iteration : 1175
The accuracy of training : 0.580999970436
The loss of the training : 1.15743708611
Iteration : 1176
The accuracy of training : 0.620999991894
The loss of the training : 1.09621953964
Iteration : 1177
The accuracy of training : 0.64099997282
The loss of the training : 0.994549691677
Iteration : 1178
The accuracy of training : 0.633000016212
The loss of the training : 1.05677294731
Iteration : 1179
The accuracy of training : 0.634999990463
The loss of the training : 1.05206084251
Iteration : 1180
The accuracy of training : 0.638000011444
The loss of the training : 1.03507447243
Iteration : 1181
The accuracy of training : 0.637000024319
The loss of the training : 1.01658320427
Iteration : 1182
The accuracy of training : 0.652000010014
The loss of the training : 1.02042448521
Iteration : 1183
The accuracy of training : 0.662000000477
The loss of the training : 0.96056830883
Iteration : 1184
The accuracy of training : 0.646000027657
The loss of the training : 1.01055681705
Iteration : 1185
The accuracy of training : 0.628000020981
The loss of the training : 1.03751540184
Iteration : 1186
The accuracy of training : 0.630999982357
The loss of the training : 1.01383018494
Iteration : 1187
The accuracy of training : 0.634000003338
The loss of the training : 1.03715634346
Iteration : 1188
The accuracy of training : 0.652000010014
The loss of the training : 0.966099917889
Iteration : 1189
The accuracy of training : 0.634000003338
The loss of the training : 1.01025903225
Iteration : 1190
The accuracy of training : 0.634999990463
The loss of the training : 1.03382456303
Iteration : 1191
The accuracy of training : 0.649999976158
The loss of the training : 1.0452555418
Iteration : 1192
The accuracy of training : 0.643999993801
The loss of the training : 1.08748269081
Iteration : 1193
The accuracy of training : 0.606999993324
The loss of the training : 1.11647367477
Iteration : 1194
The accuracy of training : 0.625999987125
The loss of the training : 1.04958486557
Iteration : 1195
The accuracy of training : 0.620000004768
The loss of the training : 1.06850445271
Iteration : 1196
The accuracy of training : 0.652000010014
The loss of the training : 1.03703391552
Iteration : 1197
The accuracy of training : 0.612999975681
The loss of the training : 1.12138032913
Iteration : 1198
The accuracy of training : 0.64099997282
The loss of the training : 1.07064926624
Iteration : 1199
The accuracy of training : 0.623000025749
The loss of the training : 1.03347373009
Iteration : 1200
The accuracy of training : 0.635999977589
The loss of the training : 1.0282086134
Iteration : 1201
The accuracy of training : 0.658999979496
The loss of the training : 0.980477154255
Iteration : 1202
The accuracy of training : 0.663999974728
The loss of the training : 0.975088894367
Iteration : 1203
The accuracy of training : 0.638999998569
The loss of the training : 1.00946033001
Iteration : 1204
The accuracy of training : 0.64099997282
The loss of the training : 1.01536095142
Iteration : 1205
The accuracy of training : 0.638999998569
The loss of the training : 1.0209594965
Iteration : 1206
The accuracy of training : 0.64099997282
The loss of the training : 1.00855624676
Iteration : 1207
The accuracy of training : 0.646000027657
The loss of the training : 1.02421784401
Iteration : 1208
The accuracy of training : 0.671000003815
The loss of the training : 0.983307123184
Iteration : 1209
The accuracy of training : 0.648000001907
The loss of the training : 1.01298594475
Iteration : 1210
The accuracy of training : 0.625
The loss of the training : 1.08270215988
Iteration : 1211
The accuracy of training : 0.64099997282
The loss of the training : 1.03139317036
Iteration : 1212
The accuracy of training : 0.625
The loss of the training : 1.06929719448
Iteration : 1213
The accuracy of training : 0.64200001955
The loss of the training : 1.03740310669
Iteration : 1214
The accuracy of training : 0.637000024319
The loss of the training : 1.04913532734
Iteration : 1215
The accuracy of training : 0.597999989986
The loss of the training : 1.11785888672
Iteration : 1216
The accuracy of training : 0.620999991894
The loss of the training : 1.07767140865
Iteration : 1217
The accuracy of training : 0.662000000477
The loss of the training : 0.97047752142
Iteration : 1218
The accuracy of training : 0.647000014782
The loss of the training : 1.03846311569
Iteration : 1219
The accuracy of training : 0.637000024319
The loss of the training : 1.04394936562
Iteration : 1220
The accuracy of training : 0.633000016212
The loss of the training : 1.02816212177
Iteration : 1221
The accuracy of training : 0.638000011444
The loss of the training : 1.01472973824
Iteration : 1222
The accuracy of training : 0.652999997139
The loss of the training : 1.01804947853
Iteration : 1223
The accuracy of training : 0.670000016689
The loss of the training : 0.954112946987
Iteration : 1224
The accuracy of training : 0.652000010014
The loss of the training : 0.999018192291
Iteration : 1225
The accuracy of training : 0.638999998569
The loss of the training : 1.0224660635
Iteration : 1226
The accuracy of training : 0.639999985695
The loss of the training : 0.993384838104
Iteration : 1227
The accuracy of training : 0.646000027657
The loss of the training : 1.01635456085
Iteration : 1228
The accuracy of training : 0.661000013351
The loss of the training : 0.945998191833
Iteration : 1229
The accuracy of training : 0.646000027657
The loss of the training : 0.989288210869
Iteration : 1230
The accuracy of training : 0.648999989033
The loss of the training : 1.01075839996
Iteration : 1231
The accuracy of training : 0.660000026226
The loss of the training : 1.02333188057
Iteration : 1232
The accuracy of training : 0.639999985695
The loss of the training : 1.06716895103
Iteration : 1233
The accuracy of training : 0.611999988556
The loss of the training : 1.09514522552
Iteration : 1234
The accuracy of training : 0.651000022888
The loss of the training : 1.0050740242
Iteration : 1235
The accuracy of training : 0.657000005245
The loss of the training : 1.00624096394
Iteration : 1236
The accuracy of training : 0.680000007153
The loss of the training : 0.958695530891
Iteration : 1237
The accuracy of training : 0.630999982357
The loss of the training : 1.02367854118
Iteration : 1238
The accuracy of training : 0.674000024796
The loss of the training : 0.983159601688
Iteration : 1239
The accuracy of training : 0.638000011444
The loss of the training : 1.00650656223
Iteration : 1240
The accuracy of training : 0.646000027657
The loss of the training : 1.00750172138
Iteration : 1241
The accuracy of training : 0.676999986172
The loss of the training : 0.962204515934
Iteration : 1242
The accuracy of training : 0.666000008583
The loss of the training : 0.957085847855
Iteration : 1243
The accuracy of training : 0.649999976158
The loss of the training : 1.01999557018
Iteration : 1244
The accuracy of training : 0.632000029087
The loss of the training : 1.01341557503
Iteration : 1245
The accuracy of training : 0.64099997282
The loss of the training : 1.03237020969
Iteration : 1246
The accuracy of training : 0.619000017643
The loss of the training : 1.03124916553
Iteration : 1247
The accuracy of training : 0.626999974251
The loss of the training : 1.07214927673
Iteration : 1248
The accuracy of training : 0.65499997139
The loss of the training : 1.01359641552
Iteration : 1249
The accuracy of training : 0.620000004768
The loss of the training : 1.06999146938
Iteration : 1250
The accuracy of training : 0.603999972343
The loss of the training : 1.15310657024
Iteration : 1251
The accuracy of training : 0.615000009537
The loss of the training : 1.0870115757
Iteration : 1252
The accuracy of training : 0.625999987125
The loss of the training : 1.1100987196
Iteration : 1253
The accuracy of training : 0.620000004768
The loss of the training : 1.06666827202
Iteration : 1254
The accuracy of training : 0.628000020981
The loss of the training : 1.06817686558
Iteration : 1255
The accuracy of training : 0.601999998093
The loss of the training : 1.11426091194
Iteration : 1256
The accuracy of training : 0.630999982357
The loss of the training : 1.0589287281
Iteration : 1257
The accuracy of training : 0.657999992371
The loss of the training : 0.95228433609
Iteration : 1258
The accuracy of training : 0.657000005245
The loss of the training : 1.00745880604
Iteration : 1259
The accuracy of training : 0.647000014782
The loss of the training : 1.01394999027
Iteration : 1260
The accuracy of training : 0.649999976158
The loss of the training : 1.0061391592
Iteration : 1261
The accuracy of training : 0.651000022888
The loss of the training : 0.996526241302
Iteration : 1262
The accuracy of training : 0.657999992371
The loss of the training : 0.99982714653
Iteration : 1263
The accuracy of training : 0.680999994278
The loss of the training : 0.938951849937
Iteration : 1264
The accuracy of training : 0.657999992371
The loss of the training : 0.982421040535
Iteration : 1265
The accuracy of training : 0.651000022888
The loss of the training : 1.00126135349
Iteration : 1266
The accuracy of training : 0.648000001907
The loss of the training : 0.977403223515
Iteration : 1267
The accuracy of training : 0.648999989033
The loss of the training : 1.00581741333
Iteration : 1268
The accuracy of training : 0.667999982834
The loss of the training : 0.934905230999
Iteration : 1269
The accuracy of training : 0.658999979496
The loss of the training : 0.981532752514
Iteration : 1270
The accuracy of training : 0.651000022888
The loss of the training : 0.999162971973
Iteration : 1271
The accuracy of training : 0.662999987602
The loss of the training : 1.01067209244
Iteration : 1272
The accuracy of training : 0.64099997282
The loss of the training : 1.05121350288
Iteration : 1273
The accuracy of training : 0.617999970913
The loss of the training : 1.08194315434
Iteration : 1274
The accuracy of training : 0.652000010014
The loss of the training : 0.993606090546
Iteration : 1275
The accuracy of training : 0.665000021458
The loss of the training : 1.00106048584
Iteration : 1276
The accuracy of training : 0.685000002384
The loss of the training : 0.952791929245
Iteration : 1277
The accuracy of training : 0.634999990463
The loss of the training : 1.01546013355
Iteration : 1278
The accuracy of training : 0.674000024796
The loss of the training : 0.97774964571
Iteration : 1279
The accuracy of training : 0.644999980927
The loss of the training : 1.00479757786
Iteration : 1280
The accuracy of training : 0.648999989033
The loss of the training : 1.00032281876
Iteration : 1281
The accuracy of training : 0.680999994278
The loss of the training : 0.953130662441
Iteration : 1282
The accuracy of training : 0.670000016689
The loss of the training : 0.941930949688
Iteration : 1283
The accuracy of training : 0.652000010014
The loss of the training : 0.993701279163
Iteration : 1284
The accuracy of training : 0.649999976158
The loss of the training : 0.976459383965
Iteration : 1285
The accuracy of training : 0.667999982834
The loss of the training : 0.985405087471
Iteration : 1286
The accuracy of training : 0.638999998569
The loss of the training : 0.987554252148
Iteration : 1287
The accuracy of training : 0.648000001907
The loss of the training : 1.0072927475
Iteration : 1288
The accuracy of training : 0.660000026226
The loss of the training : 0.97579485178
Iteration : 1289
The accuracy of training : 0.638000011444
The loss of the training : 1.0219669342
Iteration : 1290
The accuracy of training : 0.615000009537
The loss of the training : 1.0925719738
Iteration : 1291
The accuracy of training : 0.628000020981
The loss of the training : 1.06112456322
Iteration : 1292
The accuracy of training : 0.628000020981
The loss of the training : 1.06892037392
Iteration : 1293
The accuracy of training : 0.652999997139
The loss of the training : 1.00844919682
Iteration : 1294
The accuracy of training : 0.643999993801
The loss of the training : 1.01991927624
Iteration : 1295
The accuracy of training : 0.597000002861
The loss of the training : 1.09615707397
Iteration : 1296
The accuracy of training : 0.632000029087
The loss of the training : 1.06545996666
Iteration : 1297
The accuracy of training : 0.671000003815
The loss of the training : 0.946659982204
Iteration : 1298
The accuracy of training : 0.651000022888
The loss of the training : 1.0173188448
Iteration : 1299
The accuracy of training : 0.64099997282
The loss of the training : 1.02737772465
Iteration : 1300
The accuracy of training : 0.64200001955
The loss of the training : 1.00896084309
Iteration : 1301
The accuracy of training : 0.637000024319
The loss of the training : 1.00486528873
Iteration : 1302
The accuracy of training : 0.65600001812
The loss of the training : 1.00864696503
Iteration : 1303
The accuracy of training : 0.681999981403
The loss of the training : 0.940057516098
Iteration : 1304
The accuracy of training : 0.667999982834
The loss of the training : 0.981741547585
Iteration : 1305
The accuracy of training : 0.647000014782
The loss of the training : 0.998997807503
Iteration : 1306
The accuracy of training : 0.649999976158
The loss of the training : 0.969144761562
Iteration : 1307
The accuracy of training : 0.653999984264
The loss of the training : 0.998934805393
Iteration : 1308
The accuracy of training : 0.671000003815
The loss of the training : 0.933434605598
Iteration : 1309
The accuracy of training : 0.660000026226
The loss of the training : 0.979404807091
Iteration : 1310
The accuracy of training : 0.649999976158
The loss of the training : 0.995701372623
Iteration : 1311
The accuracy of training : 0.661000013351
The loss of the training : 1.00223600864
Iteration : 1312
The accuracy of training : 0.64200001955
The loss of the training : 1.04376125336
Iteration : 1313
The accuracy of training : 0.619000017643
The loss of the training : 1.07620704174
Iteration : 1314
The accuracy of training : 0.653999984264
The loss of the training : 0.98541790247
Iteration : 1315
The accuracy of training : 0.657999992371
The loss of the training : 0.998433113098
Iteration : 1316
The accuracy of training : 0.683000028133
The loss of the training : 0.951302528381
Iteration : 1317
The accuracy of training : 0.643000006676
The loss of the training : 1.00633561611
Iteration : 1318
The accuracy of training : 0.670000016689
The loss of the training : 0.966326951981
Iteration : 1319
The accuracy of training : 0.648999989033
The loss of the training : 0.99026542902
Iteration : 1320
The accuracy of training : 0.65600001812
The loss of the training : 0.98304605484
Iteration : 1321
The accuracy of training : 0.690999984741
The loss of the training : 0.938443362713
Iteration : 1322
The accuracy of training : 0.686999976635
The loss of the training : 0.927044212818
Iteration : 1323
The accuracy of training : 0.657000005245
The loss of the training : 0.975805521011
Iteration : 1324
The accuracy of training : 0.662000000477
The loss of the training : 0.968671739101
Iteration : 1325
The accuracy of training : 0.661000013351
The loss of the training : 0.979580640793
Iteration : 1326
The accuracy of training : 0.638999998569
The loss of the training : 0.980678498745
Iteration : 1327
The accuracy of training : 0.661000013351
The loss of the training : 1.0063123703
Iteration : 1328
The accuracy of training : 0.67199999094
The loss of the training : 0.964819133282
Iteration : 1329
The accuracy of training : 0.643000006676
The loss of the training : 1.01032555103
Iteration : 1330
The accuracy of training : 0.615000009537
The loss of the training : 1.12027382851
Iteration : 1331
The accuracy of training : 0.620999991894
The loss of the training : 1.08197903633
Iteration : 1332
The accuracy of training : 0.625999987125
The loss of the training : 1.09648907185
Iteration : 1333
The accuracy of training : 0.639999985695
The loss of the training : 1.0248196125
Iteration : 1334
The accuracy of training : 0.647000014782
The loss of the training : 1.02627325058
Iteration : 1335
The accuracy of training : 0.601999998093
The loss of the training : 1.08535981178
Iteration : 1336
The accuracy of training : 0.639999985695
The loss of the training : 1.03872060776
Iteration : 1337
The accuracy of training : 0.667999982834
The loss of the training : 0.933678925037
Iteration : 1338
The accuracy of training : 0.658999979496
The loss of the training : 0.993413150311
Iteration : 1339
The accuracy of training : 0.652999997139
The loss of the training : 0.998101651669
Iteration : 1340
The accuracy of training : 0.65499997139
The loss of the training : 0.985936284065
Iteration : 1341
The accuracy of training : 0.660000026226
The loss of the training : 0.980346620083
Iteration : 1342
The accuracy of training : 0.662000000477
The loss of the training : 0.982823550701
Iteration : 1343
The accuracy of training : 0.680999994278
The loss of the training : 0.923054754734
Iteration : 1344
The accuracy of training : 0.670000016689
The loss of the training : 0.96416670084
Iteration : 1345
The accuracy of training : 0.649999976158
The loss of the training : 0.987723350525
Iteration : 1346
The accuracy of training : 0.657000005245
The loss of the training : 0.960245668888
Iteration : 1347
The accuracy of training : 0.657999992371
The loss of the training : 0.987846851349
Iteration : 1348
The accuracy of training : 0.672999978065
The loss of the training : 0.921503603458
Iteration : 1349
The accuracy of training : 0.658999979496
The loss of the training : 0.96353328228
Iteration : 1350
The accuracy of training : 0.65499997139
The loss of the training : 0.984585106373
Iteration : 1351
The accuracy of training : 0.662999987602
The loss of the training : 0.995218575001
Iteration : 1352
The accuracy of training : 0.648000001907
The loss of the training : 1.03538429737
Iteration : 1353
The accuracy of training : 0.621999979019
The loss of the training : 1.07093882561
Iteration : 1354
The accuracy of training : 0.65499997139
The loss of the training : 0.997474730015
Iteration : 1355
The accuracy of training : 0.644999980927
The loss of the training : 1.00712883472
Iteration : 1356
The accuracy of training : 0.690999984741
The loss of the training : 0.953621268272
Iteration : 1357
The accuracy of training : 0.639999985695
The loss of the training : 1.02059388161
Iteration : 1358
The accuracy of training : 0.665000021458
The loss of the training : 0.975921571255
Iteration : 1359
The accuracy of training : 0.643999993801
The loss of the training : 0.983160674572
Iteration : 1360
The accuracy of training : 0.65600001812
The loss of the training : 0.97554731369
Iteration : 1361
The accuracy of training : 0.686999976635
The loss of the training : 0.932467937469
Iteration : 1362
The accuracy of training : 0.669000029564
The loss of the training : 0.922511398792
Iteration : 1363
The accuracy of training : 0.648000001907
The loss of the training : 0.985896646976
Iteration : 1364
The accuracy of training : 0.661000013351
The loss of the training : 0.980248212814
Iteration : 1365
The accuracy of training : 0.634999990463
The loss of the training : 1.000669837
Iteration : 1366
The accuracy of training : 0.647000014782
The loss of the training : 0.963584005833
Iteration : 1367
The accuracy of training : 0.648999989033
The loss of the training : 0.984638214111
Iteration : 1368
The accuracy of training : 0.679000020027
The loss of the training : 0.947012484074
Iteration : 1369
The accuracy of training : 0.661000013351
The loss of the training : 0.978600800037
Iteration : 1370
The accuracy of training : 0.632000029087
The loss of the training : 1.05396819115
Iteration : 1371
The accuracy of training : 0.638000011444
The loss of the training : 1.02681720257
Iteration : 1372
The accuracy of training : 0.643999993801
The loss of the training : 1.06259191036
Iteration : 1373
The accuracy of training : 0.649999976158
The loss of the training : 1.00560438633
Iteration : 1374
The accuracy of training : 0.64200001955
The loss of the training : 1.01876306534
Iteration : 1375
The accuracy of training : 0.606000006199
The loss of the training : 1.08803522587
Iteration : 1376
The accuracy of training : 0.639999985695
The loss of the training : 1.05029988289
Iteration : 1377
The accuracy of training : 0.680999994278
The loss of the training : 0.935604989529
Iteration : 1378
The accuracy of training : 0.639999985695
The loss of the training : 0.989423751831
Iteration : 1379
The accuracy of training : 0.657999992371
The loss of the training : 0.998955368996
Iteration : 1380
The accuracy of training : 0.648000001907
The loss of the training : 0.986237943172
Iteration : 1381
The accuracy of training : 0.657999992371
The loss of the training : 0.978296339512
Iteration : 1382
The accuracy of training : 0.657000005245
The loss of the training : 0.982139348984
Iteration : 1383
The accuracy of training : 0.681999981403
The loss of the training : 0.922048568726
Iteration : 1384
The accuracy of training : 0.665000021458
The loss of the training : 0.968022346497
Iteration : 1385
The accuracy of training : 0.65600001812
The loss of the training : 0.98840546608
Iteration : 1386
The accuracy of training : 0.65600001812
The loss of the training : 0.965807259083
Iteration : 1387
The accuracy of training : 0.643999993801
The loss of the training : 0.994037270546
Iteration : 1388
The accuracy of training : 0.675999999046
The loss of the training : 0.922205746174
Iteration : 1389
The accuracy of training : 0.670000016689
The loss of the training : 0.968229234219
Iteration : 1390
The accuracy of training : 0.660000026226
The loss of the training : 0.986623704433
Iteration : 1391
The accuracy of training : 0.665000021458
The loss of the training : 0.99431681633
Iteration : 1392
The accuracy of training : 0.643999993801
The loss of the training : 1.02819252014
Iteration : 1393
The accuracy of training : 0.624000012875
The loss of the training : 1.06653475761
Iteration : 1394
The accuracy of training : 0.666000008583
The loss of the training : 0.967962741852
Iteration : 1395
The accuracy of training : 0.663999974728
The loss of the training : 0.981023013592
Iteration : 1396
The accuracy of training : 0.690999984741
The loss of the training : 0.933193385601
Iteration : 1397
The accuracy of training : 0.644999980927
The loss of the training : 0.993139922619
Iteration : 1398
The accuracy of training : 0.679000020027
The loss of the training : 0.952752053738
Iteration : 1399
The accuracy of training : 0.65600001812
The loss of the training : 0.971314847469
Iteration : 1400
The accuracy of training : 0.667999982834
The loss of the training : 0.960687220097
Iteration : 1401
The accuracy of training : 0.695999979973
The loss of the training : 0.915865957737
Iteration : 1402
The accuracy of training : 0.68900001049
The loss of the training : 0.899603903294
Iteration : 1403
The accuracy of training : 0.67199999094
The loss of the training : 0.950729429722
Iteration : 1404
The accuracy of training : 0.662999987602
The loss of the training : 0.946872115135
Iteration : 1405
The accuracy of training : 0.662000000477
The loss of the training : 0.961055755615
Iteration : 1406
The accuracy of training : 0.653999984264
The loss of the training : 0.95213842392
Iteration : 1407
The accuracy of training : 0.661000013351
The loss of the training : 0.979336678982
Iteration : 1408
The accuracy of training : 0.666999995708
The loss of the training : 0.953144609928
Iteration : 1409
The accuracy of training : 0.651000022888
The loss of the training : 0.985535264015
Iteration : 1410
The accuracy of training : 0.625999987125
The loss of the training : 1.04880571365
Iteration : 1411
The accuracy of training : 0.648000001907
The loss of the training : 1.0123591423
Iteration : 1412
The accuracy of training : 0.64200001955
The loss of the training : 1.0475962162
Iteration : 1413
The accuracy of training : 0.65499997139
The loss of the training : 0.97816324234
Iteration : 1414
The accuracy of training : 0.653999984264
The loss of the training : 0.986340522766
Iteration : 1415
The accuracy of training : 0.624000012875
The loss of the training : 1.0352742672
Iteration : 1416
The accuracy of training : 0.657999992371
The loss of the training : 0.990857601166
Iteration : 1417
The accuracy of training : 0.695999979973
The loss of the training : 0.90198636055
Iteration : 1418
The accuracy of training : 0.667999982834
The loss of the training : 0.969922959805
Iteration : 1419
The accuracy of training : 0.660000026226
The loss of the training : 0.98134046793
Iteration : 1420
The accuracy of training : 0.649999976158
The loss of the training : 0.980245351791
Iteration : 1421
The accuracy of training : 0.660000026226
The loss of the training : 0.979462921619
Iteration : 1422
The accuracy of training : 0.666999995708
The loss of the training : 0.986504197121
Iteration : 1423
The accuracy of training : 0.686999976635
The loss of the training : 0.916038155556
Iteration : 1424
The accuracy of training : 0.677999973297
The loss of the training : 0.950036048889
Iteration : 1425
The accuracy of training : 0.662999987602
The loss of the training : 0.967171370983
Iteration : 1426
The accuracy of training : 0.67199999094
The loss of the training : 0.944603323936
Iteration : 1427
The accuracy of training : 0.666999995708
The loss of the training : 0.969840407372
Iteration : 1428
The accuracy of training : 0.680000007153
The loss of the training : 0.902097463608
Iteration : 1429
The accuracy of training : 0.67199999094
The loss of the training : 0.94936388731
Iteration : 1430
The accuracy of training : 0.663999974728
The loss of the training : 0.968010902405
Iteration : 1431
The accuracy of training : 0.665000021458
The loss of the training : 0.977432250977
Iteration : 1432
The accuracy of training : 0.646000027657
The loss of the training : 1.0170340538
Iteration : 1433
The accuracy of training : 0.629999995232
The loss of the training : 1.05550467968
Iteration : 1434
The accuracy of training : 0.658999979496
The loss of the training : 0.964463591576
Iteration : 1435
The accuracy of training : 0.666000008583
The loss of the training : 0.988581895828
Iteration : 1436
The accuracy of training : 0.689999997616
The loss of the training : 0.938417613506
Iteration : 1437
The accuracy of training : 0.648999989033
The loss of the training : 0.999697446823
Iteration : 1438
The accuracy of training : 0.666000008583
The loss of the training : 0.966014444828
Iteration : 1439
The accuracy of training : 0.657999992371
The loss of the training : 0.984594285488
Iteration : 1440
The accuracy of training : 0.65600001812
The loss of the training : 0.97778236866
Iteration : 1441
The accuracy of training : 0.686999976635
The loss of the training : 0.937382638454
Iteration : 1442
The accuracy of training : 0.688000023365
The loss of the training : 0.924398124218
Iteration : 1443
The accuracy of training : 0.65600001812
The loss of the training : 0.959069728851
Iteration : 1444
The accuracy of training : 0.675999999046
The loss of the training : 0.961456656456
Iteration : 1445
The accuracy of training : 0.653999984264
The loss of the training : 0.970720589161
Iteration : 1446
The accuracy of training : 0.661000013351
The loss of the training : 0.954995989799
Iteration : 1447
The accuracy of training : 0.661000013351
The loss of the training : 0.980424582958
Iteration : 1448
The accuracy of training : 0.688000023365
The loss of the training : 0.924299001694
Iteration : 1449
The accuracy of training : 0.670000016689
The loss of the training : 0.959547042847
Iteration : 1450
The accuracy of training : 0.639999985695
The loss of the training : 1.06106507778
Iteration : 1451
The accuracy of training : 0.64200001955
The loss of the training : 1.01255786419
Iteration : 1452
The accuracy of training : 0.639999985695
The loss of the training : 1.02995812893
Iteration : 1453
The accuracy of training : 0.667999982834
The loss of the training : 0.978730261326
Iteration : 1454
The accuracy of training : 0.658999979496
The loss of the training : 0.982746005058
Iteration : 1455
The accuracy of training : 0.616999983788
The loss of the training : 1.04278993607
Iteration : 1456
The accuracy of training : 0.657000005245
The loss of the training : 1.01222133636
Iteration : 1457
The accuracy of training : 0.685000002384
The loss of the training : 0.904815733433
Iteration : 1458
The accuracy of training : 0.661000013351
The loss of the training : 0.972043693066
Iteration : 1459
The accuracy of training : 0.662999987602
The loss of the training : 0.977803051472
Iteration : 1460
The accuracy of training : 0.658999979496
The loss of the training : 0.964170098305
Iteration : 1461
The accuracy of training : 0.665000021458
The loss of the training : 0.956815421581
Iteration : 1462
The accuracy of training : 0.675000011921
The loss of the training : 0.960201323032
Iteration : 1463
The accuracy of training : 0.685000002384
The loss of the training : 0.89814054966
Iteration : 1464
The accuracy of training : 0.677999973297
The loss of the training : 0.93773317337
Iteration : 1465
The accuracy of training : 0.662999987602
The loss of the training : 0.962966859341
Iteration : 1466
The accuracy of training : 0.670000016689
The loss of the training : 0.936196208
Iteration : 1467
The accuracy of training : 0.675999999046
The loss of the training : 0.962086319923
Iteration : 1468
The accuracy of training : 0.68599998951
The loss of the training : 0.897014200687
Iteration : 1469
The accuracy of training : 0.669000029564
The loss of the training : 0.937328875065
Iteration : 1470
The accuracy of training : 0.667999982834
The loss of the training : 0.958480894566
Iteration : 1471
The accuracy of training : 0.683000028133
The loss of the training : 0.964167773724
Iteration : 1472
The accuracy of training : 0.658999979496
The loss of the training : 0.99776494503
Iteration : 1473
The accuracy of training : 0.638999998569
The loss of the training : 1.03331100941
Iteration : 1474
The accuracy of training : 0.657000005245
The loss of the training : 0.970721840858
Iteration : 1475
The accuracy of training : 0.653999984264
The loss of the training : 0.974837958813
Iteration : 1476
The accuracy of training : 0.700999975204
The loss of the training : 0.922853827477
Iteration : 1477
The accuracy of training : 0.644999980927
The loss of the training : 1.00560939312
Iteration : 1478
The accuracy of training : 0.675000011921
The loss of the training : 0.955894947052
Iteration : 1479
The accuracy of training : 0.661000013351
The loss of the training : 0.959223747253
Iteration : 1480
The accuracy of training : 0.65600001812
The loss of the training : 0.957309126854
Iteration : 1481
The accuracy of training : 0.679000020027
The loss of the training : 0.92501360178
Iteration : 1482
The accuracy of training : 0.67199999094
The loss of the training : 0.915306210518
Iteration : 1483
The accuracy of training : 0.661000013351
The loss of the training : 0.952375769615
Iteration : 1484
The accuracy of training : 0.662999987602
The loss of the training : 0.962887823582
Iteration : 1485
The accuracy of training : 0.651000022888
The loss of the training : 0.967450976372
Iteration : 1486
The accuracy of training : 0.666000008583
The loss of the training : 0.933274030685
Iteration : 1487
The accuracy of training : 0.667999982834
The loss of the training : 0.955612361431
Iteration : 1488
The accuracy of training : 0.694000005722
The loss of the training : 0.912879824638
Iteration : 1489
The accuracy of training : 0.677999973297
The loss of the training : 0.939400792122
Iteration : 1490
The accuracy of training : 0.643000006676
The loss of the training : 1.01272284985
Iteration : 1491
The accuracy of training : 0.661000013351
The loss of the training : 0.977195799351
Iteration : 1492
The accuracy of training : 0.658999979496
The loss of the training : 1.00633847713
Iteration : 1493
The accuracy of training : 0.666000008583
The loss of the training : 0.953312337399
Iteration : 1494
The accuracy of training : 0.662000000477
The loss of the training : 0.963095545769
Iteration : 1495
The accuracy of training : 0.625999987125
The loss of the training : 1.02155327797
Iteration : 1496
The accuracy of training : 0.663999974728
The loss of the training : 0.985876321793
Iteration : 1497
The accuracy of training : 0.70300000906
The loss of the training : 0.891291439533
Iteration : 1498
The accuracy of training : 0.662999987602
The loss of the training : 0.956780195236
Iteration : 1499
The accuracy of training : 0.665000021458
The loss of the training : 0.964852154255
Iteration : 1500
The accuracy of training : 0.667999982834
The loss of the training : 0.951098799706
Iteration : 1501
The accuracy of training : 0.674000024796
The loss of the training : 0.944942772388
Iteration : 1502
The accuracy of training : 0.679000020027
The loss of the training : 0.948587596416
Iteration : 1503
The accuracy of training : 0.698000013828
The loss of the training : 0.887858331203
Iteration : 1504
The accuracy of training : 0.676999986172
The loss of the training : 0.928586065769
Iteration : 1505
The accuracy of training : 0.665000021458
The loss of the training : 0.954017221928
Iteration : 1506
The accuracy of training : 0.674000024796
The loss of the training : 0.926661789417
Iteration : 1507
The accuracy of training : 0.680000007153
The loss of the training : 0.950604200363
Iteration : 1508
The accuracy of training : 0.68599998951
The loss of the training : 0.885511279106
Iteration : 1509
The accuracy of training : 0.681999981403
The loss of the training : 0.928091108799
Iteration : 1510
The accuracy of training : 0.680000007153
The loss of the training : 0.948097527027
Iteration : 1511
The accuracy of training : 0.680000007153
The loss of the training : 0.956410944462
Iteration : 1512
The accuracy of training : 0.660000026226
The loss of the training : 0.988333404064
Iteration : 1513
The accuracy of training : 0.638999998569
The loss of the training : 1.02334177494
Iteration : 1514
The accuracy of training : 0.667999982834
The loss of the training : 0.946456134319
Iteration : 1515
The accuracy of training : 0.680999994278
The loss of the training : 0.953144669533
Iteration : 1516
The accuracy of training : 0.712000012398
The loss of the training : 0.900379896164
Iteration : 1517
The accuracy of training : 0.662000000477
The loss of the training : 0.975486814976
Iteration : 1518
The accuracy of training : 0.685000002384
The loss of the training : 0.92950284481
Iteration : 1519
The accuracy of training : 0.666999995708
The loss of the training : 0.940395772457
Iteration : 1520
The accuracy of training : 0.666000008583
The loss of the training : 0.934406757355
Iteration : 1521
The accuracy of training : 0.699000000954
The loss of the training : 0.893684029579
Iteration : 1522
The accuracy of training : 0.68900001049
The loss of the training : 0.883843302727
Iteration : 1523
The accuracy of training : 0.672999978065
The loss of the training : 0.945446193218
Iteration : 1524
The accuracy of training : 0.657999992371
The loss of the training : 0.957351148129
Iteration : 1525
The accuracy of training : 0.64200001955
The loss of the training : 0.977596104145
Iteration : 1526
The accuracy of training : 0.657999992371
The loss of the training : 0.940291464329
Iteration : 1527
The accuracy of training : 0.660000026226
The loss of the training : 0.960138559341
Iteration : 1528
The accuracy of training : 0.693000018597
The loss of the training : 0.913848936558
Iteration : 1529
The accuracy of training : 0.683000028133
The loss of the training : 0.933708131313
Iteration : 1530
The accuracy of training : 0.643000006676
The loss of the training : 1.00217330456
Iteration : 1531
The accuracy of training : 0.666999995708
The loss of the training : 0.968791365623
Iteration : 1532
The accuracy of training : 0.662999987602
The loss of the training : 0.991683661938
Iteration : 1533
The accuracy of training : 0.676999986172
The loss of the training : 0.934036195278
Iteration : 1534
The accuracy of training : 0.671000003815
The loss of the training : 0.938959360123
Iteration : 1535
The accuracy of training : 0.64200001955
The loss of the training : 1.00150620937
Iteration : 1536
The accuracy of training : 0.671000003815
The loss of the training : 0.966078996658
Iteration : 1537
The accuracy of training : 0.703999996185
The loss of the training : 0.880489587784
Iteration : 1538
The accuracy of training : 0.662000000477
The loss of the training : 0.957205653191
Iteration : 1539
The accuracy of training : 0.666999995708
The loss of the training : 0.975068092346
Iteration : 1540
The accuracy of training : 0.652999997139
The loss of the training : 0.965523421764
Iteration : 1541
The accuracy of training : 0.657999992371
The loss of the training : 0.96578836441
Iteration : 1542
The accuracy of training : 0.658999979496
The loss of the training : 0.972862124443
Iteration : 1543
The accuracy of training : 0.68599998951
The loss of the training : 0.898879528046
Iteration : 1544
The accuracy of training : 0.674000024796
The loss of the training : 0.939234673977
Iteration : 1545
The accuracy of training : 0.665000021458
The loss of the training : 0.959601163864
Iteration : 1546
The accuracy of training : 0.669000029564
The loss of the training : 0.931865155697
Iteration : 1547
The accuracy of training : 0.662000000477
The loss of the training : 0.963950872421
Iteration : 1548
The accuracy of training : 0.684000015259
The loss of the training : 0.89480727911
Iteration : 1549
The accuracy of training : 0.675000011921
The loss of the training : 0.93714094162
Iteration : 1550
The accuracy of training : 0.675999999046
The loss of the training : 0.95371055603
Iteration : 1551
The accuracy of training : 0.681999981403
The loss of the training : 0.953176558018
Iteration : 1552
The accuracy of training : 0.662999987602
The loss of the training : 0.980444431305
Iteration : 1553
The accuracy of training : 0.638999998569
The loss of the training : 1.01658153534
Iteration : 1554
The accuracy of training : 0.676999986172
The loss of the training : 0.936263859272
Iteration : 1555
The accuracy of training : 0.68900001049
The loss of the training : 0.94523614645
Iteration : 1556
The accuracy of training : 0.712999999523
The loss of the training : 0.892308652401
Iteration : 1557
The accuracy of training : 0.669000029564
The loss of the training : 0.961785912514
Iteration : 1558
The accuracy of training : 0.68599998951
The loss of the training : 0.915175259113
Iteration : 1559
The accuracy of training : 0.671000003815
The loss of the training : 0.927628040314
Iteration : 1560
The accuracy of training : 0.685000002384
The loss of the training : 0.917690217495
Iteration : 1561
The accuracy of training : 0.716000020504
The loss of the training : 0.881330251694
Iteration : 1562
The accuracy of training : 0.702000021935
The loss of the training : 0.865500092506
Iteration : 1563
The accuracy of training : 0.680999994278
The loss of the training : 0.917845189571
Iteration : 1564
The accuracy of training : 0.674000024796
The loss of the training : 0.926170945168
Iteration : 1565
The accuracy of training : 0.663999974728
The loss of the training : 0.942076325417
Iteration : 1566
The accuracy of training : 0.667999982834
The loss of the training : 0.919853746891
Iteration : 1567
The accuracy of training : 0.666999995708
The loss of the training : 0.946393430233
Iteration : 1568
The accuracy of training : 0.699000000954
The loss of the training : 0.902844846249
Iteration : 1569
The accuracy of training : 0.679000020027
The loss of the training : 0.923825144768
Iteration : 1570
The accuracy of training : 0.646000027657
The loss of the training : 0.991883456707
Iteration : 1571
The accuracy of training : 0.667999982834
The loss of the training : 0.953427791595
Iteration : 1572
The accuracy of training : 0.674000024796
The loss of the training : 0.97565472126
Iteration : 1573
The accuracy of training : 0.686999976635
The loss of the training : 0.920335710049
Iteration : 1574
The accuracy of training : 0.680999994278
The loss of the training : 0.927245378494
Iteration : 1575
The accuracy of training : 0.64099997282
The loss of the training : 0.994453787804
Iteration : 1576
The accuracy of training : 0.666999995708
The loss of the training : 0.969175219536
Iteration : 1577
The accuracy of training : 0.705999970436
The loss of the training : 0.880180120468
Iteration : 1578
The accuracy of training : 0.663999974728
The loss of the training : 0.958386540413
Iteration : 1579
The accuracy of training : 0.661000013351
The loss of the training : 0.973106026649
Iteration : 1580
The accuracy of training : 0.660000026226
The loss of the training : 0.952428519726
Iteration : 1581
The accuracy of training : 0.663999974728
The loss of the training : 0.946820557117
Iteration : 1582
The accuracy of training : 0.675999999046
The loss of the training : 0.948734104633
Iteration : 1583
The accuracy of training : 0.698000013828
The loss of the training : 0.881144106388
Iteration : 1584
The accuracy of training : 0.686999976635
The loss of the training : 0.922723412514
Iteration : 1585
The accuracy of training : 0.662999987602
The loss of the training : 0.94495433569
Iteration : 1586
The accuracy of training : 0.675000011921
The loss of the training : 0.917709767818
Iteration : 1587
The accuracy of training : 0.676999986172
The loss of the training : 0.943005859852
Iteration : 1588
The accuracy of training : 0.694999992847
The loss of the training : 0.875609397888
Iteration : 1589
The accuracy of training : 0.684000015259
The loss of the training : 0.92022895813
Iteration : 1590
The accuracy of training : 0.685000002384
The loss of the training : 0.937129974365
Iteration : 1591
The accuracy of training : 0.68900001049
The loss of the training : 0.940447092056
Iteration : 1592
The accuracy of training : 0.665000021458
The loss of the training : 0.968246817589
Iteration : 1593
The accuracy of training : 0.64099997282
The loss of the training : 1.00430488586
Iteration : 1594
The accuracy of training : 0.680000007153
The loss of the training : 0.927040696144
Iteration : 1595
The accuracy of training : 0.693000018597
The loss of the training : 0.936150074005
Iteration : 1596
The accuracy of training : 0.713999986649
The loss of the training : 0.883776724339
Iteration : 1597
The accuracy of training : 0.671000003815
The loss of the training : 0.954207420349
Iteration : 1598
The accuracy of training : 0.68900001049
The loss of the training : 0.908545076847
Iteration : 1599
The accuracy of training : 0.67199999094
The loss of the training : 0.920447826385
Iteration : 1600
The accuracy of training : 0.68900001049
The loss of the training : 0.909346401691
Iteration : 1601
The accuracy of training : 0.72000002861
The loss of the training : 0.874672353268
Iteration : 1602
The accuracy of training : 0.705999970436
The loss of the training : 0.857880890369
Iteration : 1603
The accuracy of training : 0.681999981403
The loss of the training : 0.910378932953
Iteration : 1604
The accuracy of training : 0.672999978065
The loss of the training : 0.918160676956
Iteration : 1605
The accuracy of training : 0.667999982834
The loss of the training : 0.934953212738
Iteration : 1606
The accuracy of training : 0.666000008583
The loss of the training : 0.913699150085
Iteration : 1607
The accuracy of training : 0.670000016689
The loss of the training : 0.941072642803
Iteration : 1608
The accuracy of training : 0.70300000906
The loss of the training : 0.897070229053
Iteration : 1609
The accuracy of training : 0.683000028133
The loss of the training : 0.916409194469
Iteration : 1610
The accuracy of training : 0.647000014782
The loss of the training : 0.984647274017
Iteration : 1611
The accuracy of training : 0.667999982834
The loss of the training : 0.947245299816
Iteration : 1612
The accuracy of training : 0.674000024796
The loss of the training : 0.967580378056
Iteration : 1613
The accuracy of training : 0.690999984741
The loss of the training : 0.911879897118
Iteration : 1614
The accuracy of training : 0.683000028133
The loss of the training : 0.919327020645
Iteration : 1615
The accuracy of training : 0.643000006676
The loss of the training : 0.988581418991
Iteration : 1616
The accuracy of training : 0.666000008583
The loss of the training : 0.967478632927
Iteration : 1617
The accuracy of training : 0.705999970436
The loss of the training : 0.875888824463
Iteration : 1618
The accuracy of training : 0.666000008583
The loss of the training : 0.954947650433
Iteration : 1619
The accuracy of training : 0.662000000477
The loss of the training : 0.967821061611
Iteration : 1620
The accuracy of training : 0.666000008583
The loss of the training : 0.943414092064
Iteration : 1621
The accuracy of training : 0.670000016689
The loss of the training : 0.937182605267
Iteration : 1622
The accuracy of training : 0.680000007153
The loss of the training : 0.938443183899
Iteration : 1623
The accuracy of training : 0.699999988079
The loss of the training : 0.871674716473
Iteration : 1624
The accuracy of training : 0.68900001049
The loss of the training : 0.912285387516
Iteration : 1625
The accuracy of training : 0.667999982834
The loss of the training : 0.93651920557
Iteration : 1626
The accuracy of training : 0.679000020027
The loss of the training : 0.90867716074
Iteration : 1627
The accuracy of training : 0.680000007153
The loss of the training : 0.932735800743
Iteration : 1628
The accuracy of training : 0.698000013828
The loss of the training : 0.866279602051
Iteration : 1629
The accuracy of training : 0.68900001049
The loss of the training : 0.910069286823
Iteration : 1630
The accuracy of training : 0.689999997616
The loss of the training : 0.927673220634
Iteration : 1631
The accuracy of training : 0.694000005722
The loss of the training : 0.930796682835
Iteration : 1632
The accuracy of training : 0.662999987602
The loss of the training : 0.958395659924
Iteration : 1633
The accuracy of training : 0.64200001955
The loss of the training : 0.993008077145
Iteration : 1634
The accuracy of training : 0.680000007153
The loss of the training : 0.918106496334
Iteration : 1635
The accuracy of training : 0.694000005722
The loss of the training : 0.924470365047
Iteration : 1636
The accuracy of training : 0.716000020504
The loss of the training : 0.873376190662
Iteration : 1637
The accuracy of training : 0.679000020027
The loss of the training : 0.945948302746
Iteration : 1638
The accuracy of training : 0.689999997616
The loss of the training : 0.899859547615
Iteration : 1639
The accuracy of training : 0.675000011921
The loss of the training : 0.911048293114
Iteration : 1640
The accuracy of training : 0.690999984741
The loss of the training : 0.900348186493
Iteration : 1641
The accuracy of training : 0.712999999523
The loss of the training : 0.868800997734
Iteration : 1642
The accuracy of training : 0.708999991417
The loss of the training : 0.850922763348
Iteration : 1643
The accuracy of training : 0.68599998951
The loss of the training : 0.903139710426
Iteration : 1644
The accuracy of training : 0.680000007153
The loss of the training : 0.915479421616
Iteration : 1645
The accuracy of training : 0.667999982834
The loss of the training : 0.936635077
Iteration : 1646
The accuracy of training : 0.672999978065
The loss of the training : 0.910618245602
Iteration : 1647
The accuracy of training : 0.669000029564
The loss of the training : 0.937302052975
Iteration : 1648
The accuracy of training : 0.703999996185
The loss of the training : 0.890942573547
Iteration : 1649
The accuracy of training : 0.68599998951
The loss of the training : 0.905338287354
Iteration : 1650
The accuracy of training : 0.657999992371
The loss of the training : 0.972178637981
Iteration : 1651
The accuracy of training : 0.671000003815
The loss of the training : 0.93471044302
Iteration : 1652
The accuracy of training : 0.674000024796
The loss of the training : 0.962992072105
Iteration : 1653
The accuracy of training : 0.68599998951
The loss of the training : 0.909524679184
Iteration : 1654
The accuracy of training : 0.680999994278
The loss of the training : 0.913421034813
Iteration : 1655
The accuracy of training : 0.644999980927
The loss of the training : 0.974464118481
Iteration : 1656
The accuracy of training : 0.675000011921
The loss of the training : 0.945889651775
Iteration : 1657
The accuracy of training : 0.708000004292
The loss of the training : 0.857029080391
Iteration : 1658
The accuracy of training : 0.675000011921
The loss of the training : 0.931726098061
Iteration : 1659
The accuracy of training : 0.672999978065
The loss of the training : 0.940261006355
Iteration : 1660
The accuracy of training : 0.666999995708
The loss of the training : 0.922330975533
Iteration : 1661
The accuracy of training : 0.68599998951
The loss of the training : 0.919130623341
Iteration : 1662
The accuracy of training : 0.691999971867
The loss of the training : 0.923673212528
Iteration : 1663
The accuracy of training : 0.700999975204
The loss of the training : 0.862362265587
Iteration : 1664
The accuracy of training : 0.685000002384
The loss of the training : 0.902147829533
Iteration : 1665
The accuracy of training : 0.669000029564
The loss of the training : 0.930212795734
Iteration : 1666
The accuracy of training : 0.68900001049
The loss of the training : 0.898714721203
Iteration : 1667
The accuracy of training : 0.689999997616
The loss of the training : 0.92195391655
Iteration : 1668
The accuracy of training : 0.702000021935
The loss of the training : 0.859032511711
Iteration : 1669
The accuracy of training : 0.691999971867
The loss of the training : 0.900907278061
Iteration : 1670
The accuracy of training : 0.683000028133
The loss of the training : 0.920638620853
Iteration : 1671
The accuracy of training : 0.697000026703
The loss of the training : 0.921763300896
Iteration : 1672
The accuracy of training : 0.663999974728
The loss of the training : 0.949058592319
Iteration : 1673
The accuracy of training : 0.65600001812
The loss of the training : 0.983908712864
Iteration : 1674
The accuracy of training : 0.675999999046
The loss of the training : 0.915021181107
Iteration : 1675
The accuracy of training : 0.689999997616
The loss of the training : 0.918524742126
Iteration : 1676
The accuracy of training : 0.72000002861
The loss of the training : 0.868800103664
Iteration : 1677
The accuracy of training : 0.672999978065
The loss of the training : 0.95708489418
Iteration : 1678
The accuracy of training : 0.691999971867
The loss of the training : 0.90969145298
Iteration : 1679
The accuracy of training : 0.676999986172
The loss of the training : 0.91560792923
Iteration : 1680
The accuracy of training : 0.675999999046
The loss of the training : 0.913302183151
Iteration : 1681
The accuracy of training : 0.698000013828
The loss of the training : 0.888713419437
Iteration : 1682
The accuracy of training : 0.695999979973
The loss of the training : 0.87652772665
Iteration : 1683
The accuracy of training : 0.666000008583
The loss of the training : 0.917583882809
Iteration : 1684
The accuracy of training : 0.671000003815
The loss of the training : 0.935631036758
Iteration : 1685
The accuracy of training : 0.661000013351
The loss of the training : 0.945376753807
Iteration : 1686
The accuracy of training : 0.672999978065
The loss of the training : 0.906466007233
Iteration : 1687
The accuracy of training : 0.674000024796
The loss of the training : 0.929143846035
Iteration : 1688
The accuracy of training : 0.703999996185
The loss of the training : 0.882595896721
Iteration : 1689
The accuracy of training : 0.698000013828
The loss of the training : 0.895508527756
Iteration : 1690
The accuracy of training : 0.669000029564
The loss of the training : 0.968196570873
Iteration : 1691
The accuracy of training : 0.675999999046
The loss of the training : 0.93355691433
Iteration : 1692
The accuracy of training : 0.675999999046
The loss of the training : 0.962973177433
Iteration : 1693
The accuracy of training : 0.68599998951
The loss of the training : 0.913020431995
Iteration : 1694
The accuracy of training : 0.671000003815
The loss of the training : 0.919550955296
Iteration : 1695
The accuracy of training : 0.638999998569
The loss of the training : 0.978552401066
Iteration : 1696
The accuracy of training : 0.680999994278
The loss of the training : 0.951010048389
Iteration : 1697
The accuracy of training : 0.699999988079
The loss of the training : 0.855937600136
Iteration : 1698
The accuracy of training : 0.675000011921
The loss of the training : 0.927676320076
Iteration : 1699
The accuracy of training : 0.679000020027
The loss of the training : 0.934540450573
Iteration : 1700
The accuracy of training : 0.667999982834
The loss of the training : 0.919171214104
Iteration : 1701
The accuracy of training : 0.688000023365
The loss of the training : 0.916404426098
Iteration : 1702
The accuracy of training : 0.694999992847
The loss of the training : 0.92328619957
Iteration : 1703
The accuracy of training : 0.700999975204
The loss of the training : 0.862411856651
Iteration : 1704
The accuracy of training : 0.684000015259
The loss of the training : 0.900755286217
Iteration : 1705
The accuracy of training : 0.672999978065
The loss of the training : 0.928115427494
Iteration : 1706
The accuracy of training : 0.694000005722
The loss of the training : 0.894053280354
Iteration : 1707
The accuracy of training : 0.689999997616
The loss of the training : 0.921045958996
Iteration : 1708
The accuracy of training : 0.694999992847
The loss of the training : 0.861273407936
Iteration : 1709
The accuracy of training : 0.685000002384
The loss of the training : 0.8994333148
Iteration : 1710
The accuracy of training : 0.681999981403
The loss of the training : 0.915948033333
Iteration : 1711
The accuracy of training : 0.697000026703
The loss of the training : 0.915319919586
Iteration : 1712
The accuracy of training : 0.667999982834
The loss of the training : 0.941275835037
Iteration : 1713
The accuracy of training : 0.652000010014
The loss of the training : 0.977641701698
Iteration : 1714
The accuracy of training : 0.674000024796
The loss of the training : 0.913624823093
Iteration : 1715
The accuracy of training : 0.689999997616
The loss of the training : 0.915253460407
Iteration : 1716
The accuracy of training : 0.717999994755
The loss of the training : 0.86284917593
Iteration : 1717
The accuracy of training : 0.675000011921
The loss of the training : 0.950455904007
Iteration : 1718
The accuracy of training : 0.693000018597
The loss of the training : 0.899749159813
Iteration : 1719
The accuracy of training : 0.676999986172
The loss of the training : 0.904018580914
Iteration : 1720
The accuracy of training : 0.681999981403
The loss of the training : 0.896067202091
Iteration : 1721
The accuracy of training : 0.705999970436
The loss of the training : 0.870771110058
Iteration : 1722
The accuracy of training : 0.707000017166
The loss of the training : 0.854161322117
Iteration : 1723
The accuracy of training : 0.680000007153
The loss of the training : 0.899947881699
Iteration : 1724
The accuracy of training : 0.677999973297
The loss of the training : 0.915733575821
Iteration : 1725
The accuracy of training : 0.672999978065
The loss of the training : 0.926321268082
Iteration : 1726
The accuracy of training : 0.688000023365
The loss of the training : 0.892043113708
Iteration : 1727
The accuracy of training : 0.68599998951
The loss of the training : 0.917714715004
Iteration : 1728
The accuracy of training : 0.708999991417
The loss of the training : 0.87132525444
Iteration : 1729
The accuracy of training : 0.694999992847
The loss of the training : 0.888849318027
Iteration : 1730
The accuracy of training : 0.667999982834
The loss of the training : 0.964783489704
Iteration : 1731
The accuracy of training : 0.677999973297
The loss of the training : 0.927525699139
Iteration : 1732
The accuracy of training : 0.680999994278
The loss of the training : 0.951223671436
Iteration : 1733
The accuracy of training : 0.694000005722
The loss of the training : 0.900279819965
Iteration : 1734
The accuracy of training : 0.681999981403
The loss of the training : 0.904501736164
Iteration : 1735
The accuracy of training : 0.651000022888
The loss of the training : 0.967613339424
Iteration : 1736
The accuracy of training : 0.680000007153
The loss of the training : 0.942416608334
Iteration : 1737
The accuracy of training : 0.712000012398
The loss of the training : 0.846797227859
Iteration : 1738
The accuracy of training : 0.675999999046
The loss of the training : 0.920914471149
Iteration : 1739
The accuracy of training : 0.675999999046
The loss of the training : 0.926620185375
Iteration : 1740
The accuracy of training : 0.677999973297
The loss of the training : 0.905620574951
Iteration : 1741
The accuracy of training : 0.690999984741
The loss of the training : 0.90314078331
Iteration : 1742
The accuracy of training : 0.704999983311
The loss of the training : 0.90839022398
Iteration : 1743
The accuracy of training : 0.70300000906
The loss of the training : 0.848375082016
Iteration : 1744
The accuracy of training : 0.689999997616
The loss of the training : 0.888061821461
Iteration : 1745
The accuracy of training : 0.676999986172
The loss of the training : 0.914135396481
Iteration : 1746
The accuracy of training : 0.694000005722
The loss of the training : 0.882686376572
Iteration : 1747
The accuracy of training : 0.693000018597
The loss of the training : 0.910106658936
Iteration : 1748
The accuracy of training : 0.708000004292
The loss of the training : 0.848910272121
Iteration : 1749
The accuracy of training : 0.691999971867
The loss of the training : 0.890636146069
Iteration : 1750
The accuracy of training : 0.688000023365
The loss of the training : 0.907395780087
Iteration : 1751
The accuracy of training : 0.70300000906
The loss of the training : 0.907363474369
Iteration : 1752
The accuracy of training : 0.672999978065
The loss of the training : 0.933784782887
Iteration : 1753
The accuracy of training : 0.65499997139
The loss of the training : 0.969315648079
Iteration : 1754
The accuracy of training : 0.691999971867
The loss of the training : 0.898629188538
Iteration : 1755
The accuracy of training : 0.694999992847
The loss of the training : 0.90412735939
Iteration : 1756
The accuracy of training : 0.725000023842
The loss of the training : 0.852766394615
Iteration : 1757
The accuracy of training : 0.681999981403
The loss of the training : 0.928708314896
Iteration : 1758
The accuracy of training : 0.698000013828
The loss of the training : 0.881314396858
Iteration : 1759
The accuracy of training : 0.681999981403
The loss of the training : 0.892810821533
Iteration : 1760
The accuracy of training : 0.694999992847
The loss of the training : 0.879209399223
Iteration : 1761
The accuracy of training : 0.725000023842
The loss of the training : 0.852764010429
Iteration : 1762
The accuracy of training : 0.716000020504
The loss of the training : 0.831273436546
Iteration : 1763
The accuracy of training : 0.690999984741
The loss of the training : 0.880513250828
Iteration : 1764
The accuracy of training : 0.690999984741
The loss of the training : 0.888320505619
Iteration : 1765
The accuracy of training : 0.694000005722
The loss of the training : 0.899580478668
Iteration : 1766
The accuracy of training : 0.683000028133
The loss of the training : 0.877977609634
Iteration : 1767
The accuracy of training : 0.699000000954
The loss of the training : 0.90679359436
Iteration : 1768
The accuracy of training : 0.716000020504
The loss of the training : 0.861664831638
Iteration : 1769
The accuracy of training : 0.702000021935
The loss of the training : 0.887881398201
Iteration : 1770
The accuracy of training : 0.666999995708
The loss of the training : 0.971135675907
Iteration : 1771
The accuracy of training : 0.675000011921
The loss of the training : 0.938909113407
Iteration : 1772
The accuracy of training : 0.679000020027
The loss of the training : 0.950826823711
Iteration : 1773
The accuracy of training : 0.698000013828
The loss of the training : 0.894976258278
Iteration : 1774
The accuracy of training : 0.680999994278
The loss of the training : 0.902913987637
Iteration : 1775
The accuracy of training : 0.635999977589
The loss of the training : 0.978339254856
Iteration : 1776
The accuracy of training : 0.666999995708
The loss of the training : 0.961420357227
Iteration : 1777
The accuracy of training : 0.708999991417
The loss of the training : 0.853724777699
Iteration : 1778
The accuracy of training : 0.67199999094
The loss of the training : 0.927619218826
Iteration : 1779
The accuracy of training : 0.677999973297
The loss of the training : 0.932796299458
Iteration : 1780
The accuracy of training : 0.680999994278
The loss of the training : 0.90492105484
Iteration : 1781
The accuracy of training : 0.697000026703
The loss of the training : 0.900206506252
Iteration : 1782
The accuracy of training : 0.700999975204
The loss of the training : 0.905533015728
Iteration : 1783
The accuracy of training : 0.70300000906
The loss of the training : 0.844208538532
Iteration : 1784
The accuracy of training : 0.693000018597
The loss of the training : 0.88426053524
Iteration : 1785
The accuracy of training : 0.675000011921
The loss of the training : 0.909214138985
Iteration : 1786
The accuracy of training : 0.699000000954
The loss of the training : 0.879118680954
Iteration : 1787
The accuracy of training : 0.688000023365
The loss of the training : 0.908659219742
Iteration : 1788
The accuracy of training : 0.708000004292
The loss of the training : 0.847371220589
Iteration : 1789
The accuracy of training : 0.694999992847
The loss of the training : 0.889000892639
Iteration : 1790
The accuracy of training : 0.697000026703
The loss of the training : 0.905273973942
Iteration : 1791
The accuracy of training : 0.699000000954
The loss of the training : 0.905338644981
Iteration : 1792
The accuracy of training : 0.676999986172
The loss of the training : 0.931150555611
Iteration : 1793
The accuracy of training : 0.661000013351
The loss of the training : 0.966867625713
Iteration : 1794
The accuracy of training : 0.691999971867
The loss of the training : 0.893968999386
Iteration : 1795
The accuracy of training : 0.693000018597
The loss of the training : 0.899721562862
Iteration : 1796
The accuracy of training : 0.727999985218
The loss of the training : 0.849081933498
Iteration : 1797
The accuracy of training : 0.681999981403
The loss of the training : 0.923455357552
Iteration : 1798
The accuracy of training : 0.70300000906
The loss of the training : 0.876107871532
Iteration : 1799
The accuracy of training : 0.688000023365
The loss of the training : 0.889039576054
Iteration : 1800
The accuracy of training : 0.691999971867
The loss of the training : 0.874132573605
Iteration : 1801
The accuracy of training : 0.725000023842
The loss of the training : 0.848729431629
Iteration : 1802
The accuracy of training : 0.72000002861
The loss of the training : 0.826618075371
Iteration : 1803
The accuracy of training : 0.698000013828
The loss of the training : 0.874295771122
Iteration : 1804
The accuracy of training : 0.693000018597
The loss of the training : 0.880841016769
Iteration : 1805
The accuracy of training : 0.698000013828
The loss of the training : 0.890310704708
Iteration : 1806
The accuracy of training : 0.685000002384
The loss of the training : 0.872256159782
Iteration : 1807
The accuracy of training : 0.695999979973
The loss of the training : 0.902857005596
Iteration : 1808
The accuracy of training : 0.72000002861
The loss of the training : 0.857599794865
Iteration : 1809
The accuracy of training : 0.699000000954
The loss of the training : 0.885739207268
Iteration : 1810
The accuracy of training : 0.669000029564
The loss of the training : 0.968700706959
Iteration : 1811
The accuracy of training : 0.67199999094
The loss of the training : 0.934712052345
Iteration : 1812
The accuracy of training : 0.679000020027
The loss of the training : 0.944232940674
Iteration : 1813
The accuracy of training : 0.698000013828
The loss of the training : 0.888537406921
Iteration : 1814
The accuracy of training : 0.68599998951
The loss of the training : 0.893375635147
Iteration : 1815
The accuracy of training : 0.64200001955
The loss of the training : 0.963735461235
Iteration : 1816
The accuracy of training : 0.670000016689
The loss of the training : 0.943490862846
Iteration : 1817
The accuracy of training : 0.712999999523
The loss of the training : 0.839942336082
Iteration : 1818
The accuracy of training : 0.672999978065
The loss of the training : 0.914768278599
Iteration : 1819
The accuracy of training : 0.688000023365
The loss of the training : 0.918799996376
Iteration : 1820
The accuracy of training : 0.680000007153
The loss of the training : 0.89482909441
Iteration : 1821
The accuracy of training : 0.697000026703
The loss of the training : 0.891019582748
Iteration : 1822
The accuracy of training : 0.707000017166
The loss of the training : 0.897405803204
Iteration : 1823
The accuracy of training : 0.709999978542
The loss of the training : 0.836930692196
Iteration : 1824
The accuracy of training : 0.694999992847
The loss of the training : 0.875701844692
Iteration : 1825
The accuracy of training : 0.680999994278
The loss of the training : 0.901829123497
Iteration : 1826
The accuracy of training : 0.70300000906
The loss of the training : 0.870453059673
Iteration : 1827
The accuracy of training : 0.698000013828
The loss of the training : 0.899212300777
Iteration : 1828
The accuracy of training : 0.713999986649
The loss of the training : 0.839721024036
Iteration : 1829
The accuracy of training : 0.700999975204
The loss of the training : 0.880230665207
Iteration : 1830
The accuracy of training : 0.694000005722
The loss of the training : 0.896266996861
Iteration : 1831
The accuracy of training : 0.705999970436
The loss of the training : 0.894930422306
Iteration : 1832
The accuracy of training : 0.680000007153
The loss of the training : 0.91900908947
Iteration : 1833
The accuracy of training : 0.660000026226
The loss of the training : 0.956901729107
Iteration : 1834
The accuracy of training : 0.691999971867
The loss of the training : 0.888355612755
Iteration : 1835
The accuracy of training : 0.697000026703
The loss of the training : 0.890150129795
Iteration : 1836
The accuracy of training : 0.723999977112
The loss of the training : 0.840279817581
Iteration : 1837
The accuracy of training : 0.68900001049
The loss of the training : 0.922040343285
Iteration : 1838
The accuracy of training : 0.704999983311
The loss of the training : 0.86998295784
Iteration : 1839
The accuracy of training : 0.689999997616
The loss of the training : 0.878838777542
Iteration : 1840
The accuracy of training : 0.698000013828
The loss of the training : 0.865970432758
Iteration : 1841
The accuracy of training : 0.713999986649
The loss of the training : 0.844987392426
Iteration : 1842
The accuracy of training : 0.721000015736
The loss of the training : 0.822554290295
Iteration : 1843
The accuracy of training : 0.693000018597
The loss of the training : 0.871917128563
Iteration : 1844
The accuracy of training : 0.689999997616
The loss of the training : 0.886394321918
Iteration : 1845
The accuracy of training : 0.683000028133
The loss of the training : 0.90095102787
Iteration : 1846
The accuracy of training : 0.695999979973
The loss of the training : 0.870503365993
Iteration : 1847
The accuracy of training : 0.691999971867
The loss of the training : 0.900363087654
Iteration : 1848
The accuracy of training : 0.717999994755
The loss of the training : 0.855811178684
Iteration : 1849
The accuracy of training : 0.704999983311
The loss of the training : 0.872732579708
Iteration : 1850
The accuracy of training : 0.672999978065
The loss of the training : 0.946557581425
Iteration : 1851
The accuracy of training : 0.684000015259
The loss of the training : 0.908411026001
Iteration : 1852
The accuracy of training : 0.689999997616
The loss of the training : 0.932288765907
Iteration : 1853
The accuracy of training : 0.708000004292
The loss of the training : 0.880647003651
Iteration : 1854
The accuracy of training : 0.680999994278
The loss of the training : 0.882370769978
Iteration : 1855
The accuracy of training : 0.670000016689
The loss of the training : 0.945026099682
Iteration : 1856
The accuracy of training : 0.683000028133
The loss of the training : 0.91920119524
Iteration : 1857
The accuracy of training : 0.722000002861
The loss of the training : 0.826109409332
Iteration : 1858
The accuracy of training : 0.685000002384
The loss of the training : 0.902077376842
Iteration : 1859
The accuracy of training : 0.694000005722
The loss of the training : 0.906504690647
Iteration : 1860
The accuracy of training : 0.683000028133
The loss of the training : 0.886776685715
Iteration : 1861
The accuracy of training : 0.699000000954
The loss of the training : 0.885118484497
Iteration : 1862
The accuracy of training : 0.705999970436
The loss of the training : 0.892922639847
Iteration : 1863
The accuracy of training : 0.709999978542
The loss of the training : 0.832766532898
Iteration : 1864
The accuracy of training : 0.694000005722
The loss of the training : 0.871269464493
Iteration : 1865
The accuracy of training : 0.677999973297
The loss of the training : 0.898400425911
Iteration : 1866
The accuracy of training : 0.70300000906
The loss of the training : 0.865310072899
Iteration : 1867
The accuracy of training : 0.694999992847
The loss of the training : 0.892995417118
Iteration : 1868
The accuracy of training : 0.712000012398
The loss of the training : 0.834152877331
Iteration : 1869
The accuracy of training : 0.699000000954
The loss of the training : 0.873698890209
Iteration : 1870
The accuracy of training : 0.697000026703
The loss of the training : 0.889293372631
Iteration : 1871
The accuracy of training : 0.708999991417
The loss of the training : 0.887592434883
Iteration : 1872
The accuracy of training : 0.680000007153
The loss of the training : 0.911060810089
Iteration : 1873
The accuracy of training : 0.665000021458
The loss of the training : 0.949598431587
Iteration : 1874
The accuracy of training : 0.694999992847
The loss of the training : 0.882556557655
Iteration : 1875
The accuracy of training : 0.702000021935
The loss of the training : 0.884373903275
Iteration : 1876
The accuracy of training : 0.726999998093
The loss of the training : 0.834338009357
Iteration : 1877
The accuracy of training : 0.689999997616
The loss of the training : 0.916928708553
Iteration : 1878
The accuracy of training : 0.704999983311
The loss of the training : 0.86426627636
Iteration : 1879
The accuracy of training : 0.688000023365
The loss of the training : 0.873247206211
Iteration : 1880
The accuracy of training : 0.702000021935
The loss of the training : 0.859971284866
Iteration : 1881
The accuracy of training : 0.717000007629
The loss of the training : 0.841259777546
Iteration : 1882
The accuracy of training : 0.722000002861
The loss of the training : 0.81814956665
Iteration : 1883
The accuracy of training : 0.68900001049
The loss of the training : 0.867504656315
Iteration : 1884
The accuracy of training : 0.688000023365
The loss of the training : 0.883925497532
Iteration : 1885
The accuracy of training : 0.68599998951
The loss of the training : 0.899629771709
Iteration : 1886
The accuracy of training : 0.691999971867
The loss of the training : 0.867313861847
Iteration : 1887
The accuracy of training : 0.694000005722
The loss of the training : 0.897016167641
Iteration : 1888
The accuracy of training : 0.721000015736
The loss of the training : 0.851645708084
Iteration : 1889
The accuracy of training : 0.708999991417
The loss of the training : 0.866301000118
Iteration : 1890
The accuracy of training : 0.679000020027
The loss of the training : 0.939439892769
Iteration : 1891
The accuracy of training : 0.685000002384
The loss of the training : 0.902305364609
Iteration : 1892
The accuracy of training : 0.694000005722
The loss of the training : 0.926706135273
Iteration : 1893
The accuracy of training : 0.707000017166
The loss of the training : 0.875012993813
Iteration : 1894
The accuracy of training : 0.68599998951
The loss of the training : 0.876623153687
Iteration : 1895
The accuracy of training : 0.67199999094
The loss of the training : 0.939524114132
Iteration : 1896
The accuracy of training : 0.684000015259
The loss of the training : 0.914376854897
Iteration : 1897
The accuracy of training : 0.725000023842
The loss of the training : 0.821287155151
Iteration : 1898
The accuracy of training : 0.68900001049
The loss of the training : 0.897815406322
Iteration : 1899
The accuracy of training : 0.694000005722
The loss of the training : 0.901521623135
Iteration : 1900
The accuracy of training : 0.681999981403
The loss of the training : 0.881495594978
Iteration : 1901
The accuracy of training : 0.703999996185
The loss of the training : 0.879231214523
Iteration : 1902
The accuracy of training : 0.711000025272
The loss of the training : 0.88749319315
Iteration : 1903
The accuracy of training : 0.713999986649
The loss of the training : 0.827678740025
Iteration : 1904
The accuracy of training : 0.697000026703
The loss of the training : 0.865989148617
Iteration : 1905
The accuracy of training : 0.680000007153
The loss of the training : 0.892840564251
Iteration : 1906
The accuracy of training : 0.703999996185
The loss of the training : 0.8596829772
Iteration : 1907
The accuracy of training : 0.699000000954
The loss of the training : 0.887898623943
Iteration : 1908
The accuracy of training : 0.717999994755
The loss of the training : 0.83008402586
Iteration : 1909
The accuracy of training : 0.705999970436
The loss of the training : 0.86903822422
Iteration : 1910
The accuracy of training : 0.700999975204
The loss of the training : 0.884271860123
Iteration : 1911
The accuracy of training : 0.707000017166
The loss of the training : 0.882358670235
Iteration : 1912
The accuracy of training : 0.683000028133
The loss of the training : 0.906143963337
Iteration : 1913
The accuracy of training : 0.666000008583
The loss of the training : 0.944271624088
Iteration : 1914
The accuracy of training : 0.695999979973
The loss of the training : 0.877089381218
Iteration : 1915
The accuracy of training : 0.702000021935
The loss of the training : 0.879279792309
Iteration : 1916
The accuracy of training : 0.727999985218
The loss of the training : 0.828743100166
Iteration : 1917
The accuracy of training : 0.694999992847
The loss of the training : 0.90918970108
Iteration : 1918
The accuracy of training : 0.711000025272
The loss of the training : 0.857230246067
Iteration : 1919
The accuracy of training : 0.690999984741
The loss of the training : 0.86778652668
Iteration : 1920
The accuracy of training : 0.707000017166
The loss of the training : 0.852955460548
Iteration : 1921
The accuracy of training : 0.72000002861
The loss of the training : 0.835207521915
Iteration : 1922
The accuracy of training : 0.71899998188
The loss of the training : 0.80977666378
Iteration : 1923
The accuracy of training : 0.703999996185
The loss of the training : 0.856671750546
Iteration : 1924
The accuracy of training : 0.694000005722
The loss of the training : 0.867158830166
Iteration : 1925
The accuracy of training : 0.693000018597
The loss of the training : 0.8777821064
Iteration : 1926
The accuracy of training : 0.694000005722
The loss of the training : 0.855430960655
Iteration : 1927
The accuracy of training : 0.70300000906
The loss of the training : 0.886682152748
Iteration : 1928
The accuracy of training : 0.726999998093
The loss of the training : 0.840751826763
Iteration : 1929
The accuracy of training : 0.708999991417
The loss of the training : 0.864603281021
Iteration : 1930
The accuracy of training : 0.684000015259
The loss of the training : 0.946873724461
Iteration : 1931
The accuracy of training : 0.685000002384
The loss of the training : 0.913600325584
Iteration : 1932
The accuracy of training : 0.686999976635
The loss of the training : 0.925139188766
Iteration : 1933
The accuracy of training : 0.709999978542
The loss of the training : 0.869928002357
Iteration : 1934
The accuracy of training : 0.693000018597
The loss of the training : 0.873837947845
Iteration : 1935
The accuracy of training : 0.662999987602
The loss of the training : 0.945903718472
Iteration : 1936
The accuracy of training : 0.676999986172
The loss of the training : 0.925922572613
Iteration : 1937
The accuracy of training : 0.726999998093
The loss of the training : 0.823457837105
Iteration : 1938
The accuracy of training : 0.68599998951
The loss of the training : 0.900307416916
Iteration : 1939
The accuracy of training : 0.695999979973
The loss of the training : 0.903232812881
Iteration : 1940
The accuracy of training : 0.690999984741
The loss of the training : 0.878878355026
Iteration : 1941
The accuracy of training : 0.707000017166
The loss of the training : 0.874494731426
Iteration : 1942
The accuracy of training : 0.712999999523
The loss of the training : 0.882335305214
Iteration : 1943
The accuracy of training : 0.717000007629
The loss of the training : 0.823385536671
Iteration : 1944
The accuracy of training : 0.700999975204
The loss of the training : 0.861884832382
Iteration : 1945
The accuracy of training : 0.680999994278
The loss of the training : 0.887924492359
Iteration : 1946
The accuracy of training : 0.711000025272
The loss of the training : 0.85595023632
Iteration : 1947
The accuracy of training : 0.705999970436
The loss of the training : 0.883725047112
Iteration : 1948
The accuracy of training : 0.71899998188
The loss of the training : 0.826791882515
Iteration : 1949
The accuracy of training : 0.709999978542
The loss of the training : 0.865029096603
Iteration : 1950
The accuracy of training : 0.704999983311
The loss of the training : 0.880527496338
Iteration : 1951
The accuracy of training : 0.707000017166
The loss of the training : 0.879362344742
Iteration : 1952
The accuracy of training : 0.685000002384
The loss of the training : 0.902678787708
Iteration : 1953
The accuracy of training : 0.667999982834
The loss of the training : 0.941800832748
Iteration : 1954
The accuracy of training : 0.694000005722
The loss of the training : 0.873038589954
Iteration : 1955
The accuracy of training : 0.699999988079
The loss of the training : 0.875352919102
Iteration : 1956
The accuracy of training : 0.730000019073
The loss of the training : 0.824980854988
Iteration : 1957
The accuracy of training : 0.695999979973
The loss of the training : 0.902906417847
Iteration : 1958
The accuracy of training : 0.711000025272
The loss of the training : 0.852244794369
Iteration : 1959
The accuracy of training : 0.694000005722
The loss of the training : 0.864853084087
Iteration : 1960
The accuracy of training : 0.704999983311
The loss of the training : 0.849456191063
Iteration : 1961
The accuracy of training : 0.726999998093
The loss of the training : 0.832134664059
Iteration : 1962
The accuracy of training : 0.722000002861
The loss of the training : 0.80591905117
Iteration : 1963
The accuracy of training : 0.707000017166
The loss of the training : 0.851471960545
Iteration : 1964
The accuracy of training : 0.70300000906
The loss of the training : 0.86078619957
Iteration : 1965
The accuracy of training : 0.70300000906
The loss of the training : 0.870498120785
Iteration : 1966
The accuracy of training : 0.695999979973
The loss of the training : 0.850894451141
Iteration : 1967
The accuracy of training : 0.703999996185
The loss of the training : 0.883410692215
Iteration : 1968
The accuracy of training : 0.723999977112
The loss of the training : 0.83714312315
Iteration : 1969
The accuracy of training : 0.711000025272
The loss of the training : 0.86192792654
Iteration : 1970
The accuracy of training : 0.680999994278
The loss of the training : 0.943687617779
Iteration : 1971
The accuracy of training : 0.684000015259
The loss of the training : 0.909723460674
Iteration : 1972
The accuracy of training : 0.690999984741
The loss of the training : 0.919479310513
Iteration : 1973
The accuracy of training : 0.711000025272
The loss of the training : 0.864628195763
Iteration : 1974
The accuracy of training : 0.694000005722
The loss of the training : 0.867545843124
Iteration : 1975
The accuracy of training : 0.671000003815
The loss of the training : 0.936275541782
Iteration : 1976
The accuracy of training : 0.680000007153
The loss of the training : 0.913219869137
Iteration : 1977
The accuracy of training : 0.726999998093
The loss of the training : 0.814585268497
Iteration : 1978
The accuracy of training : 0.685000002384
The loss of the training : 0.891739964485
Iteration : 1979
The accuracy of training : 0.699000000954
The loss of the training : 0.8931620121
Iteration : 1980
The accuracy of training : 0.689999997616
The loss of the training : 0.871676146984
Iteration : 1981
The accuracy of training : 0.712999999523
The loss of the training : 0.867991983891
Iteration : 1982
The accuracy of training : 0.714999973774
The loss of the training : 0.877597689629
Iteration : 1983
The accuracy of training : 0.72000002861
The loss of the training : 0.818967878819
Iteration : 1984
The accuracy of training : 0.70300000906
The loss of the training : 0.856719791889
Iteration : 1985
The accuracy of training : 0.681999981403
The loss of the training : 0.882326185703
Iteration : 1986
The accuracy of training : 0.709999978542
The loss of the training : 0.849868178368
Iteration : 1987
The accuracy of training : 0.704999983311
The loss of the training : 0.878223896027
Iteration : 1988
The accuracy of training : 0.72000002861
The loss of the training : 0.8225055933
Iteration : 1989
The accuracy of training : 0.708999991417
The loss of the training : 0.859612703323
Iteration : 1990
The accuracy of training : 0.704999983311
The loss of the training : 0.874435842037
Iteration : 1991
The accuracy of training : 0.711000025272
The loss of the training : 0.871509134769
Iteration : 1992
The accuracy of training : 0.684000015259
The loss of the training : 0.894243776798
Iteration : 1993
The accuracy of training : 0.670000016689
The loss of the training : 0.935021281242
Iteration : 1994
The accuracy of training : 0.697000026703
The loss of the training : 0.868711948395
Iteration : 1995
The accuracy of training : 0.708000004292
The loss of the training : 0.868495166302
Iteration : 1996
The accuracy of training : 0.728999972343
The loss of the training : 0.818917751312
Iteration : 1997
The accuracy of training : 0.694000005722
The loss of the training : 0.901650369167
Iteration : 1998
The accuracy of training : 0.711000025272
The loss of the training : 0.847736358643
Iteration : 1999
The accuracy of training : 0.698000013828
The loss of the training : 0.857498407364
Iteration : 2000
The accuracy of training : 0.711000025272
The loss of the training : 0.841941952705
Iteration : 2001
The accuracy of training : 0.731000006199
The loss of the training : 0.827360630035
Iteration : 2002
The accuracy of training : 0.721000015736
The loss of the training : 0.800586283207
Iteration : 2003
The accuracy of training : 0.698000013828
The loss of the training : 0.848134577274
Iteration : 2004
The accuracy of training : 0.697000026703
The loss of the training : 0.862428367138
Iteration : 2005
The accuracy of training : 0.690999984741
The loss of the training : 0.875260531902
Iteration : 2006
The accuracy of training : 0.702000021935
The loss of the training : 0.847862839699
Iteration : 2007
The accuracy of training : 0.702000021935
The loss of the training : 0.879423737526
Iteration : 2008
The accuracy of training : 0.731999993324
The loss of the training : 0.832758128643
Iteration : 2009
The accuracy of training : 0.709999978542
The loss of the training : 0.85175794363
Iteration : 2010
The accuracy of training : 0.68599998951
The loss of the training : 0.928517282009
Iteration : 2011
The accuracy of training : 0.688000023365
The loss of the training : 0.89172744751
Iteration : 2012
The accuracy of training : 0.694999992847
The loss of the training : 0.911110043526
Iteration : 2013
The accuracy of training : 0.712999999523
The loss of the training : 0.858391702175
Iteration : 2014
The accuracy of training : 0.699000000954
The loss of the training : 0.860421836376
Iteration : 2015
The accuracy of training : 0.680000007153
The loss of the training : 0.924676775932
Iteration : 2016
The accuracy of training : 0.690999984741
The loss of the training : 0.899781286716
Iteration : 2017
The accuracy of training : 0.731000006199
The loss of the training : 0.806938111782
Iteration : 2018
The accuracy of training : 0.690999984741
The loss of the training : 0.884425520897
Iteration : 2019
The accuracy of training : 0.697000026703
The loss of the training : 0.885104477406
Iteration : 2020
The accuracy of training : 0.690999984741
The loss of the training : 0.865583896637
Iteration : 2021
The accuracy of training : 0.708999991417
The loss of the training : 0.863131523132
Iteration : 2022
The accuracy of training : 0.72000002861
The loss of the training : 0.87377345562
Iteration : 2023
The accuracy of training : 0.71899998188
The loss of the training : 0.815401017666
Iteration : 2024
The accuracy of training : 0.708000004292
The loss of the training : 0.852500259876
Iteration : 2025
The accuracy of training : 0.681999981403
The loss of the training : 0.877991855145
Iteration : 2026
The accuracy of training : 0.714999973774
The loss of the training : 0.845239460468
Iteration : 2027
The accuracy of training : 0.703999996185
The loss of the training : 0.872906446457
Iteration : 2028
The accuracy of training : 0.717000007629
The loss of the training : 0.818638682365
Iteration : 2029
The accuracy of training : 0.708999991417
The loss of the training : 0.854684889317
Iteration : 2030
The accuracy of training : 0.709999978542
The loss of the training : 0.869180798531
Iteration : 2031
The accuracy of training : 0.712999999523
The loss of the training : 0.865901648998
Iteration : 2032
The accuracy of training : 0.688000023365
The loss of the training : 0.888527393341
Iteration : 2033
The accuracy of training : 0.669000029564
The loss of the training : 0.930411934853
Iteration : 2034
The accuracy of training : 0.699000000954
The loss of the training : 0.865512251854
Iteration : 2035
The accuracy of training : 0.707000017166
The loss of the training : 0.863212287426
Iteration : 2036
The accuracy of training : 0.73299998045
The loss of the training : 0.814584136009
Iteration : 2037
The accuracy of training : 0.697000026703
The loss of the training : 0.898374974728
Iteration : 2038
The accuracy of training : 0.712000012398
The loss of the training : 0.843518853188
Iteration : 2039
The accuracy of training : 0.700999975204
The loss of the training : 0.852735817432
Iteration : 2040
The accuracy of training : 0.712999999523
The loss of the training : 0.836983382702
Iteration : 2041
The accuracy of training : 0.722999989986
The loss of the training : 0.824401795864
Iteration : 2042
The accuracy of training : 0.721000015736
The loss of the training : 0.797661304474
Iteration : 2043
The accuracy of training : 0.697000026703
The loss of the training : 0.845256447792
Iteration : 2044
The accuracy of training : 0.700999975204
The loss of the training : 0.861405670643
Iteration : 2045
The accuracy of training : 0.691999971867
The loss of the training : 0.873722016811
Iteration : 2046
The accuracy of training : 0.70300000906
The loss of the training : 0.844047248363
Iteration : 2047
The accuracy of training : 0.700999975204
The loss of the training : 0.876025080681
Iteration : 2048
The accuracy of training : 0.73299998045
The loss of the training : 0.828930437565
Iteration : 2049
The accuracy of training : 0.708999991417
The loss of the training : 0.846513926983
Iteration : 2050
The accuracy of training : 0.686999976635
The loss of the training : 0.922329902649
Iteration : 2051
The accuracy of training : 0.690999984741
The loss of the training : 0.885454893112
Iteration : 2052
The accuracy of training : 0.699999988079
The loss of the training : 0.90624332428
Iteration : 2053
The accuracy of training : 0.713999986649
The loss of the training : 0.853921175003
Iteration : 2054
The accuracy of training : 0.699999988079
The loss of the training : 0.855154693127
Iteration : 2055
The accuracy of training : 0.683000028133
The loss of the training : 0.91890335083
Iteration : 2056
The accuracy of training : 0.694999992847
The loss of the training : 0.893621385098
Iteration : 2057
The accuracy of training : 0.731000006199
The loss of the training : 0.802098095417
Iteration : 2058
The accuracy of training : 0.694000005722
The loss of the training : 0.879500746727
Iteration : 2059
The accuracy of training : 0.699000000954
The loss of the training : 0.879588901997
Iteration : 2060
The accuracy of training : 0.690999984741
The loss of the training : 0.860256373882
Iteration : 2061
The accuracy of training : 0.712000012398
The loss of the training : 0.857789814472
Iteration : 2062
The accuracy of training : 0.721000015736
The loss of the training : 0.869681894779
Iteration : 2063
The accuracy of training : 0.713999986649
The loss of the training : 0.811764359474
Iteration : 2064
The accuracy of training : 0.708000004292
The loss of the training : 0.848096191883
Iteration : 2065
The accuracy of training : 0.681999981403
The loss of the training : 0.873334646225
Iteration : 2066
The accuracy of training : 0.71899998188
The loss of the training : 0.840915799141
Iteration : 2067
The accuracy of training : 0.703999996185
The loss of the training : 0.868997871876
Iteration : 2068
The accuracy of training : 0.716000020504
The loss of the training : 0.815652787685
Iteration : 2069
The accuracy of training : 0.712999999523
The loss of the training : 0.850652933121
Iteration : 2070
The accuracy of training : 0.707000017166
The loss of the training : 0.865179479122
Iteration : 2071
The accuracy of training : 0.714999973774
The loss of the training : 0.861329257488
Iteration : 2072
The accuracy of training : 0.686999976635
The loss of the training : 0.88390815258
Iteration : 2073
The accuracy of training : 0.669000029564
The loss of the training : 0.92583322525
Iteration : 2074
The accuracy of training : 0.695999979973
The loss of the training : 0.860519587994
Iteration : 2075
The accuracy of training : 0.708999991417
The loss of the training : 0.858669281006
Iteration : 2076
The accuracy of training : 0.73400002718
The loss of the training : 0.810313761234
Iteration : 2077
The accuracy of training : 0.693000018597
The loss of the training : 0.89280551672
Iteration : 2078
The accuracy of training : 0.717000007629
The loss of the training : 0.838252365589
Iteration : 2079
The accuracy of training : 0.699999988079
The loss of the training : 0.848861098289
Iteration : 2080
The accuracy of training : 0.713999986649
The loss of the training : 0.832117259502
Iteration : 2081
The accuracy of training : 0.731999993324
The loss of the training : 0.819979965687
Iteration : 2082
The accuracy of training : 0.723999977112
The loss of the training : 0.792111933231
Iteration : 2083
The accuracy of training : 0.708999991417
The loss of the training : 0.838589966297
Iteration : 2084
The accuracy of training : 0.704999983311
The loss of the training : 0.852217674255
Iteration : 2085
The accuracy of training : 0.700999975204
The loss of the training : 0.863598942757
Iteration : 2086
The accuracy of training : 0.707000017166
The loss of the training : 0.83865070343
Iteration : 2087
The accuracy of training : 0.700999975204
The loss of the training : 0.871393620968
Iteration : 2088
The accuracy of training : 0.730000019073
The loss of the training : 0.823843538761
Iteration : 2089
The accuracy of training : 0.712999999523
The loss of the training : 0.8447021842
Iteration : 2090
The accuracy of training : 0.68900001049
The loss of the training : 0.923587977886
Iteration : 2091
The accuracy of training : 0.689999997616
The loss of the training : 0.886443972588
Iteration : 2092
The accuracy of training : 0.697000026703
The loss of the training : 0.902507066727
Iteration : 2093
The accuracy of training : 0.717000007629
The loss of the training : 0.849211871624
Iteration : 2094
The accuracy of training : 0.699999988079
The loss of the training : 0.851330041885
Iteration : 2095
The accuracy of training : 0.681999981403
The loss of the training : 0.917195260525
Iteration : 2096
The accuracy of training : 0.694000005722
The loss of the training : 0.891922414303
Iteration : 2097
The accuracy of training : 0.73400002718
The loss of the training : 0.799243569374
Iteration : 2098
The accuracy of training : 0.693000018597
The loss of the training : 0.876198887825
Iteration : 2099
The accuracy of training : 0.702000021935
The loss of the training : 0.876004040241
Iteration : 2100
The accuracy of training : 0.690999984741
The loss of the training : 0.856158196926
Iteration : 2101
The accuracy of training : 0.712999999523
The loss of the training : 0.853021979332
Iteration : 2102
The accuracy of training : 0.71899998188
The loss of the training : 0.865785360336
Iteration : 2103
The accuracy of training : 0.716000020504
The loss of the training : 0.808097422123
Iteration : 2104
The accuracy of training : 0.708999991417
The loss of the training : 0.84386831522
Iteration : 2105
The accuracy of training : 0.68599998951
The loss of the training : 0.868834495544
Iteration : 2106
The accuracy of training : 0.722999989986
The loss of the training : 0.83667242527
Iteration : 2107
The accuracy of training : 0.709999978542
The loss of the training : 0.865051269531
Iteration : 2108
The accuracy of training : 0.716000020504
The loss of the training : 0.812516212463
Iteration : 2109
The accuracy of training : 0.713999986649
The loss of the training : 0.846479177475
Iteration : 2110
The accuracy of training : 0.712999999523
The loss of the training : 0.86083304882
Iteration : 2111
The accuracy of training : 0.712999999523
The loss of the training : 0.856622457504
Iteration : 2112
The accuracy of training : 0.68599998951
The loss of the training : 0.879117131233
Iteration : 2113
The accuracy of training : 0.667999982834
The loss of the training : 0.921905577183
Iteration : 2114
The accuracy of training : 0.694000005722
The loss of the training : 0.856675684452
Iteration : 2115
The accuracy of training : 0.708999991417
The loss of the training : 0.853706359863
Iteration : 2116
The accuracy of training : 0.735000014305
The loss of the training : 0.806612551212
Iteration : 2117
The accuracy of training : 0.693000018597
The loss of the training : 0.88941437006
Iteration : 2118
The accuracy of training : 0.714999973774
The loss of the training : 0.83445340395
Iteration : 2119
The accuracy of training : 0.702000021935
The loss of the training : 0.844534516335
Iteration : 2120
The accuracy of training : 0.712999999523
The loss of the training : 0.827469289303
Iteration : 2121
The accuracy of training : 0.731000006199
The loss of the training : 0.816636264324
Iteration : 2122
The accuracy of training : 0.721000015736
The loss of the training : 0.788218438625
Iteration : 2123
The accuracy of training : 0.705999970436
The loss of the training : 0.8351521492
Iteration : 2124
The accuracy of training : 0.704999983311
The loss of the training : 0.850206792355
Iteration : 2125
The accuracy of training : 0.702000021935
The loss of the training : 0.861406803131
Iteration : 2126
The accuracy of training : 0.711000025272
The loss of the training : 0.834661543369
Iteration : 2127
The accuracy of training : 0.70300000906
The loss of the training : 0.867887794971
Iteration : 2128
The accuracy of training : 0.731999993324
The loss of the training : 0.82003724575
Iteration : 2129
The accuracy of training : 0.713999986649
The loss of the training : 0.839898407459
Iteration : 2130
The accuracy of training : 0.690999984741
The loss of the training : 0.917838931084
Iteration : 2131
The accuracy of training : 0.694000005722
The loss of the training : 0.879971146584
Iteration : 2132
The accuracy of training : 0.700999975204
The loss of the training : 0.897716343403
Iteration : 2133
The accuracy of training : 0.72000002861
The loss of the training : 0.845174670219
Iteration : 2134
The accuracy of training : 0.70300000906
The loss of the training : 0.846485853195
Iteration : 2135
The accuracy of training : 0.683000028133
The loss of the training : 0.910407245159
Iteration : 2136
The accuracy of training : 0.694999992847
The loss of the training : 0.884542942047
Iteration : 2137
The accuracy of training : 0.736999988556
The loss of the training : 0.794203162193
Iteration : 2138
The accuracy of training : 0.695999979973
The loss of the training : 0.871233582497
Iteration : 2139
The accuracy of training : 0.705999970436
The loss of the training : 0.869730651379
Iteration : 2140
The accuracy of training : 0.694999992847
The loss of the training : 0.851439118385
Iteration : 2141
The accuracy of training : 0.712999999523
The loss of the training : 0.848807632923
Iteration : 2142
The accuracy of training : 0.721000015736
The loss of the training : 0.863055109978
Iteration : 2143
The accuracy of training : 0.717999994755
The loss of the training : 0.805394530296
Iteration : 2144
The accuracy of training : 0.712000012398
The loss of the training : 0.840299248695
Iteration : 2145
The accuracy of training : 0.68900001049
The loss of the training : 0.864724457264
Iteration : 2146
The accuracy of training : 0.722000002861
The loss of the training : 0.832431972027
Iteration : 2147
The accuracy of training : 0.708999991417
The loss of the training : 0.861459493637
Iteration : 2148
The accuracy of training : 0.72000002861
The loss of the training : 0.809953153133
Iteration : 2149
The accuracy of training : 0.716000020504
The loss of the training : 0.842395782471
Iteration : 2150
The accuracy of training : 0.717000007629
The loss of the training : 0.856781721115
Iteration : 2151
The accuracy of training : 0.714999973774
The loss of the training : 0.851666271687
Iteration : 2152
The accuracy of training : 0.686999976635
The loss of the training : 0.874269723892
Iteration : 2153
The accuracy of training : 0.669000029564
The loss of the training : 0.918087303638
Iteration : 2154
The accuracy of training : 0.694999992847
The loss of the training : 0.853695690632
Iteration : 2155
The accuracy of training : 0.712999999523
The loss of the training : 0.849055588245
Iteration : 2156
The accuracy of training : 0.73400002718
The loss of the training : 0.803085565567
Iteration : 2157
The accuracy of training : 0.694999992847
The loss of the training : 0.886693000793
Iteration : 2158
The accuracy of training : 0.716000020504
The loss of the training : 0.830813646317
Iteration : 2159
The accuracy of training : 0.704999983311
The loss of the training : 0.840484797955
Iteration : 2160
The accuracy of training : 0.714999973774
The loss of the training : 0.823116540909
Iteration : 2161
The accuracy of training : 0.728999972343
The loss of the training : 0.813971698284
Iteration : 2162
The accuracy of training : 0.722000002861
The loss of the training : 0.784833371639
Iteration : 2163
The accuracy of training : 0.70300000906
The loss of the training : 0.832030415535
Iteration : 2164
The accuracy of training : 0.704999983311
The loss of the training : 0.848095238209
Iteration : 2165
The accuracy of training : 0.699999988079
The loss of the training : 0.858924746513
Iteration : 2166
The accuracy of training : 0.714999973774
The loss of the training : 0.831622838974
Iteration : 2167
The accuracy of training : 0.700999975204
The loss of the training : 0.864746749401
Iteration : 2168
The accuracy of training : 0.735000014305
The loss of the training : 0.81620901823
Iteration : 2169
The accuracy of training : 0.713999986649
The loss of the training : 0.835786521435
Iteration : 2170
The accuracy of training : 0.694000005722
The loss of the training : 0.912911295891
Iteration : 2171
The accuracy of training : 0.695999979973
The loss of the training : 0.87475001812
Iteration : 2172
The accuracy of training : 0.703999996185
The loss of the training : 0.893345475197
Iteration : 2173
The accuracy of training : 0.722999989986
The loss of the training : 0.840994179249
Iteration : 2174
The accuracy of training : 0.703999996185
The loss of the training : 0.842057287693
Iteration : 2175
The accuracy of training : 0.683000028133
The loss of the training : 0.905407011509
Iteration : 2176
The accuracy of training : 0.699000000954
The loss of the training : 0.879542946815
Iteration : 2177
The accuracy of training : 0.736999988556
The loss of the training : 0.790362238884
Iteration : 2178
The accuracy of training : 0.700999975204
The loss of the training : 0.867497682571
Iteration : 2179
The accuracy of training : 0.704999983311
The loss of the training : 0.865050435066
Iteration : 2180
The accuracy of training : 0.697000026703
The loss of the training : 0.84715282917
Iteration : 2181
The accuracy of training : 0.717000007629
The loss of the training : 0.844834506512
Iteration : 2182
The accuracy of training : 0.721000015736
The loss of the training : 0.859796524048
Iteration : 2183
The accuracy of training : 0.71899998188
The loss of the training : 0.802005469799
Iteration : 2184
The accuracy of training : 0.713999986649
The loss of the training : 0.836419939995
Iteration : 2185
The accuracy of training : 0.689999997616
The loss of the training : 0.860526740551
Iteration : 2186
The accuracy of training : 0.723999977112
The loss of the training : 0.828590810299
Iteration : 2187
The accuracy of training : 0.713999986649
The loss of the training : 0.858061432838
Iteration : 2188
The accuracy of training : 0.71899998188
The loss of the training : 0.807432174683
Iteration : 2189
The accuracy of training : 0.714999973774
The loss of the training : 0.838456332684
Iteration : 2190
The accuracy of training : 0.71899998188
The loss of the training : 0.853336811066
Iteration : 2191
The accuracy of training : 0.71899998188
The loss of the training : 0.847446203232
Iteration : 2192
The accuracy of training : 0.68599998951
The loss of the training : 0.870163500309
Iteration : 2193
The accuracy of training : 0.670000016689
The loss of the training : 0.914316833019
Iteration : 2194
The accuracy of training : 0.700999975204
The loss of the training : 0.849826872349
Iteration : 2195
The accuracy of training : 0.716000020504
The loss of the training : 0.84467279911
Iteration : 2196
The accuracy of training : 0.735000014305
The loss of the training : 0.799712061882
Iteration : 2197
The accuracy of training : 0.695999979973
The loss of the training : 0.883082747459
Iteration : 2198
The accuracy of training : 0.713999986649
The loss of the training : 0.826928853989
Iteration : 2199
The accuracy of training : 0.708000004292
The loss of the training : 0.8369140625
Iteration : 2200
The accuracy of training : 0.717000007629
The loss of the training : 0.818893253803
Iteration : 2201
The accuracy of training : 0.73400002718
The loss of the training : 0.810496032238
Iteration : 2202
The accuracy of training : 0.72000002861
The loss of the training : 0.780725717545
Iteration : 2203
The accuracy of training : 0.707000017166
The loss of the training : 0.827245354652
Iteration : 2204
The accuracy of training : 0.707000017166
The loss of the training : 0.843014240265
Iteration : 2205
The accuracy of training : 0.709999978542
The loss of the training : 0.853488326073
Iteration : 2206
The accuracy of training : 0.714999973774
The loss of the training : 0.827758133411
Iteration : 2207
The accuracy of training : 0.70300000906
The loss of the training : 0.861553013325
Iteration : 2208
The accuracy of training : 0.73400002718
The loss of the training : 0.812876343727
Iteration : 2209
The accuracy of training : 0.712999999523
The loss of the training : 0.833351671696
Iteration : 2210
The accuracy of training : 0.694999992847
The loss of the training : 0.90953117609
Iteration : 2211
The accuracy of training : 0.698000013828
The loss of the training : 0.871348917484
Iteration : 2212
The accuracy of training : 0.705999970436
The loss of the training : 0.889554381371
Iteration : 2213
The accuracy of training : 0.723999977112
The loss of the training : 0.836847305298
Iteration : 2214
The accuracy of training : 0.707000017166
The loss of the training : 0.8375030756
Iteration : 2215
The accuracy of training : 0.683000028133
The loss of the training : 0.900607466698
Iteration : 2216
The accuracy of training : 0.699000000954
The loss of the training : 0.873977541924
Iteration : 2217
The accuracy of training : 0.736999988556
The loss of the training : 0.786270320415
Iteration : 2218
The accuracy of training : 0.699999988079
The loss of the training : 0.863490521908
Iteration : 2219
The accuracy of training : 0.705999970436
The loss of the training : 0.8605260849
Iteration : 2220
The accuracy of training : 0.697000026703
The loss of the training : 0.843349277973
Iteration : 2221
The accuracy of training : 0.713999986649
The loss of the training : 0.841142237186
Iteration : 2222
The accuracy of training : 0.723999977112
The loss of the training : 0.856566667557
Iteration : 2223
The accuracy of training : 0.717999994755
The loss of the training : 0.799163103104
Iteration : 2224
The accuracy of training : 0.713999986649
The loss of the training : 0.833032131195
Iteration : 2225
The accuracy of training : 0.691999971867
The loss of the training : 0.856879532337
Iteration : 2226
The accuracy of training : 0.725000023842
The loss of the training : 0.825130462646
Iteration : 2227
The accuracy of training : 0.716000020504
The loss of the training : 0.853847324848
Iteration : 2228
The accuracy of training : 0.722000002861
The loss of the training : 0.803960621357
Iteration : 2229
The accuracy of training : 0.716000020504
The loss of the training : 0.834259688854
Iteration : 2230
The accuracy of training : 0.716000020504
The loss of the training : 0.849373877048
Iteration : 2231
The accuracy of training : 0.71899998188
The loss of the training : 0.843048393726
Iteration : 2232
The accuracy of training : 0.688000023365
The loss of the training : 0.866183698177
Iteration : 2233
The accuracy of training : 0.672999978065
The loss of the training : 0.910933017731
Iteration : 2234
The accuracy of training : 0.702000021935
The loss of the training : 0.846183896065
Iteration : 2235
The accuracy of training : 0.717000007629
The loss of the training : 0.840409576893
Iteration : 2236
The accuracy of training : 0.735000014305
The loss of the training : 0.796452879906
Iteration : 2237
The accuracy of training : 0.697000026703
The loss of the training : 0.880150198936
Iteration : 2238
The accuracy of training : 0.714999973774
The loss of the training : 0.823126196861
Iteration : 2239
The accuracy of training : 0.711000025272
The loss of the training : 0.833179831505
Iteration : 2240
The accuracy of training : 0.71899998188
The loss of the training : 0.814879894257
Iteration : 2241
The accuracy of training : 0.735000014305
The loss of the training : 0.807733535767
Iteration : 2242
The accuracy of training : 0.723999977112
The loss of the training : 0.777262151241
Iteration : 2243
The accuracy of training : 0.708999991417
The loss of the training : 0.823748588562
Iteration : 2244
The accuracy of training : 0.708999991417
The loss of the training : 0.839705049992
Iteration : 2245
The accuracy of training : 0.712000012398
The loss of the training : 0.849887728691
Iteration : 2246
The accuracy of training : 0.717999994755
The loss of the training : 0.825237631798
Iteration : 2247
The accuracy of training : 0.707000017166
The loss of the training : 0.858692884445
Iteration : 2248
The accuracy of training : 0.740000009537
The loss of the training : 0.809237003326
Iteration : 2249
The accuracy of training : 0.711000025272
The loss of the training : 0.82958984375
Iteration : 2250
The accuracy of training : 0.694999992847
The loss of the training : 0.905388116837
Iteration : 2251
The accuracy of training : 0.700999975204
The loss of the training : 0.866658270359
Iteration : 2252
The accuracy of training : 0.704999983311
The loss of the training : 0.885450720787
Iteration : 2253
The accuracy of training : 0.727999985218
The loss of the training : 0.832932412624
Iteration : 2254
The accuracy of training : 0.709999978542
The loss of the training : 0.833151161671
Iteration : 2255
The accuracy of training : 0.684000015259
The loss of the training : 0.89517301321
Iteration : 2256
The accuracy of training : 0.698000013828
The loss of the training : 0.869136691093
Iteration : 2257
The accuracy of training : 0.735000014305
The loss of the training : 0.782634317875
Iteration : 2258
The accuracy of training : 0.702000021935
The loss of the training : 0.859795212746
Iteration : 2259
The accuracy of training : 0.707000017166
The loss of the training : 0.856508433819
Iteration : 2260
The accuracy of training : 0.699999988079
The loss of the training : 0.839486598969
Iteration : 2261
The accuracy of training : 0.722000002861
The loss of the training : 0.837418735027
Iteration : 2262
The accuracy of training : 0.726000010967
The loss of the training : 0.853504657745
Iteration : 2263
The accuracy of training : 0.72000002861
The loss of the training : 0.796129047871
Iteration : 2264
The accuracy of training : 0.712999999523
The loss of the training : 0.829503834248
Iteration : 2265
The accuracy of training : 0.694000005722
The loss of the training : 0.853067815304
Iteration : 2266
The accuracy of training : 0.723999977112
The loss of the training : 0.82199794054
Iteration : 2267
The accuracy of training : 0.716000020504
The loss of the training : 0.850334584713
Iteration : 2268
The accuracy of training : 0.722000002861
The loss of the training : 0.801281750202
Iteration : 2269
The accuracy of training : 0.717000007629
The loss of the training : 0.830769538879
Iteration : 2270
The accuracy of training : 0.721000015736
The loss of the training : 0.846309840679
Iteration : 2271
The accuracy of training : 0.717999994755
The loss of the training : 0.839348137379
Iteration : 2272
The accuracy of training : 0.690999984741
The loss of the training : 0.862414836884
Iteration : 2273
The accuracy of training : 0.67199999094
The loss of the training : 0.907846152782
Iteration : 2274
The accuracy of training : 0.702000021935
The loss of the training : 0.84298402071
Iteration : 2275
The accuracy of training : 0.717000007629
The loss of the training : 0.836689651012
Iteration : 2276
The accuracy of training : 0.735000014305
The loss of the training : 0.793457508087
Iteration : 2277
The accuracy of training : 0.698000013828
The loss of the training : 0.87719810009
Iteration : 2278
The accuracy of training : 0.716000020504
The loss of the training : 0.819751858711
Iteration : 2279
The accuracy of training : 0.716000020504
The loss of the training : 0.829744160175
Iteration : 2280
The accuracy of training : 0.722999989986
The loss of the training : 0.810965359211
Iteration : 2281
The accuracy of training : 0.736999988556
The loss of the training : 0.805040001869
Iteration : 2282
The accuracy of training : 0.726000010967
The loss of the training : 0.773899316788
Iteration : 2283
The accuracy of training : 0.709999978542
The loss of the training : 0.820395767689
Iteration : 2284
The accuracy of training : 0.709999978542
The loss of the training : 0.836678981781
Iteration : 2285
The accuracy of training : 0.714999973774
The loss of the training : 0.846539974213
Iteration : 2286
The accuracy of training : 0.717000007629
The loss of the training : 0.821825861931
Iteration : 2287
The accuracy of training : 0.707000017166
The loss of the training : 0.855646431446
Iteration : 2288
The accuracy of training : 0.740000009537
The loss of the training : 0.806145071983
Iteration : 2289
The accuracy of training : 0.713999986649
The loss of the training : 0.826012015343
Iteration : 2290
The accuracy of training : 0.697000026703
The loss of the training : 0.901191413403
Iteration : 2291
The accuracy of training : 0.703999996185
The loss of the training : 0.861954510212
Iteration : 2292
The accuracy of training : 0.707000017166
The loss of the training : 0.881338775158
Iteration : 2293
The accuracy of training : 0.726000010967
The loss of the training : 0.829558491707
Iteration : 2294
The accuracy of training : 0.711000025272
The loss of the training : 0.829246759415
Iteration : 2295
The accuracy of training : 0.685000002384
The loss of the training : 0.89064091444
Iteration : 2296
The accuracy of training : 0.703999996185
The loss of the training : 0.864665687084
Iteration : 2297
The accuracy of training : 0.737999975681
The loss of the training : 0.779338300228
Iteration : 2298
The accuracy of training : 0.703999996185
The loss of the training : 0.856276988983
Iteration : 2299
The accuracy of training : 0.707000017166
The loss of the training : 0.852518081665
Iteration : 2300
The accuracy of training : 0.704999983311
The loss of the training : 0.836004137993
Iteration : 2301
The accuracy of training : 0.725000023842
The loss of the training : 0.833842694759
Iteration : 2302
The accuracy of training : 0.725000023842
The loss of the training : 0.850594341755
Iteration : 2303
The accuracy of training : 0.721000015736
The loss of the training : 0.79326236248
Iteration : 2304
The accuracy of training : 0.712000012398
The loss of the training : 0.826334774494
Iteration : 2305
The accuracy of training : 0.694999992847
The loss of the training : 0.849681675434
Iteration : 2306
The accuracy of training : 0.726000010967
The loss of the training : 0.818661808968
Iteration : 2307
The accuracy of training : 0.717000007629
The loss of the training : 0.846906304359
Iteration : 2308
The accuracy of training : 0.721000015736
The loss of the training : 0.798648059368
Iteration : 2309
The accuracy of training : 0.716000020504
The loss of the training : 0.827294170856
Iteration : 2310
The accuracy of training : 0.722999989986
The loss of the training : 0.843008935452
Iteration : 2311
The accuracy of training : 0.717999994755
The loss of the training : 0.835823893547
Iteration : 2312
The accuracy of training : 0.693000018597
The loss of the training : 0.85898911953
Iteration : 2313
The accuracy of training : 0.67199999094
The loss of the training : 0.904830694199
Iteration : 2314
The accuracy of training : 0.703999996185
The loss of the training : 0.839828312397
Iteration : 2315
The accuracy of training : 0.72000002861
The loss of the training : 0.833148479462
Iteration : 2316
The accuracy of training : 0.73400002718
The loss of the training : 0.790465712547
Iteration : 2317
The accuracy of training : 0.697000026703
The loss of the training : 0.873769938946
Iteration : 2318
The accuracy of training : 0.71899998188
The loss of the training : 0.816344618797
Iteration : 2319
The accuracy of training : 0.71899998188
The loss of the training : 0.826637983322
Iteration : 2320
The accuracy of training : 0.721000015736
The loss of the training : 0.807359457016
Iteration : 2321
The accuracy of training : 0.739000022411
The loss of the training : 0.802383244038
Iteration : 2322
The accuracy of training : 0.727999985218
The loss of the training : 0.770695865154
Iteration : 2323
The accuracy of training : 0.711000025272
The loss of the training : 0.816821992397
Iteration : 2324
The accuracy of training : 0.712000012398
The loss of the training : 0.832949817181
Iteration : 2325
The accuracy of training : 0.713999986649
The loss of the training : 0.842627465725
Iteration : 2326
The accuracy of training : 0.717999994755
The loss of the training : 0.819289147854
Iteration : 2327
The accuracy of training : 0.708000004292
The loss of the training : 0.853247106075
Iteration : 2328
The accuracy of training : 0.740999996662
The loss of the training : 0.80316400528
Iteration : 2329
The accuracy of training : 0.712000012398
The loss of the training : 0.822953760624
Iteration : 2330
The accuracy of training : 0.697000026703
The loss of the training : 0.897794485092
Iteration : 2331
The accuracy of training : 0.70300000906
The loss of the training : 0.85811406374
Iteration : 2332
The accuracy of training : 0.708000004292
The loss of the training : 0.877724468708
Iteration : 2333
The accuracy of training : 0.728999972343
The loss of the training : 0.826021790504
Iteration : 2334
The accuracy of training : 0.712999999523
The loss of the training : 0.825618803501
Iteration : 2335
The accuracy of training : 0.686999976635
The loss of the training : 0.886406540871
Iteration : 2336
The accuracy of training : 0.708000004292
The loss of the training : 0.860297620296
Iteration : 2337
The accuracy of training : 0.737999975681
The loss of the training : 0.776229858398
Iteration : 2338
The accuracy of training : 0.70300000906
The loss of the training : 0.853214859962
Iteration : 2339
The accuracy of training : 0.707000017166
The loss of the training : 0.8488265872
Iteration : 2340
The accuracy of training : 0.703999996185
The loss of the training : 0.832903623581
Iteration : 2341
The accuracy of training : 0.726000010967
The loss of the training : 0.830550730228
Iteration : 2342
The accuracy of training : 0.725000023842
The loss of the training : 0.847666084766
Iteration : 2343
The accuracy of training : 0.722000002861
The loss of the training : 0.790445446968
Iteration : 2344
The accuracy of training : 0.712000012398
The loss of the training : 0.822965502739
Iteration : 2345
The accuracy of training : 0.697000026703
The loss of the training : 0.846755325794
Iteration : 2346
The accuracy of training : 0.727999985218
The loss of the training : 0.815437674522
Iteration : 2347
The accuracy of training : 0.71899998188
The loss of the training : 0.843656718731
Iteration : 2348
The accuracy of training : 0.723999977112
The loss of the training : 0.795966863632
Iteration : 2349
The accuracy of training : 0.716000020504
The loss of the training : 0.823980271816
Iteration : 2350
The accuracy of training : 0.726000010967
The loss of the training : 0.840060114861
Iteration : 2351
The accuracy of training : 0.72000002861
The loss of the training : 0.832336127758
Iteration : 2352
The accuracy of training : 0.698000013828
The loss of the training : 0.855553984642
Iteration : 2353
The accuracy of training : 0.672999978065
The loss of the training : 0.902212619781
Iteration : 2354
The accuracy of training : 0.705999970436
The loss of the training : 0.836956977844
Iteration : 2355
The accuracy of training : 0.722999989986
The loss of the training : 0.829533576965
Iteration : 2356
The accuracy of training : 0.736000001431
The loss of the training : 0.787665069103
Iteration : 2357
The accuracy of training : 0.697000026703
The loss of the training : 0.871194601059
Iteration : 2358
The accuracy of training : 0.72000002861
The loss of the training : 0.813324868679
Iteration : 2359
The accuracy of training : 0.71899998188
The loss of the training : 0.823420166969
Iteration : 2360
The accuracy of training : 0.725000023842
The loss of the training : 0.803720474243
Iteration : 2361
The accuracy of training : 0.739000022411
The loss of the training : 0.79969984293
Iteration : 2362
The accuracy of training : 0.731000006199
The loss of the training : 0.767570734024
Iteration : 2363
The accuracy of training : 0.709999978542
The loss of the training : 0.813815712929
Iteration : 2364
The accuracy of training : 0.712000012398
The loss of the training : 0.830187261105
Iteration : 2365
The accuracy of training : 0.714999973774
The loss of the training : 0.839544832706
Iteration : 2366
The accuracy of training : 0.717000007629
The loss of the training : 0.816644430161
Iteration : 2367
The accuracy of training : 0.708999991417
The loss of the training : 0.850377976894
Iteration : 2368
The accuracy of training : 0.741999983788
The loss of the training : 0.799976468086
Iteration : 2369
The accuracy of training : 0.714999973774
The loss of the training : 0.819635152817
Iteration : 2370
The accuracy of training : 0.698000013828
The loss of the training : 0.893504440784
Iteration : 2371
The accuracy of training : 0.703999996185
The loss of the training : 0.853433489799
Iteration : 2372
The accuracy of training : 0.708999991417
The loss of the training : 0.874283373356
Iteration : 2373
The accuracy of training : 0.730000019073
The loss of the training : 0.822547256947
Iteration : 2374
The accuracy of training : 0.712999999523
The loss of the training : 0.822184860706
Iteration : 2375
The accuracy of training : 0.68900001049
The loss of the training : 0.883045136929
Iteration : 2376
The accuracy of training : 0.708000004292
The loss of the training : 0.856645166874
Iteration : 2377
The accuracy of training : 0.736999988556
The loss of the training : 0.773382604122
Iteration : 2378
The accuracy of training : 0.70300000906
The loss of the training : 0.850247085094
Iteration : 2379
The accuracy of training : 0.708000004292
The loss of the training : 0.845488607883
Iteration : 2380
The accuracy of training : 0.702000021935
The loss of the training : 0.829701602459
Iteration : 2381
The accuracy of training : 0.728999972343
The loss of the training : 0.827356815338
Iteration : 2382
The accuracy of training : 0.726000010967
The loss of the training : 0.844850182533
Iteration : 2383
The accuracy of training : 0.722000002861
The loss of the training : 0.787723064423
Iteration : 2384
The accuracy of training : 0.716000020504
The loss of the training : 0.81977802515
Iteration : 2385
The accuracy of training : 0.699000000954
The loss of the training : 0.843900859356
Iteration : 2386
The accuracy of training : 0.731999993324
The loss of the training : 0.812448382378
Iteration : 2387
The accuracy of training : 0.722000002861
The loss of the training : 0.840607702732
Iteration : 2388
The accuracy of training : 0.726999998093
The loss of the training : 0.793664097786
Iteration : 2389
The accuracy of training : 0.713999986649
The loss of the training : 0.820982456207
Iteration : 2390
The accuracy of training : 0.725000023842
The loss of the training : 0.837139308453
Iteration : 2391
The accuracy of training : 0.722000002861
The loss of the training : 0.829242289066
Iteration : 2392
The accuracy of training : 0.699000000954
The loss of the training : 0.852364122868
Iteration : 2393
The accuracy of training : 0.672999978065
The loss of the training : 0.89933437109
Iteration : 2394
The accuracy of training : 0.708000004292
The loss of the training : 0.834098577499
Iteration : 2395
The accuracy of training : 0.723999977112
The loss of the training : 0.826232731342
Iteration : 2396
The accuracy of training : 0.735000014305
The loss of the training : 0.785154879093
Iteration : 2397
The accuracy of training : 0.698000013828
The loss of the training : 0.868605613708
Iteration : 2398
The accuracy of training : 0.721000015736
The loss of the training : 0.8102465868
Iteration : 2399
The accuracy of training : 0.721000015736
The loss of the training : 0.820587456226
Iteration : 2400
The accuracy of training : 0.726999998093
The loss of the training : 0.800436198711
Iteration : 2401
The accuracy of training : 0.740000009537
The loss of the training : 0.797317922115
Iteration : 2402
The accuracy of training : 0.731999993324
The loss of the training : 0.764515817165
Iteration : 2403
The accuracy of training : 0.711000025272
The loss of the training : 0.810897171497
Iteration : 2404
The accuracy of training : 0.712999999523
The loss of the training : 0.827370405197
Iteration : 2405
The accuracy of training : 0.714999973774
The loss of the training : 0.836437284946
Iteration : 2406
The accuracy of training : 0.71899998188
The loss of the training : 0.813974916935
Iteration : 2407
The accuracy of training : 0.712000012398
The loss of the training : 0.847555220127
Iteration : 2408
The accuracy of training : 0.740000009537
The loss of the training : 0.797247111797
Iteration : 2409
The accuracy of training : 0.717000007629
The loss of the training : 0.81645655632
Iteration : 2410
The accuracy of training : 0.699000000954
The loss of the training : 0.889429867268
Iteration : 2411
The accuracy of training : 0.704999983311
The loss of the training : 0.848716974258
Iteration : 2412
The accuracy of training : 0.707000017166
The loss of the training : 0.870906054974
Iteration : 2413
The accuracy of training : 0.730000019073
The loss of the training : 0.819549977779
Iteration : 2414
The accuracy of training : 0.714999973774
The loss of the training : 0.819089114666
Iteration : 2415
The accuracy of training : 0.693000018597
The loss of the training : 0.879772007465
Iteration : 2416
The accuracy of training : 0.709999978542
The loss of the training : 0.853479862213
Iteration : 2417
The accuracy of training : 0.737999975681
The loss of the training : 0.770630419254
Iteration : 2418
The accuracy of training : 0.702000021935
The loss of the training : 0.847435951233
Iteration : 2419
The accuracy of training : 0.711000025272
The loss of the training : 0.842159092426
Iteration : 2420
The accuracy of training : 0.702000021935
The loss of the training : 0.82696801424
Iteration : 2421
The accuracy of training : 0.728999972343
The loss of the training : 0.824475109577
Iteration : 2422
The accuracy of training : 0.726999998093
The loss of the training : 0.842260479927
Iteration : 2423
The accuracy of training : 0.725000023842
The loss of the training : 0.785319030285
Iteration : 2424
The accuracy of training : 0.716000020504
The loss of the training : 0.816805541515
Iteration : 2425
The accuracy of training : 0.699999988079
The loss of the training : 0.841283023357
Iteration : 2426
The accuracy of training : 0.73400002718
The loss of the training : 0.80979347229
Iteration : 2427
The accuracy of training : 0.722999989986
The loss of the training : 0.837355136871
Iteration : 2428
The accuracy of training : 0.726999998093
The loss of the training : 0.791261613369
Iteration : 2429
The accuracy of training : 0.71899998188
The loss of the training : 0.817905187607
Iteration : 2430
The accuracy of training : 0.726999998093
The loss of the training : 0.834543645382
Iteration : 2431
The accuracy of training : 0.722999989986
The loss of the training : 0.826383292675
Iteration : 2432
The accuracy of training : 0.700999975204
The loss of the training : 0.849184393883
Iteration : 2433
The accuracy of training : 0.672999978065
The loss of the training : 0.896495044231
Iteration : 2434
The accuracy of training : 0.705999970436
The loss of the training : 0.831104695797
Iteration : 2435
The accuracy of training : 0.725000023842
The loss of the training : 0.822903335094
Iteration : 2436
The accuracy of training : 0.736999988556
The loss of the training : 0.782832801342
Iteration : 2437
The accuracy of training : 0.699000000954
The loss of the training : 0.86628985405
Iteration : 2438
The accuracy of training : 0.722000002861
The loss of the training : 0.807405412197
Iteration : 2439
The accuracy of training : 0.722999989986
The loss of the training : 0.817845702171
Iteration : 2440
The accuracy of training : 0.727999985218
The loss of the training : 0.797400891781
Iteration : 2441
The accuracy of training : 0.740999996662
The loss of the training : 0.795062184334
Iteration : 2442
The accuracy of training : 0.731999993324
The loss of the training : 0.761615872383
Iteration : 2443
The accuracy of training : 0.712000012398
The loss of the training : 0.808192074299
Iteration : 2444
The accuracy of training : 0.712999999523
The loss of the training : 0.824967086315
Iteration : 2445
The accuracy of training : 0.716000020504
The loss of the training : 0.833665430546
Iteration : 2446
The accuracy of training : 0.72000002861
The loss of the training : 0.811985135078
Iteration : 2447
The accuracy of training : 0.713999986649
The loss of the training : 0.845189154148
Iteration : 2448
The accuracy of training : 0.740999996662
The loss of the training : 0.794309139252
Iteration : 2449
The accuracy of training : 0.713999986649
The loss of the training : 0.8130813241
Iteration : 2450
The accuracy of training : 0.700999975204
The loss of the training : 0.885264158249
Iteration : 2451
The accuracy of training : 0.703999996185
The loss of the training : 0.845102310181
Iteration : 2452
The accuracy of training : 0.708999991417
The loss of the training : 0.868014395237
Iteration : 2453
The accuracy of training : 0.73299998045
The loss of the training : 0.81698012352
Iteration : 2454
The accuracy of training : 0.717000007629
The loss of the training : 0.815986871719
Iteration : 2455
The accuracy of training : 0.695999979973
The loss of the training : 0.876211941242
Iteration : 2456
The accuracy of training : 0.712000012398
The loss of the training : 0.850222110748
Iteration : 2457
The accuracy of training : 0.739000022411
The loss of the training : 0.768329024315
Iteration : 2458
The accuracy of training : 0.702000021935
The loss of the training : 0.844907283783
Iteration : 2459
The accuracy of training : 0.711000025272
The loss of the training : 0.839141488075
Iteration : 2460
The accuracy of training : 0.70300000906
The loss of the training : 0.824131071568
Iteration : 2461
The accuracy of training : 0.728999972343
The loss of the training : 0.821636140347
Iteration : 2462
The accuracy of training : 0.727999985218
The loss of the training : 0.839964389801
Iteration : 2463
The accuracy of training : 0.725000023842
The loss of the training : 0.782850265503
Iteration : 2464
The accuracy of training : 0.717999994755
The loss of the training : 0.813938975334
Iteration : 2465
The accuracy of training : 0.699999988079
The loss of the training : 0.8386541605
Iteration : 2466
The accuracy of training : 0.731999993324
The loss of the training : 0.807138323784
Iteration : 2467
The accuracy of training : 0.726000010967
The loss of the training : 0.834570109844
Iteration : 2468
The accuracy of training : 0.726000010967
The loss of the training : 0.789113521576
Iteration : 2469
The accuracy of training : 0.722000002861
The loss of the training : 0.815066337585
Iteration : 2470
The accuracy of training : 0.730000019073
The loss of the training : 0.831943511963
Iteration : 2471
The accuracy of training : 0.722999989986
The loss of the training : 0.823436200619
Iteration : 2472
The accuracy of training : 0.700999975204
The loss of the training : 0.846127748489
Iteration : 2473
The accuracy of training : 0.672999978065
The loss of the training : 0.893912255764
Iteration : 2474
The accuracy of training : 0.708000004292
The loss of the training : 0.828321576118
Iteration : 2475
The accuracy of training : 0.730000019073
The loss of the training : 0.819964647293
Iteration : 2476
The accuracy of training : 0.736000001431
The loss of the training : 0.780379056931
Iteration : 2477
The accuracy of training : 0.698000013828
The loss of the training : 0.864067435265
Iteration : 2478
The accuracy of training : 0.721000015736
The loss of the training : 0.804754137993
Iteration : 2479
The accuracy of training : 0.726000010967
The loss of the training : 0.814978063107
Iteration : 2480
The accuracy of training : 0.726999998093
The loss of the training : 0.79432195425
Iteration : 2481
The accuracy of training : 0.745000004768
The loss of the training : 0.792907834053
Iteration : 2482
The accuracy of training : 0.73299998045
The loss of the training : 0.758946597576
Iteration : 2483
The accuracy of training : 0.712000012398
The loss of the training : 0.805643677711
Iteration : 2484
The accuracy of training : 0.712999999523
The loss of the training : 0.822628200054
Iteration : 2485
The accuracy of training : 0.717999994755
The loss of the training : 0.830910086632
Iteration : 2486
The accuracy of training : 0.72000002861
The loss of the training : 0.809708833694
Iteration : 2487
The accuracy of training : 0.713999986649
The loss of the training : 0.842791557312
Iteration : 2488
The accuracy of training : 0.745000004768
The loss of the training : 0.791590988636
Iteration : 2489
The accuracy of training : 0.713999986649
The loss of the training : 0.810319364071
Iteration : 2490
The accuracy of training : 0.70300000906
The loss of the training : 0.881546795368
Iteration : 2491
The accuracy of training : 0.703999996185
The loss of the training : 0.84143871069
Iteration : 2492
The accuracy of training : 0.711000025272
The loss of the training : 0.865413308144
Iteration : 2493
The accuracy of training : 0.73400002718
The loss of the training : 0.814622700214
Iteration : 2494
The accuracy of training : 0.717000007629
The loss of the training : 0.813335955143
Iteration : 2495
The accuracy of training : 0.697000026703
The loss of the training : 0.873319506645
Iteration : 2496
The accuracy of training : 0.712999999523
The loss of the training : 0.84746414423
Iteration : 2497
The accuracy of training : 0.740000009537
The loss of the training : 0.765813946724
Iteration : 2498
The accuracy of training : 0.703999996185
The loss of the training : 0.842580735683
Iteration : 2499
The accuracy of training : 0.712999999523
The loss of the training : 0.836392879486
Iteration : 2500
The accuracy of training : 0.703999996185
The loss of the training : 0.821562170982
Iteration : 2501
The accuracy of training : 0.730000019073
The loss of the training : 0.818969666958
Iteration : 2502
The accuracy of training : 0.730000019073
The loss of the training : 0.837763249874
Iteration : 2503
The accuracy of training : 0.725000023842
The loss of the training : 0.780522346497
Iteration : 2504
The accuracy of training : 0.71899998188
The loss of the training : 0.811455607414
Iteration : 2505
The accuracy of training : 0.700999975204
The loss of the training : 0.836218178272
Iteration : 2506
The accuracy of training : 0.731999993324
The loss of the training : 0.80478310585
Iteration : 2507
The accuracy of training : 0.725000023842
The loss of the training : 0.831949114799
Iteration : 2508
The accuracy of training : 0.726000010967
The loss of the training : 0.786818146706
Iteration : 2509
The accuracy of training : 0.722000002861
The loss of the training : 0.812149167061
Iteration : 2510
The accuracy of training : 0.731000006199
The loss of the training : 0.82957816124
Iteration : 2511
The accuracy of training : 0.723999977112
The loss of the training : 0.820547997952
Iteration : 2512
The accuracy of training : 0.702000021935
The loss of the training : 0.843294262886
Iteration : 2513
The accuracy of training : 0.672999978065
The loss of the training : 0.891434431076
Iteration : 2514
The accuracy of training : 0.707000017166
The loss of the training : 0.825736999512
Iteration : 2515
The accuracy of training : 0.731000006199
The loss of the training : 0.817081809044
Iteration : 2516
The accuracy of training : 0.736000001431
The loss of the training : 0.778021633625
Iteration : 2517
The accuracy of training : 0.699000000954
The loss of the training : 0.86161082983
Iteration : 2518
The accuracy of training : 0.721000015736
The loss of the training : 0.802068412304
Iteration : 2519
The accuracy of training : 0.726000010967
The loss of the training : 0.812361299992
Iteration : 2520
The accuracy of training : 0.726999998093
The loss of the training : 0.791645169258
Iteration : 2521
The accuracy of training : 0.745999991894
The loss of the training : 0.790713310242
Iteration : 2522
The accuracy of training : 0.736000001431
The loss of the training : 0.756273508072
Iteration : 2523
The accuracy of training : 0.713999986649
The loss of the training : 0.803223669529
Iteration : 2524
The accuracy of training : 0.713999986649
The loss of the training : 0.820191919804
Iteration : 2525
The accuracy of training : 0.717000007629
The loss of the training : 0.82835817337
Iteration : 2526
The accuracy of training : 0.722000002861
The loss of the training : 0.807958066463
Iteration : 2527
The accuracy of training : 0.714999973774
The loss of the training : 0.840628504753
Iteration : 2528
The accuracy of training : 0.748000025749
The loss of the training : 0.788986802101
Iteration : 2529
The accuracy of training : 0.713999986649
The loss of the training : 0.807501733303
Iteration : 2530
The accuracy of training : 0.703999996185
The loss of the training : 0.878041088581
Iteration : 2531
The accuracy of training : 0.703999996185
The loss of the training : 0.83794438839
Iteration : 2532
The accuracy of training : 0.712999999523
The loss of the training : 0.862634181976
Iteration : 2533
The accuracy of training : 0.736000001431
The loss of the training : 0.812152147293
Iteration : 2534
The accuracy of training : 0.717000007629
The loss of the training : 0.810633182526
Iteration : 2535
The accuracy of training : 0.699000000954
The loss of the training : 0.870401501656
Iteration : 2536
The accuracy of training : 0.712999999523
The loss of the training : 0.844570696354
Iteration : 2537
The accuracy of training : 0.742999970913
The loss of the training : 0.763741374016
Iteration : 2538
The accuracy of training : 0.704999983311
The loss of the training : 0.840266406536
Iteration : 2539
The accuracy of training : 0.712999999523
The loss of the training : 0.833722531796
Iteration : 2540
The accuracy of training : 0.707000017166
The loss of the training : 0.81887614727
Iteration : 2541
The accuracy of training : 0.730000019073
The loss of the training : 0.816403865814
Iteration : 2542
The accuracy of training : 0.731000006199
The loss of the training : 0.835434675217
Iteration : 2543
The accuracy of training : 0.725000023842
The loss of the training : 0.778239250183
Iteration : 2544
The accuracy of training : 0.721000015736
The loss of the training : 0.808828413486
Iteration : 2545
The accuracy of training : 0.699999988079
The loss of the training : 0.833791792393
Iteration : 2546
The accuracy of training : 0.731999993324
The loss of the training : 0.802436590195
Iteration : 2547
The accuracy of training : 0.725000023842
The loss of the training : 0.829367697239
Iteration : 2548
The accuracy of training : 0.726000010967
The loss of the training : 0.784768462181
Iteration : 2549
The accuracy of training : 0.722999989986
The loss of the training : 0.809631705284
Iteration : 2550
The accuracy of training : 0.73299998045
The loss of the training : 0.827186405659
Iteration : 2551
The accuracy of training : 0.726000010967
The loss of the training : 0.817657768726
Iteration : 2552
The accuracy of training : 0.702000021935
The loss of the training : 0.840410888195
Iteration : 2553
The accuracy of training : 0.674000024796
The loss of the training : 0.889278829098
Iteration : 2554
The accuracy of training : 0.707000017166
The loss of the training : 0.823230862617
Iteration : 2555
The accuracy of training : 0.730000019073
The loss of the training : 0.814346790314
Iteration : 2556
The accuracy of training : 0.736000001431
The loss of the training : 0.77591663599
Iteration : 2557
The accuracy of training : 0.699000000954
The loss of the training : 0.859560847282
Iteration : 2558
The accuracy of training : 0.72000002861
The loss of the training : 0.799458801746
Iteration : 2559
The accuracy of training : 0.726999998093
The loss of the training : 0.809882998466
Iteration : 2560
The accuracy of training : 0.731000006199
The loss of the training : 0.788908362389
Iteration : 2561
The accuracy of training : 0.745999991894
The loss of the training : 0.788586437702
Iteration : 2562
The accuracy of training : 0.736999988556
The loss of the training : 0.753763079643
Iteration : 2563
The accuracy of training : 0.713999986649
The loss of the training : 0.800730288029
Iteration : 2564
The accuracy of training : 0.714999973774
The loss of the training : 0.817784488201
Iteration : 2565
The accuracy of training : 0.717999994755
The loss of the training : 0.825729191303
Iteration : 2566
The accuracy of training : 0.722000002861
The loss of the training : 0.805783212185
Iteration : 2567
The accuracy of training : 0.714999973774
The loss of the training : 0.838323175907
Iteration : 2568
The accuracy of training : 0.748000025749
The loss of the training : 0.786519825459
Iteration : 2569
The accuracy of training : 0.714999973774
The loss of the training : 0.804993391037
Iteration : 2570
The accuracy of training : 0.705999970436
The loss of the training : 0.874625205994
Iteration : 2571
The accuracy of training : 0.707000017166
The loss of the training : 0.834451019764
Iteration : 2572
The accuracy of training : 0.712000012398
The loss of the training : 0.860164940357
Iteration : 2573
The accuracy of training : 0.736999988556
The loss of the training : 0.809701442719
Iteration : 2574
The accuracy of training : 0.714999973774
The loss of the training : 0.808074593544
Iteration : 2575
The accuracy of training : 0.699000000954
The loss of the training : 0.867542743683
Iteration : 2576
The accuracy of training : 0.712999999523
The loss of the training : 0.842188298702
Iteration : 2577
The accuracy of training : 0.745000004768
The loss of the training : 0.761667251587
Iteration : 2578
The accuracy of training : 0.705999970436
The loss of the training : 0.83804166317
Iteration : 2579
The accuracy of training : 0.712000012398
The loss of the training : 0.831103384495
Iteration : 2580
The accuracy of training : 0.707000017166
The loss of the training : 0.816520631313
Iteration : 2581
The accuracy of training : 0.731000006199
The loss of the training : 0.813891291618
Iteration : 2582
The accuracy of training : 0.731999993324
The loss of the training : 0.833250522614
Iteration : 2583
The accuracy of training : 0.727999985218
The loss of the training : 0.776304125786
Iteration : 2584
The accuracy of training : 0.726000010967
The loss of the training : 0.806306302547
Iteration : 2585
The accuracy of training : 0.699000000954
The loss of the training : 0.831571936607
Iteration : 2586
The accuracy of training : 0.73400002718
The loss of the training : 0.800130426884
Iteration : 2587
The accuracy of training : 0.723999977112
The loss of the training : 0.826873958111
Iteration : 2588
The accuracy of training : 0.726000010967
The loss of the training : 0.782763600349
Iteration : 2589
The accuracy of training : 0.722999989986
The loss of the training : 0.807134389877
Iteration : 2590
The accuracy of training : 0.73400002718
The loss of the training : 0.825069010258
Iteration : 2591
The accuracy of training : 0.727999985218
The loss of the training : 0.814965009689
Iteration : 2592
The accuracy of training : 0.702000021935
The loss of the training : 0.837853491306
Iteration : 2593
The accuracy of training : 0.675000011921
The loss of the training : 0.886781096458
Iteration : 2594
The accuracy of training : 0.708000004292
The loss of the training : 0.820550084114
Iteration : 2595
The accuracy of training : 0.731999993324
The loss of the training : 0.811649084091
Iteration : 2596
The accuracy of training : 0.736999988556
The loss of the training : 0.773871779442
Iteration : 2597
The accuracy of training : 0.700999975204
The loss of the training : 0.857518613338
Iteration : 2598
The accuracy of training : 0.721000015736
The loss of the training : 0.797071814537
Iteration : 2599
The accuracy of training : 0.730000019073
The loss of the training : 0.807444989681
Iteration : 2600
The accuracy of training : 0.731999993324
The loss of the training : 0.786423742771
Iteration : 2601
The accuracy of training : 0.748000025749
The loss of the training : 0.786550223827
Iteration : 2602
The accuracy of training : 0.740999996662
The loss of the training : 0.751203536987
Iteration : 2603
The accuracy of training : 0.717000007629
The loss of the training : 0.79840105772
Iteration : 2604
The accuracy of training : 0.713999986649
The loss of the training : 0.815484523773
Iteration : 2605
The accuracy of training : 0.717999994755
The loss of the training : 0.823358952999
Iteration : 2606
The accuracy of training : 0.722999989986
The loss of the training : 0.803744673729
Iteration : 2607
The accuracy of training : 0.714999973774
The loss of the training : 0.83604824543
Iteration : 2608
The accuracy of training : 0.748000025749
The loss of the training : 0.784012019634
Iteration : 2609
The accuracy of training : 0.71899998188
The loss of the training : 0.802268862724
Iteration : 2610
The accuracy of training : 0.708000004292
The loss of the training : 0.871237754822
Iteration : 2611
The accuracy of training : 0.708000004292
The loss of the training : 0.831119835377
Iteration : 2612
The accuracy of training : 0.712000012398
The loss of the training : 0.857656478882
Iteration : 2613
The accuracy of training : 0.736000001431
The loss of the training : 0.807294845581
Iteration : 2614
The accuracy of training : 0.716000020504
The loss of the training : 0.805668354034
Iteration : 2615
The accuracy of training : 0.699000000954
The loss of the training : 0.86481744051
Iteration : 2616
The accuracy of training : 0.713999986649
The loss of the training : 0.83970952034
Iteration : 2617
The accuracy of training : 0.744000017643
The loss of the training : 0.759489834309
Iteration : 2618
The accuracy of training : 0.704999983311
The loss of the training : 0.835908174515
Iteration : 2619
The accuracy of training : 0.712999999523
The loss of the training : 0.828686892986
Iteration : 2620
The accuracy of training : 0.709999978542
The loss of the training : 0.814183294773
Iteration : 2621
The accuracy of training : 0.73299998045
The loss of the training : 0.811438858509
Iteration : 2622
The accuracy of training : 0.73400002718
The loss of the training : 0.831167161465
Iteration : 2623
The accuracy of training : 0.727999985218
The loss of the training : 0.774221837521
Iteration : 2624
The accuracy of training : 0.726999998093
The loss of the training : 0.803911626339
Iteration : 2625
The accuracy of training : 0.698000013828
The loss of the training : 0.829376041889
Iteration : 2626
The accuracy of training : 0.736000001431
The loss of the training : 0.798038840294
Iteration : 2627
The accuracy of training : 0.723999977112
The loss of the training : 0.824221789837
Iteration : 2628
The accuracy of training : 0.726999998093
The loss of the training : 0.780932545662
Iteration : 2629
The accuracy of training : 0.722000002861
The loss of the training : 0.804880678654
Iteration : 2630
The accuracy of training : 0.73400002718
The loss of the training : 0.823009252548
Iteration : 2631
The accuracy of training : 0.728999972343
The loss of the training : 0.812596797943
Iteration : 2632
The accuracy of training : 0.702000021935
The loss of the training : 0.835291564465
Iteration : 2633
The accuracy of training : 0.675999999046
The loss of the training : 0.884444117546
Iteration : 2634
The accuracy of training : 0.708000004292
The loss of the training : 0.818238914013
Iteration : 2635
The accuracy of training : 0.731000006199
The loss of the training : 0.808984518051
Iteration : 2636
The accuracy of training : 0.737999975681
The loss of the training : 0.771888136864
Iteration : 2637
The accuracy of training : 0.702000021935
The loss of the training : 0.855242371559
Iteration : 2638
The accuracy of training : 0.721000015736
The loss of the training : 0.794692099094
Iteration : 2639
The accuracy of training : 0.73400002718
The loss of the training : 0.805274486542
Iteration : 2640
The accuracy of training : 0.73299998045
The loss of the training : 0.78396821022
Iteration : 2641
The accuracy of training : 0.75
The loss of the training : 0.78464204073
Iteration : 2642
The accuracy of training : 0.740999996662
The loss of the training : 0.748890161514
Iteration : 2643
The accuracy of training : 0.721000015736
The loss of the training : 0.796325325966
Iteration : 2644
The accuracy of training : 0.714999973774
The loss of the training : 0.813310980797
Iteration : 2645
The accuracy of training : 0.71899998188
The loss of the training : 0.821088910103
Iteration : 2646
The accuracy of training : 0.726000010967
The loss of the training : 0.802277326584
Iteration : 2647
The accuracy of training : 0.714999973774
The loss of the training : 0.834316372871
Iteration : 2648
The accuracy of training : 0.748000025749
The loss of the training : 0.78172814846
Iteration : 2649
The accuracy of training : 0.72000002861
The loss of the training : 0.799753427505
Iteration : 2650
The accuracy of training : 0.708000004292
The loss of the training : 0.868227660656
Iteration : 2651
The accuracy of training : 0.709999978542
The loss of the training : 0.828155994415
Iteration : 2652
The accuracy of training : 0.712999999523
The loss of the training : 0.855286836624
Iteration : 2653
The accuracy of training : 0.736999988556
The loss of the training : 0.805139183998
Iteration : 2654
The accuracy of training : 0.717000007629
The loss of the training : 0.803322732449
Iteration : 2655
The accuracy of training : 0.702000021935
The loss of the training : 0.862101137638
Iteration : 2656
The accuracy of training : 0.713999986649
The loss of the training : 0.837362706661
Iteration : 2657
The accuracy of training : 0.745999991894
The loss of the training : 0.757362961769
Iteration : 2658
The accuracy of training : 0.707000017166
The loss of the training : 0.833977639675
Iteration : 2659
The accuracy of training : 0.713999986649
The loss of the training : 0.826291382313
Iteration : 2660
The accuracy of training : 0.713999986649
The loss of the training : 0.812005579472
Iteration : 2661
The accuracy of training : 0.73400002718
The loss of the training : 0.809164226055
Iteration : 2662
The accuracy of training : 0.73400002718
The loss of the training : 0.829260706902
Iteration : 2663
The accuracy of training : 0.727999985218
The loss of the training : 0.772288739681
Iteration : 2664
The accuracy of training : 0.728999972343
The loss of the training : 0.801689743996
Iteration : 2665
The accuracy of training : 0.699999988079
The loss of the training : 0.827181696892
Iteration : 2666
The accuracy of training : 0.736000001431
The loss of the training : 0.795951187611
Iteration : 2667
The accuracy of training : 0.723999977112
The loss of the training : 0.821763932705
Iteration : 2668
The accuracy of training : 0.726999998093
The loss of the training : 0.779198229313
Iteration : 2669
The accuracy of training : 0.722999989986
The loss of the training : 0.802689433098
Iteration : 2670
The accuracy of training : 0.73400002718
The loss of the training : 0.821076273918
Iteration : 2671
The accuracy of training : 0.727999985218
The loss of the training : 0.810196638107
Iteration : 2672
The accuracy of training : 0.703999996185
The loss of the training : 0.832906246185
Iteration : 2673
The accuracy of training : 0.675999999046
The loss of the training : 0.882384479046
Iteration : 2674
The accuracy of training : 0.711000025272
The loss of the training : 0.81596583128
Iteration : 2675
The accuracy of training : 0.731999993324
The loss of the training : 0.806588709354
Iteration : 2676
The accuracy of training : 0.737999975681
The loss of the training : 0.770071923733
Iteration : 2677
The accuracy of training : 0.700999975204
The loss of the training : 0.853367865086
Iteration : 2678
The accuracy of training : 0.722000002861
The loss of the training : 0.792489171028
Iteration : 2679
The accuracy of training : 0.735000014305
The loss of the training : 0.803066372871
Iteration : 2680
The accuracy of training : 0.73299998045
The loss of the training : 0.781605899334
Iteration : 2681
The accuracy of training : 0.75
The loss of the training : 0.782753288746
Iteration : 2682
The accuracy of training : 0.740999996662
The loss of the training : 0.746834635735
Iteration : 2683
The accuracy of training : 0.72000002861
The loss of the training : 0.794192194939
Iteration : 2684
The accuracy of training : 0.713999986649
The loss of the training : 0.811239302158
Iteration : 2685
The accuracy of training : 0.72000002861
The loss of the training : 0.818872272968
Iteration : 2686
The accuracy of training : 0.727999985218
The loss of the training : 0.800346851349
Iteration : 2687
The accuracy of training : 0.714999973774
The loss of the training : 0.832268714905
Iteration : 2688
The accuracy of training : 0.749000012875
The loss of the training : 0.779478013515
Iteration : 2689
The accuracy of training : 0.722999989986
The loss of the training : 0.79749250412
Iteration : 2690
The accuracy of training : 0.709999978542
The loss of the training : 0.865155398846
Iteration : 2691
The accuracy of training : 0.712000012398
The loss of the training : 0.825472474098
Iteration : 2692
The accuracy of training : 0.712999999523
The loss of the training : 0.853098332882
Iteration : 2693
The accuracy of training : 0.737999975681
The loss of the training : 0.803102552891
Iteration : 2694
The accuracy of training : 0.717000007629
The loss of the training : 0.801146030426
Iteration : 2695
The accuracy of training : 0.699999988079
The loss of the training : 0.859638273716
Iteration : 2696
The accuracy of training : 0.714999973774
The loss of the training : 0.835073113441
Iteration : 2697
The accuracy of training : 0.745999991894
The loss of the training : 0.755467832088
Iteration : 2698
The accuracy of training : 0.707000017166
The loss of the training : 0.832088649273
Iteration : 2699
The accuracy of training : 0.713999986649
The loss of the training : 0.824087202549
Iteration : 2700
The accuracy of training : 0.714999973774
The loss of the training : 0.809856235981
Iteration : 2701
The accuracy of training : 0.735000014305
The loss of the training : 0.807054758072
Iteration : 2702
The accuracy of training : 0.735000014305
The loss of the training : 0.827039122581
Iteration : 2703
The accuracy of training : 0.731999993324
The loss of the training : 0.770295858383
Iteration : 2704
The accuracy of training : 0.730000019073
The loss of the training : 0.799509227276
Iteration : 2705
The accuracy of training : 0.70300000906
The loss of the training : 0.82515078783
Iteration : 2706
The accuracy of training : 0.736000001431
The loss of the training : 0.793869912624
Iteration : 2707
The accuracy of training : 0.723999977112
The loss of the training : 0.819593012333
Iteration : 2708
The accuracy of training : 0.726000010967
The loss of the training : 0.777352929115
Iteration : 2709
The accuracy of training : 0.722999989986
The loss of the training : 0.800681293011
Iteration : 2710
The accuracy of training : 0.73400002718
The loss of the training : 0.81927382946
Iteration : 2711
The accuracy of training : 0.727999985218
The loss of the training : 0.807997226715
Iteration : 2712
The accuracy of training : 0.703999996185
The loss of the training : 0.830526769161
Iteration : 2713
The accuracy of training : 0.676999986172
The loss of the training : 0.88034671545
Iteration : 2714
The accuracy of training : 0.709999978542
The loss of the training : 0.813842594624
Iteration : 2715
The accuracy of training : 0.73299998045
The loss of the training : 0.804237484932
Iteration : 2716
The accuracy of training : 0.736999988556
The loss of the training : 0.768099844456
Iteration : 2717
The accuracy of training : 0.700999975204
The loss of the training : 0.8513687253
Iteration : 2718
The accuracy of training : 0.721000015736
The loss of the training : 0.790378212929
Iteration : 2719
The accuracy of training : 0.735000014305
The loss of the training : 0.801159381866
Iteration : 2720
The accuracy of training : 0.735000014305
The loss of the training : 0.779432713985
Iteration : 2721
The accuracy of training : 0.749000012875
The loss of the training : 0.780913949013
Iteration : 2722
The accuracy of training : 0.740999996662
The loss of the training : 0.744741857052
Iteration : 2723
The accuracy of training : 0.722000002861
The loss of the training : 0.792176544666
Iteration : 2724
The accuracy of training : 0.713999986649
The loss of the training : 0.809127688408
Iteration : 2725
The accuracy of training : 0.71899998188
The loss of the training : 0.81691300869
Iteration : 2726
The accuracy of training : 0.728999972343
The loss of the training : 0.798872828484
Iteration : 2727
The accuracy of training : 0.714999973774
The loss of the training : 0.83061337471
Iteration : 2728
The accuracy of training : 0.75
The loss of the training : 0.777316868305
Iteration : 2729
The accuracy of training : 0.723999977112
The loss of the training : 0.795112967491
Iteration : 2730
The accuracy of training : 0.709999978542
The loss of the training : 0.862515568733
Iteration : 2731
The accuracy of training : 0.713999986649
The loss of the training : 0.822685718536
Iteration : 2732
The accuracy of training : 0.713999986649
The loss of the training : 0.850972294807
Iteration : 2733
The accuracy of training : 0.739000022411
The loss of the training : 0.80101531744
Iteration : 2734
The accuracy of training : 0.717000007629
The loss of the training : 0.799204289913
Iteration : 2735
The accuracy of training : 0.700999975204
The loss of the training : 0.857452690601
Iteration : 2736
The accuracy of training : 0.717000007629
The loss of the training : 0.833074629307
Iteration : 2737
The accuracy of training : 0.748000025749
The loss of the training : 0.753581225872
Iteration : 2738
The accuracy of training : 0.708000004292
The loss of the training : 0.830380797386
Iteration : 2739
The accuracy of training : 0.716000020504
The loss of the training : 0.821993947029
Iteration : 2740
The accuracy of training : 0.717000007629
The loss of the training : 0.807775914669
Iteration : 2741
The accuracy of training : 0.73299998045
The loss of the training : 0.804904460907
Iteration : 2742
The accuracy of training : 0.735000014305
The loss of the training : 0.825123906136
Iteration : 2743
The accuracy of training : 0.731999993324
The loss of the training : 0.768580973148
Iteration : 2744
The accuracy of training : 0.731000006199
The loss of the training : 0.797645568848
Iteration : 2745
The accuracy of training : 0.703999996185
The loss of the training : 0.82308280468
Iteration : 2746
The accuracy of training : 0.735000014305
The loss of the training : 0.791914701462
Iteration : 2747
The accuracy of training : 0.723999977112
The loss of the training : 0.817505300045
Iteration : 2748
The accuracy of training : 0.727999985218
The loss of the training : 0.775671720505
Iteration : 2749
The accuracy of training : 0.722999989986
The loss of the training : 0.798752248287
Iteration : 2750
The accuracy of training : 0.73400002718
The loss of the training : 0.817382752895
Iteration : 2751
The accuracy of training : 0.728999972343
The loss of the training : 0.805785357952
Iteration : 2752
The accuracy of training : 0.704999983311
The loss of the training : 0.828331232071
Iteration : 2753
The accuracy of training : 0.680000007153
The loss of the training : 0.878477454185
Iteration : 2754
The accuracy of training : 0.709999978542
The loss of the training : 0.811804711819
Iteration : 2755
The accuracy of training : 0.73400002718
The loss of the training : 0.80215215683
Iteration : 2756
The accuracy of training : 0.739000022411
The loss of the training : 0.766195118427
Iteration : 2757
The accuracy of training : 0.699999988079
The loss of the training : 0.849739730358
Iteration : 2758
The accuracy of training : 0.721000015736
The loss of the training : 0.788480937481
Iteration : 2759
The accuracy of training : 0.735000014305
The loss of the training : 0.799183011055
Iteration : 2760
The accuracy of training : 0.735000014305
The loss of the training : 0.777242362499
Iteration : 2761
The accuracy of training : 0.753000020981
The loss of the training : 0.779102921486
Iteration : 2762
The accuracy of training : 0.741999983788
The loss of the training : 0.742755532265
Iteration : 2763
The accuracy of training : 0.722999989986
The loss of the training : 0.790153503418
Iteration : 2764
The accuracy of training : 0.716000020504
The loss of the training : 0.807148456573
Iteration : 2765
The accuracy of training : 0.71899998188
The loss of the training : 0.814907133579
Iteration : 2766
The accuracy of training : 0.727999985218
The loss of the training : 0.797361910343
Iteration : 2767
The accuracy of training : 0.714999973774
The loss of the training : 0.828735530376
Iteration : 2768
The accuracy of training : 0.75
The loss of the training : 0.775264203548
Iteration : 2769
The accuracy of training : 0.723999977112
The loss of the training : 0.793087899685
Iteration : 2770
The accuracy of training : 0.711000025272
The loss of the training : 0.859906554222
Iteration : 2771
The accuracy of training : 0.713999986649
The loss of the training : 0.820260286331
Iteration : 2772
The accuracy of training : 0.714999973774
The loss of the training : 0.84883159399
Iteration : 2773
The accuracy of training : 0.740999996662
The loss of the training : 0.799233436584
Iteration : 2774
The accuracy of training : 0.717000007629
The loss of the training : 0.79714345932
Iteration : 2775
The accuracy of training : 0.700999975204
The loss of the training : 0.854959011078
Iteration : 2776
The accuracy of training : 0.716000020504
The loss of the training : 0.831098079681
Iteration : 2777
The accuracy of training : 0.748000025749
The loss of the training : 0.751906275749
Iteration : 2778
The accuracy of training : 0.708000004292
The loss of the training : 0.828593552113
Iteration : 2779
The accuracy of training : 0.714999973774
The loss of the training : 0.820011734962
Iteration : 2780
The accuracy of training : 0.717000007629
The loss of the training : 0.805894553661
Iteration : 2781
The accuracy of training : 0.731000006199
The loss of the training : 0.802981078625
Iteration : 2782
The accuracy of training : 0.736999988556
The loss of the training : 0.823227286339
Iteration : 2783
The accuracy of training : 0.73400002718
The loss of the training : 0.766842246056
Iteration : 2784
The accuracy of training : 0.731000006199
The loss of the training : 0.795599997044
Iteration : 2785
The accuracy of training : 0.704999983311
The loss of the training : 0.821264982224
Iteration : 2786
The accuracy of training : 0.735000014305
The loss of the training : 0.790080904961
Iteration : 2787
The accuracy of training : 0.726999998093
The loss of the training : 0.815439999104
Iteration : 2788
The accuracy of training : 0.727999985218
The loss of the training : 0.773969054222
Iteration : 2789
The accuracy of training : 0.722999989986
The loss of the training : 0.796899616718
Iteration : 2790
The accuracy of training : 0.73299998045
The loss of the training : 0.815688252449
Iteration : 2791
The accuracy of training : 0.728999972343
The loss of the training : 0.803691327572
Iteration : 2792
The accuracy of training : 0.70300000906
The loss of the training : 0.826236665249
Iteration : 2793
The accuracy of training : 0.680999994278
The loss of the training : 0.876513302326
Iteration : 2794
The accuracy of training : 0.711000025272
The loss of the training : 0.80975663662
Iteration : 2795
The accuracy of training : 0.73400002718
The loss of the training : 0.800103783607
Iteration : 2796
The accuracy of training : 0.740000009537
The loss of the training : 0.764564156532
Iteration : 2797
The accuracy of training : 0.700999975204
The loss of the training : 0.847826600075
Iteration : 2798
The accuracy of training : 0.721000015736
The loss of the training : 0.786560118198
Iteration : 2799
The accuracy of training : 0.735000014305
The loss of the training : 0.797407269478
Iteration : 2800
The accuracy of training : 0.735000014305
The loss of the training : 0.77511459589
Iteration : 2801
The accuracy of training : 0.753000020981
The loss of the training : 0.777330219746
Iteration : 2802
The accuracy of training : 0.744000017643
The loss of the training : 0.740740418434
Iteration : 2803
The accuracy of training : 0.723999977112
The loss of the training : 0.788293659687
Iteration : 2804
The accuracy of training : 0.717000007629
The loss of the training : 0.805280745029
Iteration : 2805
The accuracy of training : 0.71899998188
The loss of the training : 0.813133239746
Iteration : 2806
The accuracy of training : 0.730000019073
The loss of the training : 0.795984387398
Iteration : 2807
The accuracy of training : 0.716000020504
The loss of the training : 0.827093601227
Iteration : 2808
The accuracy of training : 0.751999974251
The loss of the training : 0.773180305958
Iteration : 2809
The accuracy of training : 0.725000023842
The loss of the training : 0.791094481945
Iteration : 2810
The accuracy of training : 0.712000012398
The loss of the training : 0.857654333115
Iteration : 2811
The accuracy of training : 0.712999999523
The loss of the training : 0.81795412302
Iteration : 2812
The accuracy of training : 0.712999999523
The loss of the training : 0.84706813097
Iteration : 2813
The accuracy of training : 0.740999996662
The loss of the training : 0.797423362732
Iteration : 2814
The accuracy of training : 0.717999994755
The loss of the training : 0.795332551003
Iteration : 2815
The accuracy of training : 0.70300000906
The loss of the training : 0.852522492409
Iteration : 2816
The accuracy of training : 0.717000007629
The loss of the training : 0.829243302345
Iteration : 2817
The accuracy of training : 0.75
The loss of the training : 0.750183522701
Iteration : 2818
The accuracy of training : 0.709999978542
The loss of the training : 0.827047407627
Iteration : 2819
The accuracy of training : 0.716000020504
The loss of the training : 0.818183481693
Iteration : 2820
The accuracy of training : 0.717999994755
The loss of the training : 0.803958594799
Iteration : 2821
The accuracy of training : 0.73299998045
The loss of the training : 0.801128029823
Iteration : 2822
The accuracy of training : 0.736000001431
The loss of the training : 0.821645140648
Iteration : 2823
The accuracy of training : 0.73299998045
The loss of the training : 0.765304088593
Iteration : 2824
The accuracy of training : 0.731000006199
The loss of the training : 0.793872833252
Iteration : 2825
The accuracy of training : 0.707000017166
The loss of the training : 0.819390892982
Iteration : 2826
The accuracy of training : 0.73299998045
The loss of the training : 0.788234174252
Iteration : 2827
The accuracy of training : 0.725000023842
The loss of the training : 0.813468694687
Iteration : 2828
The accuracy of training : 0.728999972343
The loss of the training : 0.772252440453
Iteration : 2829
The accuracy of training : 0.723999977112
The loss of the training : 0.795165896416
Iteration : 2830
The accuracy of training : 0.731999993324
The loss of the training : 0.813924014568
Iteration : 2831
The accuracy of training : 0.730000019073
The loss of the training : 0.801744937897
Iteration : 2832
The accuracy of training : 0.702000021935
The loss of the training : 0.824195086956
Iteration : 2833
The accuracy of training : 0.685000002384
The loss of the training : 0.87464261055
Iteration : 2834
The accuracy of training : 0.712000012398
The loss of the training : 0.80778336525
Iteration : 2835
The accuracy of training : 0.736000001431
The loss of the training : 0.798145413399
Iteration : 2836
The accuracy of training : 0.744000017643
The loss of the training : 0.762993752956
Iteration : 2837
The accuracy of training : 0.699999988079
The loss of the training : 0.84601432085
Iteration : 2838
The accuracy of training : 0.72000002861
The loss of the training : 0.784835100174
Iteration : 2839
The accuracy of training : 0.73400002718
The loss of the training : 0.795583546162
Iteration : 2840
The accuracy of training : 0.736000001431
The loss of the training : 0.773141622543
Iteration : 2841
The accuracy of training : 0.751999974251
The loss of the training : 0.775562644005
Iteration : 2842
The accuracy of training : 0.745999991894
The loss of the training : 0.738873720169
Iteration : 2843
The accuracy of training : 0.722999989986
The loss of the training : 0.786490023136
Iteration : 2844
The accuracy of training : 0.717999994755
The loss of the training : 0.803536891937
Iteration : 2845
The accuracy of training : 0.717999994755
The loss of the training : 0.81149917841
Iteration : 2846
The accuracy of training : 0.730000019073
The loss of the training : 0.794087052345
Iteration : 2847
The accuracy of training : 0.716000020504
The loss of the training : 0.825178563595
Iteration : 2848
The accuracy of training : 0.751999974251
The loss of the training : 0.771251618862
Iteration : 2849
The accuracy of training : 0.725000023842
The loss of the training : 0.789180219173
Iteration : 2850
The accuracy of training : 0.712000012398
The loss of the training : 0.855184614658
Iteration : 2851
The accuracy of training : 0.712000012398
The loss of the training : 0.815861344337
Iteration : 2852
The accuracy of training : 0.713999986649
The loss of the training : 0.845322191715
Iteration : 2853
The accuracy of training : 0.741999983788
The loss of the training : 0.795783042908
Iteration : 2854
The accuracy of training : 0.716000020504
The loss of the training : 0.79366594553
Iteration : 2855
The accuracy of training : 0.702000021935
The loss of the training : 0.850529432297
Iteration : 2856
The accuracy of training : 0.71899998188
The loss of the training : 0.827561676502
Iteration : 2857
The accuracy of training : 0.75
The loss of the training : 0.748641610146
Iteration : 2858
The accuracy of training : 0.709999978542
The loss of the training : 0.825452566147
Iteration : 2859
The accuracy of training : 0.717999994755
The loss of the training : 0.816397845745
Iteration : 2860
The accuracy of training : 0.717999994755
The loss of the training : 0.802210092545
Iteration : 2861
The accuracy of training : 0.73400002718
The loss of the training : 0.799360156059
Iteration : 2862
The accuracy of training : 0.740000009537
The loss of the training : 0.819904565811
Iteration : 2863
The accuracy of training : 0.735000014305
The loss of the training : 0.76389580965
Iteration : 2864
The accuracy of training : 0.731999993324
The loss of the training : 0.792095899582
Iteration : 2865
The accuracy of training : 0.708999991417
The loss of the training : 0.817616760731
Iteration : 2866
The accuracy of training : 0.735000014305
The loss of the training : 0.786360502243
Iteration : 2867
The accuracy of training : 0.726000010967
The loss of the training : 0.811543762684
Iteration : 2868
The accuracy of training : 0.728999972343
The loss of the training : 0.770695626736
Iteration : 2869
The accuracy of training : 0.726999998093
The loss of the training : 0.793432533741
Iteration : 2870
The accuracy of training : 0.73299998045
The loss of the training : 0.812342762947
Iteration : 2871
The accuracy of training : 0.731999993324
The loss of the training : 0.799864172935
Iteration : 2872
The accuracy of training : 0.704999983311
The loss of the training : 0.822401583195
Iteration : 2873
The accuracy of training : 0.686999976635
The loss of the training : 0.872729361057
Iteration : 2874
The accuracy of training : 0.712999999523
The loss of the training : 0.806017160416
Iteration : 2875
The accuracy of training : 0.737999975681
The loss of the training : 0.796306073666
Iteration : 2876
The accuracy of training : 0.745999991894
The loss of the training : 0.761322677135
Iteration : 2877
The accuracy of training : 0.70300000906
The loss of the training : 0.844208478928
Iteration : 2878
The accuracy of training : 0.721000015736
The loss of the training : 0.783118128777
Iteration : 2879
The accuracy of training : 0.73400002718
The loss of the training : 0.793851494789
Iteration : 2880
The accuracy of training : 0.737999975681
The loss of the training : 0.771254181862
Iteration : 2881
The accuracy of training : 0.754000008106
The loss of the training : 0.773922622204
Iteration : 2882
The accuracy of training : 0.749000012875
The loss of the training : 0.737051427364
Iteration : 2883
The accuracy of training : 0.722999989986
The loss of the training : 0.784734725952
Iteration : 2884
The accuracy of training : 0.72000002861
The loss of the training : 0.801805377007
Iteration : 2885
The accuracy of training : 0.717999994755
The loss of the training : 0.809883952141
Iteration : 2886
The accuracy of training : 0.730000019073
The loss of the training : 0.792989552021
Iteration : 2887
The accuracy of training : 0.717999994755
The loss of the training : 0.82369107008
Iteration : 2888
The accuracy of training : 0.753000020981
The loss of the training : 0.769303619862
Iteration : 2889
The accuracy of training : 0.725000023842
The loss of the training : 0.787351191044
Iteration : 2890
The accuracy of training : 0.712000012398
The loss of the training : 0.852926254272
Iteration : 2891
The accuracy of training : 0.712000012398
The loss of the training : 0.813732206821
Iteration : 2892
The accuracy of training : 0.716000020504
The loss of the training : 0.843773782253
Iteration : 2893
The accuracy of training : 0.740999996662
The loss of the training : 0.79394119978
Iteration : 2894
The accuracy of training : 0.71899998188
The loss of the training : 0.791854679585
Iteration : 2895
The accuracy of training : 0.703999996185
The loss of the training : 0.848301768303
Iteration : 2896
The accuracy of training : 0.717000007629
The loss of the training : 0.825908780098
Iteration : 2897
The accuracy of training : 0.749000012875
The loss of the training : 0.747056901455
Iteration : 2898
The accuracy of training : 0.712999999523
The loss of the training : 0.823990404606
Iteration : 2899
The accuracy of training : 0.717999994755
The loss of the training : 0.81469219923
Iteration : 2900
The accuracy of training : 0.71899998188
The loss of the training : 0.800364911556
Iteration : 2901
The accuracy of training : 0.736999988556
The loss of the training : 0.79764431715
Iteration : 2902
The accuracy of training : 0.740000009537
The loss of the training : 0.818288326263
Iteration : 2903
The accuracy of training : 0.737999975681
The loss of the training : 0.762531757355
Iteration : 2904
The accuracy of training : 0.736000001431
The loss of the training : 0.790508508682
Iteration : 2905
The accuracy of training : 0.708999991417
The loss of the training : 0.815984904766
Iteration : 2906
The accuracy of training : 0.735000014305
The loss of the training : 0.784680604935
Iteration : 2907
The accuracy of training : 0.726000010967
The loss of the training : 0.809883952141
Iteration : 2908
The accuracy of training : 0.728999972343
The loss of the training : 0.769182682037
Iteration : 2909
The accuracy of training : 0.723999977112
The loss of the training : 0.791840195656
Iteration : 2910
The accuracy of training : 0.73400002718
The loss of the training : 0.810750424862
Iteration : 2911
The accuracy of training : 0.73400002718
The loss of the training : 0.797944009304
Iteration : 2912
The accuracy of training : 0.703999996185
The loss of the training : 0.82051807642
Iteration : 2913
The accuracy of training : 0.68900001049
The loss of the training : 0.871015548706
Iteration : 2914
The accuracy of training : 0.713999986649
The loss of the training : 0.804218709469
Iteration : 2915
The accuracy of training : 0.739000022411
The loss of the training : 0.794501900673
Iteration : 2916
The accuracy of training : 0.746999979019
The loss of the training : 0.759873330593
Iteration : 2917
The accuracy of training : 0.70300000906
The loss of the training : 0.842568337917
Iteration : 2918
The accuracy of training : 0.721000015736
The loss of the training : 0.781554102898
Iteration : 2919
The accuracy of training : 0.73299998045
The loss of the training : 0.792276382446
Iteration : 2920
The accuracy of training : 0.740000009537
The loss of the training : 0.769451141357
Iteration : 2921
The accuracy of training : 0.754000008106
The loss of the training : 0.772438526154
Iteration : 2922
The accuracy of training : 0.75
The loss of the training : 0.735373914242
Iteration : 2923
The accuracy of training : 0.725000023842
The loss of the training : 0.783098697662
Iteration : 2924
The accuracy of training : 0.721000015736
The loss of the training : 0.800081312656
Iteration : 2925
The accuracy of training : 0.717999994755
The loss of the training : 0.808391392231
Iteration : 2926
The accuracy of training : 0.731000006199
The loss of the training : 0.791482448578
Iteration : 2927
The accuracy of training : 0.717999994755
The loss of the training : 0.822067081928
Iteration : 2928
The accuracy of training : 0.751999974251
The loss of the training : 0.767500579357
Iteration : 2929
The accuracy of training : 0.725000023842
The loss of the training : 0.785774827003
Iteration : 2930
The accuracy of training : 0.712999999523
The loss of the training : 0.850742161274
Iteration : 2931
The accuracy of training : 0.712000012398
The loss of the training : 0.811787128448
Iteration : 2932
The accuracy of training : 0.717000007629
The loss of the training : 0.841977357864
Iteration : 2933
The accuracy of training : 0.740999996662
The loss of the training : 0.792497634888
Iteration : 2934
The accuracy of training : 0.72000002861
The loss of the training : 0.790271043777
Iteration : 2935
The accuracy of training : 0.703999996185
The loss of the training : 0.846461832523
Iteration : 2936
The accuracy of training : 0.717999994755
The loss of the training : 0.824403226376
Iteration : 2937
The accuracy of training : 0.749000012875
The loss of the training : 0.745506644249
Iteration : 2938
The accuracy of training : 0.714999973774
The loss of the training : 0.822569549084
Iteration : 2939
The accuracy of training : 0.717000007629
The loss of the training : 0.813127636909
Iteration : 2940
The accuracy of training : 0.71899998188
The loss of the training : 0.798750281334
Iteration : 2941
The accuracy of training : 0.740000009537
The loss of the training : 0.796070635319
Iteration : 2942
The accuracy of training : 0.741999983788
The loss of the training : 0.816650807858
Iteration : 2943
The accuracy of training : 0.736999988556
The loss of the training : 0.761120438576
Iteration : 2944
The accuracy of training : 0.736000001431
The loss of the training : 0.788938045502
Iteration : 2945
The accuracy of training : 0.708999991417
The loss of the training : 0.814281344414
Iteration : 2946
The accuracy of training : 0.735000014305
The loss of the training : 0.783103048801
Iteration : 2947
The accuracy of training : 0.726000010967
The loss of the training : 0.808048605919
Iteration : 2948
The accuracy of training : 0.728999972343
The loss of the training : 0.767679750919
Iteration : 2949
The accuracy of training : 0.726000010967
The loss of the training : 0.7903008461
Iteration : 2950
The accuracy of training : 0.735000014305
The loss of the training : 0.809258103371
Iteration : 2951
The accuracy of training : 0.73299998045
The loss of the training : 0.796160459518
Iteration : 2952
The accuracy of training : 0.70300000906
The loss of the training : 0.818860888481
Iteration : 2953
The accuracy of training : 0.689999997616
The loss of the training : 0.869164824486
Iteration : 2954
The accuracy of training : 0.716000020504
The loss of the training : 0.802421808243
Iteration : 2955
The accuracy of training : 0.740999996662
The loss of the training : 0.79272300005
Iteration : 2956
The accuracy of training : 0.748000025749
The loss of the training : 0.758391499519
Iteration : 2957
The accuracy of training : 0.703999996185
The loss of the training : 0.84069943428
Iteration : 2958
The accuracy of training : 0.722999989986
The loss of the training : 0.779999196529
Iteration : 2959
The accuracy of training : 0.73400002718
The loss of the training : 0.790646493435
Iteration : 2960
The accuracy of training : 0.742999970913
The loss of the training : 0.767727792263
Iteration : 2961
The accuracy of training : 0.754000008106
The loss of the training : 0.770993709564
Iteration : 2962
The accuracy of training : 0.748000025749
The loss of the training : 0.733768343925
Iteration : 2963
The accuracy of training : 0.726000010967
The loss of the training : 0.781592786312
Iteration : 2964
The accuracy of training : 0.722000002861
The loss of the training : 0.798434734344
Iteration : 2965
The accuracy of training : 0.717000007629
The loss of the training : 0.807042896748
Iteration : 2966
The accuracy of training : 0.73400002718
The loss of the training : 0.789954066277
Iteration : 2967
The accuracy of training : 0.717999994755
The loss of the training : 0.820476830006
Iteration : 2968
The accuracy of training : 0.751999974251
The loss of the training : 0.765936970711
Iteration : 2969
The accuracy of training : 0.726000010967
The loss of the training : 0.784252345562
Iteration : 2970
The accuracy of training : 0.714999973774
The loss of the training : 0.848793387413
Iteration : 2971
The accuracy of training : 0.713999986649
The loss of the training : 0.809897124767
Iteration : 2972
The accuracy of training : 0.717999994755
The loss of the training : 0.840232074261
Iteration : 2973
The accuracy of training : 0.740999996662
The loss of the training : 0.790970385075
Iteration : 2974
The accuracy of training : 0.71899998188
The loss of the training : 0.788478195667
Iteration : 2975
The accuracy of training : 0.703999996185
The loss of the training : 0.844536006451
Iteration : 2976
The accuracy of training : 0.716000020504
The loss of the training : 0.822882592678
Iteration : 2977
The accuracy of training : 0.746999979019
The loss of the training : 0.744083285332
Iteration : 2978
The accuracy of training : 0.717000007629
The loss of the training : 0.821228921413
Iteration : 2979
The accuracy of training : 0.717000007629
The loss of the training : 0.81159901619
Iteration : 2980
The accuracy of training : 0.72000002861
The loss of the training : 0.797196567059
Iteration : 2981
The accuracy of training : 0.741999983788
The loss of the training : 0.79458719492
Iteration : 2982
The accuracy of training : 0.742999970913
The loss of the training : 0.815252006054
Iteration : 2983
The accuracy of training : 0.740000009537
The loss of the training : 0.759835958481
Iteration : 2984
The accuracy of training : 0.739000022411
The loss of the training : 0.787492215633
Iteration : 2985
The accuracy of training : 0.709999978542
The loss of the training : 0.812721252441
Iteration : 2986
The accuracy of training : 0.735000014305
The loss of the training : 0.781633615494
Iteration : 2987
The accuracy of training : 0.725000023842
The loss of the training : 0.806504607201
Iteration : 2988
The accuracy of training : 0.731000006199
The loss of the training : 0.7661678195
Iteration : 2989
The accuracy of training : 0.727999985218
The loss of the training : 0.788796901703
Iteration : 2990
The accuracy of training : 0.736999988556
The loss of the training : 0.807895362377
Iteration : 2991
The accuracy of training : 0.73400002718
The loss of the training : 0.794416487217
Iteration : 2992
The accuracy of training : 0.703999996185
The loss of the training : 0.817202329636
Iteration : 2993
The accuracy of training : 0.690999984741
The loss of the training : 0.867516279221
Iteration : 2994
The accuracy of training : 0.717000007629
The loss of the training : 0.800785601139
Iteration : 2995
The accuracy of training : 0.740999996662
The loss of the training : 0.791019320488
Iteration : 2996
The accuracy of training : 0.749000012875
The loss of the training : 0.757015049458
Iteration : 2997
The accuracy of training : 0.705999970436
The loss of the training : 0.839068710804
Iteration : 2998
The accuracy of training : 0.725000023842
The loss of the training : 0.778605878353
Iteration : 2999
The accuracy of training : 0.735000014305
The loss of the training : 0.789088845253
INFO: Executing on the validation dataset.
RESULT: Overall validation accuracy is : 0.677000
